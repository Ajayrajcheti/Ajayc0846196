{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "H=200_le_8_3000.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9E7NFMGNr9Bu"
      }
    },
    {
      "metadata": {
        "id": "cWACPRL869I4"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym >/dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Os6feRY6ec_"
      },
      "cell_type": "code",
      "source": [
        "!pip install JSAnimation >/dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wotUOa_e6edP"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"\n",
        "    Displays a list of frames as a gif, with controls\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    HTML(anim.to_jshtml())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R66_INeZ9nYX"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Playing Pong"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U gym>=0.21.0\n",
        "%pip install -U gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ngMhg3fB9aA",
        "outputId": "e74af1f6-fab8-4a7e-bdf4-3b8a22a40ccd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.5.0)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 4.8 MB/s \n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=717b8763829c235209eec553a0148954beba0e9c0c7e72727c21fb01274f6209\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MtT2GyK_6edc",
        "outputId": "2739b98e-cfed-4e75-f4a6-c7f36070dee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oRE6WmXQJ1Z0",
        "outputId": "de2abf56-505e-422e-e401-ca10a2250deb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "yl_9d4HFJ31W",
        "outputId": "b0af953f-8d5b-4f12-8d8f-0f6b7c507f0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.observation_space"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(0, 255, (210, 160, 3), uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "trwRXI-h6eeI",
        "outputId": "e99748e5-3d4e-43a8-9470-646bd507e0ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Run a demo of the environment\n",
        "observation = env.reset()\n",
        "cumulated_reward = 0\n",
        "\n",
        "frames = []\n",
        "for t in range(1000):\n",
        "#     print(observation)\n",
        "    frames.append(env.render(mode = 'rgb_array'))\n",
        "    # very stupid agent, just makes a random action within the allowd action space\n",
        "    action = env.action_space.sample()\n",
        "#     print(\"Action: {}\".format(t+1))    \n",
        "    observation, reward, done, info = env.step(action)\n",
        "#     print(reward)\n",
        "    cumulated_reward += reward\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "        break\n",
        "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:44: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -20.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3zZTecVWLLes"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x): \n",
        "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
        "\n",
        "def prepro(I):\n",
        "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::2,::2,0] # downsample by factor of 2\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "def policy_forward(x):\n",
        "  h = np.dot(model['W1'], x)\n",
        "  h[h<0] = 0 # ReLU nonlinearity\n",
        "  logp = np.dot(model['W2'], h)\n",
        "  p = sigmoid(logp)\n",
        "  return p, h # return probability of taking action 2, and hidden state\n",
        "\n",
        "def model_step(model, observation, prev_x):\n",
        "  # preprocess the observation, set input to network to be difference image\n",
        "  cur_x = prepro(observation)\n",
        "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "  prev_x = cur_x\n",
        "  \n",
        "  # forward the policy network and sample an action from the returned probability\n",
        "  aprob, _ = policy_forward(x)\n",
        "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
        "  \n",
        "  return action, prev_x\n",
        "\n",
        "def play_game(env, model):\n",
        "  observation = env.reset()\n",
        "\n",
        "  frames = []\n",
        "  cumulated_reward = 0\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "\n",
        "  for t in range(1000):\n",
        "      frames.append(env.render(mode = 'rgb_array'))\n",
        "      action, prev_x = model_step(model, observation, prev_x)\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      cumulated_reward += reward\n",
        "      if done:\n",
        "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "          break\n",
        "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "  display_frames_as_gif(frames)\n",
        "  env.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gWvZQ7AQLQt"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Policy Gradient from Scratch"
      ]
    },
    {
      "metadata": {
        "id": "eqFm7hqcItWl"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# model initialization\n",
        "H = 200 # number of hidden layer neurons\n",
        "D = 80 * 80 # input dimensionality: 80x80 grid\n",
        "model = {}\n",
        "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
        "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
        "\n",
        "# import pickle\n",
        "# model = pickle.load(open('model.pkl', 'rb'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwjiwKisQM19"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 10 # every how many episodes to do a param update?\n",
        "# learning_rate = 1e-4\n",
        "learning_rate = 1e-8\n",
        " \n",
        "gamma = 0.99 # discount factor for reward\n",
        "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
        "  \n",
        "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
        "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
        "\n",
        "def discount_rewards(r):\n",
        "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
        "  running_add = 0\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
        "    running_add = running_add * gamma + r[t]\n",
        "    discounted_r[t] = running_add\n",
        "  return discounted_r\n",
        "\n",
        "def policy_backward(epx, eph, epdlogp):\n",
        "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
        "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
        "  dh = np.outer(epdlogp, model['W2'])\n",
        "  dh[eph <= 0] = 0 # backpro prelu\n",
        "  dW1 = np.dot(dh.T, epx)\n",
        "  return {'W1':dW1, 'W2':dW2}\n",
        "\n",
        "def train_model(env, model, total_episodes = 100):\n",
        "  hist = []\n",
        "  observation = env.reset()\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "  xs,hs,dlogps,drs = [],[],[],[]\n",
        "  running_reward = None\n",
        "  reward_sum = 0\n",
        "  episode_number = 0\n",
        "\n",
        "  while True:\n",
        "    # preprocess the observation, set input to network to be difference image\n",
        "    cur_x = prepro(observation)\n",
        "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "    prev_x = cur_x\n",
        "\n",
        "    # forward the policy network and sample an action from the returned probability\n",
        "    aprob, h = policy_forward(x)\n",
        "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
        "\n",
        "    # record various intermediates (needed later for backprop)\n",
        "    xs.append(x) # observation\n",
        "    hs.append(h) # hidden state\n",
        "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
        "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
        "\n",
        "    # step the environment and get new measurements\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    reward_sum += reward\n",
        "\n",
        "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
        "\n",
        "    if done: # an episode finished\n",
        "      episode_number += 1\n",
        "\n",
        "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
        "      epx = np.vstack(xs)\n",
        "      eph = np.vstack(hs)\n",
        "      epdlogp = np.vstack(dlogps)\n",
        "      epr = np.vstack(drs)\n",
        "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
        "\n",
        "      # compute the discounted reward backwards through time\n",
        "      discounted_epr = discount_rewards(epr)\n",
        "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
        "      discounted_epr -= np.mean(discounted_epr)\n",
        "      discounted_epr /= np.std(discounted_epr)\n",
        "\n",
        "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
        "      grad = policy_backward(epx, eph, epdlogp)\n",
        "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
        "\n",
        "      # perform rmsprop parameter update every batch_size episodes\n",
        "      if episode_number % batch_size == 0:\n",
        "        for k,v in model.items():\n",
        "          g = grad_buffer[k] # gradient\n",
        "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
        "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
        "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
        "\n",
        "      # boring book-keeping\n",
        "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "      hist.append((episode_number, reward_sum, running_reward))\n",
        "      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
        "      reward_sum = 0\n",
        "      observation = env.reset() # reset env\n",
        "      prev_x = None\n",
        "      if episode_number == total_episodes: return hist\n",
        "\n",
        "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
        "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6Ka_5Vl9Orm",
        "outputId": "aa6450c7-5be7-4eaf-c4ed-9b302882640a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist1 = train_model(env, model, total_episodes=3000)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.990000\n",
            "resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.990100\n",
            "resetting env. episode 5.000000, reward total was -19.000000. running mean: -20.970199\n",
            "resetting env. episode 6.000000, reward total was -20.000000. running mean: -20.960497\n",
            "resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.950892\n",
            "resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.951383\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.951869\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.952351\n",
            "resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.952827\n",
            "resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.953299\n",
            "resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.943766\n",
            "resetting env. episode 14.000000, reward total was -19.000000. running mean: -20.924328\n",
            "resetting env. episode 15.000000, reward total was -19.000000. running mean: -20.905085\n",
            "resetting env. episode 16.000000, reward total was -16.000000. running mean: -20.856034\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.857474\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.858899\n",
            "resetting env. episode 19.000000, reward total was -19.000000. running mean: -20.840310\n",
            "resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.841907\n",
            "resetting env. episode 21.000000, reward total was -20.000000. running mean: -20.833488\n",
            "resetting env. episode 22.000000, reward total was -20.000000. running mean: -20.825153\n",
            "resetting env. episode 23.000000, reward total was -20.000000. running mean: -20.816901\n",
            "resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.818732\n",
            "resetting env. episode 25.000000, reward total was -20.000000. running mean: -20.810545\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.812440\n",
            "resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.804315\n",
            "resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.806272\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.808209\n",
            "resetting env. episode 30.000000, reward total was -19.000000. running mean: -20.790127\n",
            "resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.792226\n",
            "resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.784304\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.786461\n",
            "resetting env. episode 34.000000, reward total was -20.000000. running mean: -20.778596\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.780810\n",
            "resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.783002\n",
            "resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.785172\n",
            "resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.787320\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.789447\n",
            "resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.791553\n",
            "resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.793637\n",
            "resetting env. episode 42.000000, reward total was -19.000000. running mean: -20.775701\n",
            "resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.777944\n",
            "resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.780164\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.782363\n",
            "resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.784539\n",
            "resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.786694\n",
            "resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.788827\n",
            "resetting env. episode 49.000000, reward total was -20.000000. running mean: -20.780938\n",
            "resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.773129\n",
            "resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.765398\n",
            "resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.767744\n",
            "resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.770066\n",
            "resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.772366\n",
            "resetting env. episode 55.000000, reward total was -20.000000. running mean: -20.764642\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.766996\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.769326\n",
            "resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.771632\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.773916\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.776177\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.778415\n",
            "resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.780631\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.782825\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.784996\n",
            "resetting env. episode 65.000000, reward total was -20.000000. running mean: -20.777146\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.779375\n",
            "resetting env. episode 67.000000, reward total was -19.000000. running mean: -20.761581\n",
            "resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.753965\n",
            "resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.746426\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.748961\n",
            "resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.751472\n",
            "resetting env. episode 72.000000, reward total was -20.000000. running mean: -20.743957\n",
            "resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.746518\n",
            "resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.749052\n",
            "resetting env. episode 75.000000, reward total was -20.000000. running mean: -20.741562\n",
            "resetting env. episode 76.000000, reward total was -20.000000. running mean: -20.734146\n",
            "resetting env. episode 77.000000, reward total was -19.000000. running mean: -20.716805\n",
            "resetting env. episode 78.000000, reward total was -19.000000. running mean: -20.699637\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.702640\n",
            "resetting env. episode 80.000000, reward total was -19.000000. running mean: -20.685614\n",
            "resetting env. episode 81.000000, reward total was -19.000000. running mean: -20.668758\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.672070\n",
            "resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.675350\n",
            "resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.678596\n",
            "resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.671810\n",
            "resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.665092\n",
            "resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.668441\n",
            "resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.671757\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.675039\n",
            "resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.678289\n",
            "resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.681506\n",
            "resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.684691\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.687844\n",
            "resetting env. episode 94.000000, reward total was -20.000000. running mean: -20.680965\n",
            "resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.684156\n",
            "resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.687314\n",
            "resetting env. episode 97.000000, reward total was -18.000000. running mean: -20.660441\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.663837\n",
            "resetting env. episode 99.000000, reward total was -18.000000. running mean: -20.637198\n",
            "resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.640826\n",
            "resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.644418\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.647974\n",
            "resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.651494\n",
            "resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.654979\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.658429\n",
            "resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.651845\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.655327\n",
            "resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.658773\n",
            "resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.662186\n",
            "resetting env. episode 110.000000, reward total was -16.000000. running mean: -20.615564\n",
            "resetting env. episode 111.000000, reward total was -19.000000. running mean: -20.599408\n",
            "resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.603414\n",
            "resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.607380\n",
            "resetting env. episode 114.000000, reward total was -20.000000. running mean: -20.601306\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.605293\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.609240\n",
            "resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.613148\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.617016\n",
            "resetting env. episode 119.000000, reward total was -19.000000. running mean: -20.600846\n",
            "resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.604838\n",
            "resetting env. episode 121.000000, reward total was -18.000000. running mean: -20.578789\n",
            "resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.573001\n",
            "resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.577271\n",
            "resetting env. episode 124.000000, reward total was -19.000000. running mean: -20.561499\n",
            "resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.565884\n",
            "resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.570225\n",
            "resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.564523\n",
            "resetting env. episode 128.000000, reward total was -20.000000. running mean: -20.558877\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.563289\n",
            "resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.557656\n",
            "resetting env. episode 131.000000, reward total was -19.000000. running mean: -20.542079\n",
            "resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.546658\n",
            "resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.541192\n",
            "resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.545780\n",
            "resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.540322\n",
            "resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.544919\n",
            "resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.549470\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.553975\n",
            "resetting env. episode 139.000000, reward total was -19.000000. running mean: -20.538435\n",
            "resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.543051\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.547620\n",
            "resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.552144\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.556623\n",
            "resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.551056\n",
            "resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.555546\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.559990\n",
            "resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.564391\n",
            "resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.568747\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.573059\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.567329\n",
            "resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.561655\n",
            "resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.566039\n",
            "resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.570378\n",
            "resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.574675\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.568928\n",
            "resetting env. episode 156.000000, reward total was -19.000000. running mean: -20.553239\n",
            "resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.557706\n",
            "resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.552129\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.556608\n",
            "resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.551042\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.555531\n",
            "resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.549976\n",
            "resetting env. episode 163.000000, reward total was -19.000000. running mean: -20.534476\n",
            "resetting env. episode 164.000000, reward total was -19.000000. running mean: -20.519131\n",
            "resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.513940\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.518801\n",
            "resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.513613\n",
            "resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.518477\n",
            "resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.513292\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.518159\n",
            "resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.522977\n",
            "resetting env. episode 172.000000, reward total was -20.000000. running mean: -20.517748\n",
            "resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.522570\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.527344\n",
            "resetting env. episode 175.000000, reward total was -18.000000. running mean: -20.502071\n",
            "resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.507050\n",
            "resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.511980\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.516860\n",
            "resetting env. episode 179.000000, reward total was -19.000000. running mean: -20.501691\n",
            "resetting env. episode 180.000000, reward total was -20.000000. running mean: -20.496674\n",
            "resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.491708\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.496791\n",
            "resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.491823\n",
            "resetting env. episode 184.000000, reward total was -20.000000. running mean: -20.486904\n",
            "resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.492035\n",
            "resetting env. episode 186.000000, reward total was -19.000000. running mean: -20.477115\n",
            "resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.482344\n",
            "resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.487520\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.482645\n",
            "resetting env. episode 190.000000, reward total was -20.000000. running mean: -20.477819\n",
            "resetting env. episode 191.000000, reward total was -19.000000. running mean: -20.463041\n",
            "resetting env. episode 192.000000, reward total was -20.000000. running mean: -20.458410\n",
            "resetting env. episode 193.000000, reward total was -20.000000. running mean: -20.453826\n",
            "resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.449288\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.454795\n",
            "resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.460247\n",
            "resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.465645\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.470988\n",
            "resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.476278\n",
            "resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.481515\n",
            "resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.476700\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.481933\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.487114\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.492243\n",
            "resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.497320\n",
            "resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.502347\n",
            "resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.507324\n",
            "resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.512250\n",
            "resetting env. episode 209.000000, reward total was -20.000000. running mean: -20.507128\n",
            "resetting env. episode 210.000000, reward total was -19.000000. running mean: -20.492057\n",
            "resetting env. episode 211.000000, reward total was -19.000000. running mean: -20.477136\n",
            "resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.482365\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.487541\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.492666\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.487739\n",
            "resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.492862\n",
            "resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.497933\n",
            "resetting env. episode 218.000000, reward total was -18.000000. running mean: -20.472954\n",
            "resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.478224\n",
            "resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.473442\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.478708\n",
            "resetting env. episode 222.000000, reward total was -20.000000. running mean: -20.473920\n",
            "resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.479181\n",
            "resetting env. episode 224.000000, reward total was -19.000000. running mean: -20.464389\n",
            "resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.459746\n",
            "resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.465148\n",
            "resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.470497\n",
            "resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.465792\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.471134\n",
            "resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.476422\n",
            "resetting env. episode 231.000000, reward total was -17.000000. running mean: -20.441658\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.447242\n",
            "resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.452769\n",
            "resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.458241\n",
            "resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.463659\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.469022\n",
            "resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.474332\n",
            "resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.469589\n",
            "resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.464893\n",
            "resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.470244\n",
            "resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.465542\n",
            "resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.470886\n",
            "resetting env. episode 243.000000, reward total was -19.000000. running mean: -20.456177\n",
            "resetting env. episode 244.000000, reward total was -20.000000. running mean: -20.451616\n",
            "resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.457099\n",
            "resetting env. episode 246.000000, reward total was -20.000000. running mean: -20.452528\n",
            "resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.458003\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.463423\n",
            "resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.468789\n",
            "resetting env. episode 250.000000, reward total was -19.000000. running mean: -20.454101\n",
            "resetting env. episode 251.000000, reward total was -17.000000. running mean: -20.419560\n",
            "resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.425364\n",
            "resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.421111\n",
            "resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.426900\n",
            "resetting env. episode 255.000000, reward total was -19.000000. running mean: -20.412631\n",
            "resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.418504\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.424319\n",
            "resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.430076\n",
            "resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.425775\n",
            "resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.431518\n",
            "resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.427202\n",
            "resetting env. episode 262.000000, reward total was -18.000000. running mean: -20.402930\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.408901\n",
            "resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.414812\n",
            "resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.420664\n",
            "resetting env. episode 266.000000, reward total was -19.000000. running mean: -20.406457\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.412393\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.418269\n",
            "resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.414086\n",
            "resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.419945\n",
            "resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.425746\n",
            "resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.431488\n",
            "resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.437173\n",
            "resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.442802\n",
            "resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.438374\n",
            "resetting env. episode 276.000000, reward total was -20.000000. running mean: -20.433990\n",
            "resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.439650\n",
            "resetting env. episode 278.000000, reward total was -20.000000. running mean: -20.435254\n",
            "resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.430901\n",
            "resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.436592\n",
            "resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.442226\n",
            "resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.447804\n",
            "resetting env. episode 283.000000, reward total was -19.000000. running mean: -20.433326\n",
            "resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.438993\n",
            "resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.434603\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.440257\n",
            "resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.445854\n",
            "resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.451396\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.456882\n",
            "resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.462313\n",
            "resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.467690\n",
            "resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.473013\n",
            "resetting env. episode 293.000000, reward total was -20.000000. running mean: -20.468283\n",
            "resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.463600\n",
            "resetting env. episode 295.000000, reward total was -19.000000. running mean: -20.448964\n",
            "resetting env. episode 296.000000, reward total was -19.000000. running mean: -20.434474\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.440129\n",
            "resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.435728\n",
            "resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.441371\n",
            "resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.446957\n",
            "resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.442488\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.448063\n",
            "resetting env. episode 303.000000, reward total was -19.000000. running mean: -20.433582\n",
            "resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.429246\n",
            "resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.434954\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.440604\n",
            "resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.446198\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.451736\n",
            "resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.457219\n",
            "resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.462647\n",
            "resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.458020\n",
            "resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.453440\n",
            "resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.458906\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.464317\n",
            "resetting env. episode 315.000000, reward total was -19.000000. running mean: -20.449673\n",
            "resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.445177\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.450725\n",
            "resetting env. episode 318.000000, reward total was -19.000000. running mean: -20.436218\n",
            "resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.441855\n",
            "resetting env. episode 320.000000, reward total was -20.000000. running mean: -20.437437\n",
            "resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.433062\n",
            "resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.428732\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.434445\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.440100\n",
            "resetting env. episode 325.000000, reward total was -18.000000. running mean: -20.415699\n",
            "resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.421542\n",
            "resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.427327\n",
            "resetting env. episode 328.000000, reward total was -20.000000. running mean: -20.423053\n",
            "resetting env. episode 329.000000, reward total was -20.000000. running mean: -20.418823\n",
            "resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.424635\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.430388\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.436084\n",
            "resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.431724\n",
            "resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.437406\n",
            "resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.433032\n",
            "resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.438702\n",
            "resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.434315\n",
            "resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.429972\n",
            "resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.435672\n",
            "resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.441315\n",
            "resetting env. episode 341.000000, reward total was -19.000000. running mean: -20.426902\n",
            "resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.422633\n",
            "resetting env. episode 343.000000, reward total was -19.000000. running mean: -20.408407\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.414323\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.420180\n",
            "resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.415978\n",
            "resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.411818\n",
            "resetting env. episode 348.000000, reward total was -19.000000. running mean: -20.397700\n",
            "resetting env. episode 349.000000, reward total was -19.000000. running mean: -20.383723\n",
            "resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.389886\n",
            "resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.395987\n",
            "resetting env. episode 352.000000, reward total was -20.000000. running mean: -20.392027\n",
            "resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.388107\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.394226\n",
            "resetting env. episode 355.000000, reward total was -20.000000. running mean: -20.390283\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.396380\n",
            "resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.402417\n",
            "resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.408392\n",
            "resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.414309\n",
            "resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.410165\n",
            "resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.416064\n",
            "resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.411903\n",
            "resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.417784\n",
            "resetting env. episode 364.000000, reward total was -20.000000. running mean: -20.413606\n",
            "resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.419470\n",
            "resetting env. episode 366.000000, reward total was -18.000000. running mean: -20.395276\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.401323\n",
            "resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.407310\n",
            "resetting env. episode 369.000000, reward total was -20.000000. running mean: -20.403236\n",
            "resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.409204\n",
            "resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.405112\n",
            "resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.411061\n",
            "resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.416950\n",
            "resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.422781\n",
            "resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.418553\n",
            "resetting env. episode 376.000000, reward total was -19.000000. running mean: -20.404367\n",
            "resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.410324\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.416221\n",
            "resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.422058\n",
            "resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.417838\n",
            "resetting env. episode 381.000000, reward total was -20.000000. running mean: -20.413659\n",
            "resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.419523\n",
            "resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.425328\n",
            "resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.431074\n",
            "resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.426764\n",
            "resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.432496\n",
            "resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.438171\n",
            "resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.433789\n",
            "resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.439451\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.445057\n",
            "resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.440606\n",
            "resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.446200\n",
            "resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.441738\n",
            "resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.437321\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.442948\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.448518\n",
            "resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.454033\n",
            "resetting env. episode 398.000000, reward total was -19.000000. running mean: -20.439493\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.445098\n",
            "resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.450647\n",
            "resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.456140\n",
            "resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.461579\n",
            "resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.466963\n",
            "resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.472293\n",
            "resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.477570\n",
            "resetting env. episode 406.000000, reward total was -19.000000. running mean: -20.462795\n",
            "resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.458167\n",
            "resetting env. episode 408.000000, reward total was -20.000000. running mean: -20.453585\n",
            "resetting env. episode 409.000000, reward total was -19.000000. running mean: -20.439049\n",
            "resetting env. episode 410.000000, reward total was -17.000000. running mean: -20.404659\n",
            "resetting env. episode 411.000000, reward total was -20.000000. running mean: -20.400612\n",
            "resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.396606\n",
            "resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.402640\n",
            "resetting env. episode 414.000000, reward total was -20.000000. running mean: -20.398614\n",
            "resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.394628\n",
            "resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.400681\n",
            "resetting env. episode 417.000000, reward total was -19.000000. running mean: -20.386674\n",
            "resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.382808\n",
            "resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.388980\n",
            "resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.395090\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.401139\n",
            "resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.397128\n",
            "resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.403156\n",
            "resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.409125\n",
            "resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.415033\n",
            "resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.420883\n",
            "resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.426674\n",
            "resetting env. episode 428.000000, reward total was -19.000000. running mean: -20.412408\n",
            "resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.418283\n",
            "resetting env. episode 430.000000, reward total was -17.000000. running mean: -20.384101\n",
            "resetting env. episode 431.000000, reward total was -19.000000. running mean: -20.370260\n",
            "resetting env. episode 432.000000, reward total was -19.000000. running mean: -20.356557\n",
            "resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.362991\n",
            "resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.369362\n",
            "resetting env. episode 435.000000, reward total was -19.000000. running mean: -20.355668\n",
            "resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.362111\n",
            "resetting env. episode 437.000000, reward total was -20.000000. running mean: -20.358490\n",
            "resetting env. episode 438.000000, reward total was -19.000000. running mean: -20.344905\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.351456\n",
            "resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.347942\n",
            "resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.354462\n",
            "resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.360918\n",
            "resetting env. episode 443.000000, reward total was -19.000000. running mean: -20.347308\n",
            "resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.353835\n",
            "resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.360297\n",
            "resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.356694\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.363127\n",
            "resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.369496\n",
            "resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.365801\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.372143\n",
            "resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.368421\n",
            "resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.364737\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.371090\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.377379\n",
            "resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.383605\n",
            "resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.389769\n",
            "resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.385871\n",
            "resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.392013\n",
            "resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.398093\n",
            "resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.394112\n",
            "resetting env. episode 461.000000, reward total was -19.000000. running mean: -20.380170\n",
            "resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.386369\n",
            "resetting env. episode 463.000000, reward total was -19.000000. running mean: -20.372505\n",
            "resetting env. episode 464.000000, reward total was -18.000000. running mean: -20.348780\n",
            "resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.355292\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.361739\n",
            "resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.358122\n",
            "resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.364541\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.370895\n",
            "resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.367186\n",
            "resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.373514\n",
            "resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.379779\n",
            "resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.385982\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.392122\n",
            "resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.398201\n",
            "resetting env. episode 476.000000, reward total was -19.000000. running mean: -20.384219\n",
            "resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.390376\n",
            "resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.396473\n",
            "resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.402508\n",
            "resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.398483\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.404498\n",
            "resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.410453\n",
            "resetting env. episode 483.000000, reward total was -20.000000. running mean: -20.406348\n",
            "resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.412285\n",
            "resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.418162\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.423980\n",
            "resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.429741\n",
            "resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.435443\n",
            "resetting env. episode 489.000000, reward total was -19.000000. running mean: -20.421089\n",
            "resetting env. episode 490.000000, reward total was -19.000000. running mean: -20.406878\n",
            "resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.412809\n",
            "resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.408681\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.404594\n",
            "resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.410548\n",
            "resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.416443\n",
            "resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.412278\n",
            "resetting env. episode 497.000000, reward total was -20.000000. running mean: -20.408156\n",
            "resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.414074\n",
            "resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.409933\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.415834\n",
            "resetting env. episode 501.000000, reward total was -20.000000. running mean: -20.411676\n",
            "resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.417559\n",
            "resetting env. episode 503.000000, reward total was -21.000000. running mean: -20.423383\n",
            "resetting env. episode 504.000000, reward total was -17.000000. running mean: -20.389149\n",
            "resetting env. episode 505.000000, reward total was -21.000000. running mean: -20.395258\n",
            "resetting env. episode 506.000000, reward total was -20.000000. running mean: -20.391305\n",
            "resetting env. episode 507.000000, reward total was -20.000000. running mean: -20.387392\n",
            "resetting env. episode 508.000000, reward total was -19.000000. running mean: -20.373518\n",
            "resetting env. episode 509.000000, reward total was -20.000000. running mean: -20.369783\n",
            "resetting env. episode 510.000000, reward total was -21.000000. running mean: -20.376085\n",
            "resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.382325\n",
            "resetting env. episode 512.000000, reward total was -21.000000. running mean: -20.388501\n",
            "resetting env. episode 513.000000, reward total was -20.000000. running mean: -20.384616\n",
            "resetting env. episode 514.000000, reward total was -20.000000. running mean: -20.380770\n",
            "resetting env. episode 515.000000, reward total was -21.000000. running mean: -20.386962\n",
            "resetting env. episode 516.000000, reward total was -21.000000. running mean: -20.393093\n",
            "resetting env. episode 517.000000, reward total was -21.000000. running mean: -20.399162\n",
            "resetting env. episode 518.000000, reward total was -18.000000. running mean: -20.375170\n",
            "resetting env. episode 519.000000, reward total was -21.000000. running mean: -20.381419\n",
            "resetting env. episode 520.000000, reward total was -21.000000. running mean: -20.387604\n",
            "resetting env. episode 521.000000, reward total was -20.000000. running mean: -20.383728\n",
            "resetting env. episode 522.000000, reward total was -21.000000. running mean: -20.389891\n",
            "resetting env. episode 523.000000, reward total was -18.000000. running mean: -20.365992\n",
            "resetting env. episode 524.000000, reward total was -21.000000. running mean: -20.372332\n",
            "resetting env. episode 525.000000, reward total was -21.000000. running mean: -20.378609\n",
            "resetting env. episode 526.000000, reward total was -17.000000. running mean: -20.344823\n",
            "resetting env. episode 527.000000, reward total was -21.000000. running mean: -20.351375\n",
            "resetting env. episode 528.000000, reward total was -20.000000. running mean: -20.347861\n",
            "resetting env. episode 529.000000, reward total was -21.000000. running mean: -20.354382\n",
            "resetting env. episode 530.000000, reward total was -20.000000. running mean: -20.350838\n",
            "resetting env. episode 531.000000, reward total was -19.000000. running mean: -20.337330\n",
            "resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.343957\n",
            "resetting env. episode 533.000000, reward total was -20.000000. running mean: -20.340517\n",
            "resetting env. episode 534.000000, reward total was -20.000000. running mean: -20.337112\n",
            "resetting env. episode 535.000000, reward total was -20.000000. running mean: -20.333741\n",
            "resetting env. episode 536.000000, reward total was -21.000000. running mean: -20.340403\n",
            "resetting env. episode 537.000000, reward total was -21.000000. running mean: -20.346999\n",
            "resetting env. episode 538.000000, reward total was -20.000000. running mean: -20.343529\n",
            "resetting env. episode 539.000000, reward total was -21.000000. running mean: -20.350094\n",
            "resetting env. episode 540.000000, reward total was -19.000000. running mean: -20.336593\n",
            "resetting env. episode 541.000000, reward total was -21.000000. running mean: -20.343227\n",
            "resetting env. episode 542.000000, reward total was -21.000000. running mean: -20.349795\n",
            "resetting env. episode 543.000000, reward total was -19.000000. running mean: -20.336297\n",
            "resetting env. episode 544.000000, reward total was -21.000000. running mean: -20.342934\n",
            "resetting env. episode 545.000000, reward total was -20.000000. running mean: -20.339505\n",
            "resetting env. episode 546.000000, reward total was -20.000000. running mean: -20.336110\n",
            "resetting env. episode 547.000000, reward total was -21.000000. running mean: -20.342749\n",
            "resetting env. episode 548.000000, reward total was -21.000000. running mean: -20.349321\n",
            "resetting env. episode 549.000000, reward total was -21.000000. running mean: -20.355828\n",
            "resetting env. episode 550.000000, reward total was -20.000000. running mean: -20.352270\n",
            "resetting env. episode 551.000000, reward total was -20.000000. running mean: -20.348747\n",
            "resetting env. episode 552.000000, reward total was -21.000000. running mean: -20.355259\n",
            "resetting env. episode 553.000000, reward total was -21.000000. running mean: -20.361707\n",
            "resetting env. episode 554.000000, reward total was -21.000000. running mean: -20.368090\n",
            "resetting env. episode 555.000000, reward total was -19.000000. running mean: -20.354409\n",
            "resetting env. episode 556.000000, reward total was -19.000000. running mean: -20.340865\n",
            "resetting env. episode 557.000000, reward total was -21.000000. running mean: -20.347456\n",
            "resetting env. episode 558.000000, reward total was -21.000000. running mean: -20.353982\n",
            "resetting env. episode 559.000000, reward total was -21.000000. running mean: -20.360442\n",
            "resetting env. episode 560.000000, reward total was -21.000000. running mean: -20.366837\n",
            "resetting env. episode 561.000000, reward total was -21.000000. running mean: -20.373169\n",
            "resetting env. episode 562.000000, reward total was -20.000000. running mean: -20.369437\n",
            "resetting env. episode 563.000000, reward total was -21.000000. running mean: -20.375743\n",
            "resetting env. episode 564.000000, reward total was -20.000000. running mean: -20.371985\n",
            "resetting env. episode 565.000000, reward total was -21.000000. running mean: -20.378266\n",
            "resetting env. episode 566.000000, reward total was -20.000000. running mean: -20.374483\n",
            "resetting env. episode 567.000000, reward total was -20.000000. running mean: -20.370738\n",
            "resetting env. episode 568.000000, reward total was -21.000000. running mean: -20.377031\n",
            "resetting env. episode 569.000000, reward total was -21.000000. running mean: -20.383260\n",
            "resetting env. episode 570.000000, reward total was -20.000000. running mean: -20.379428\n",
            "resetting env. episode 571.000000, reward total was -20.000000. running mean: -20.375634\n",
            "resetting env. episode 572.000000, reward total was -21.000000. running mean: -20.381877\n",
            "resetting env. episode 573.000000, reward total was -19.000000. running mean: -20.368058\n",
            "resetting env. episode 574.000000, reward total was -21.000000. running mean: -20.374378\n",
            "resetting env. episode 575.000000, reward total was -20.000000. running mean: -20.370634\n",
            "resetting env. episode 576.000000, reward total was -20.000000. running mean: -20.366928\n",
            "resetting env. episode 577.000000, reward total was -21.000000. running mean: -20.373258\n",
            "resetting env. episode 578.000000, reward total was -20.000000. running mean: -20.369526\n",
            "resetting env. episode 579.000000, reward total was -21.000000. running mean: -20.375831\n",
            "resetting env. episode 580.000000, reward total was -21.000000. running mean: -20.382072\n",
            "resetting env. episode 581.000000, reward total was -21.000000. running mean: -20.388252\n",
            "resetting env. episode 582.000000, reward total was -21.000000. running mean: -20.394369\n",
            "resetting env. episode 583.000000, reward total was -19.000000. running mean: -20.380425\n",
            "resetting env. episode 584.000000, reward total was -21.000000. running mean: -20.386621\n",
            "resetting env. episode 585.000000, reward total was -20.000000. running mean: -20.382755\n",
            "resetting env. episode 586.000000, reward total was -21.000000. running mean: -20.388927\n",
            "resetting env. episode 587.000000, reward total was -21.000000. running mean: -20.395038\n",
            "resetting env. episode 588.000000, reward total was -21.000000. running mean: -20.401088\n",
            "resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.407077\n",
            "resetting env. episode 590.000000, reward total was -20.000000. running mean: -20.403006\n",
            "resetting env. episode 591.000000, reward total was -20.000000. running mean: -20.398976\n",
            "resetting env. episode 592.000000, reward total was -21.000000. running mean: -20.404986\n",
            "resetting env. episode 593.000000, reward total was -20.000000. running mean: -20.400936\n",
            "resetting env. episode 594.000000, reward total was -19.000000. running mean: -20.386927\n",
            "resetting env. episode 595.000000, reward total was -21.000000. running mean: -20.393058\n",
            "resetting env. episode 596.000000, reward total was -21.000000. running mean: -20.399127\n",
            "resetting env. episode 597.000000, reward total was -20.000000. running mean: -20.395136\n",
            "resetting env. episode 598.000000, reward total was -21.000000. running mean: -20.401185\n",
            "resetting env. episode 599.000000, reward total was -21.000000. running mean: -20.407173\n",
            "resetting env. episode 600.000000, reward total was -20.000000. running mean: -20.403101\n",
            "resetting env. episode 601.000000, reward total was -21.000000. running mean: -20.409070\n",
            "resetting env. episode 602.000000, reward total was -20.000000. running mean: -20.404979\n",
            "resetting env. episode 603.000000, reward total was -19.000000. running mean: -20.390929\n",
            "resetting env. episode 604.000000, reward total was -21.000000. running mean: -20.397020\n",
            "resetting env. episode 605.000000, reward total was -21.000000. running mean: -20.403050\n",
            "resetting env. episode 606.000000, reward total was -20.000000. running mean: -20.399019\n",
            "resetting env. episode 607.000000, reward total was -21.000000. running mean: -20.405029\n",
            "resetting env. episode 608.000000, reward total was -19.000000. running mean: -20.390979\n",
            "resetting env. episode 609.000000, reward total was -21.000000. running mean: -20.397069\n",
            "resetting env. episode 610.000000, reward total was -21.000000. running mean: -20.403099\n",
            "resetting env. episode 611.000000, reward total was -21.000000. running mean: -20.409068\n",
            "resetting env. episode 612.000000, reward total was -21.000000. running mean: -20.414977\n",
            "resetting env. episode 613.000000, reward total was -21.000000. running mean: -20.420827\n",
            "resetting env. episode 614.000000, reward total was -21.000000. running mean: -20.426619\n",
            "resetting env. episode 615.000000, reward total was -16.000000. running mean: -20.382353\n",
            "resetting env. episode 616.000000, reward total was -21.000000. running mean: -20.388529\n",
            "resetting env. episode 617.000000, reward total was -21.000000. running mean: -20.394644\n",
            "resetting env. episode 618.000000, reward total was -21.000000. running mean: -20.400697\n",
            "resetting env. episode 619.000000, reward total was -20.000000. running mean: -20.396690\n",
            "resetting env. episode 620.000000, reward total was -21.000000. running mean: -20.402723\n",
            "resetting env. episode 621.000000, reward total was -21.000000. running mean: -20.408696\n",
            "resetting env. episode 622.000000, reward total was -20.000000. running mean: -20.404609\n",
            "resetting env. episode 623.000000, reward total was -21.000000. running mean: -20.410563\n",
            "resetting env. episode 624.000000, reward total was -18.000000. running mean: -20.386458\n",
            "resetting env. episode 625.000000, reward total was -21.000000. running mean: -20.392593\n",
            "resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.398667\n",
            "resetting env. episode 627.000000, reward total was -21.000000. running mean: -20.404680\n",
            "resetting env. episode 628.000000, reward total was -20.000000. running mean: -20.400634\n",
            "resetting env. episode 629.000000, reward total was -20.000000. running mean: -20.396627\n",
            "resetting env. episode 630.000000, reward total was -20.000000. running mean: -20.392661\n",
            "resetting env. episode 631.000000, reward total was -18.000000. running mean: -20.368734\n",
            "resetting env. episode 632.000000, reward total was -21.000000. running mean: -20.375047\n",
            "resetting env. episode 633.000000, reward total was -21.000000. running mean: -20.381297\n",
            "resetting env. episode 634.000000, reward total was -20.000000. running mean: -20.377484\n",
            "resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.383709\n",
            "resetting env. episode 636.000000, reward total was -20.000000. running mean: -20.379872\n",
            "resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.386073\n",
            "resetting env. episode 638.000000, reward total was -17.000000. running mean: -20.352212\n",
            "resetting env. episode 639.000000, reward total was -20.000000. running mean: -20.348690\n",
            "resetting env. episode 640.000000, reward total was -19.000000. running mean: -20.335203\n",
            "resetting env. episode 641.000000, reward total was -19.000000. running mean: -20.321851\n",
            "resetting env. episode 642.000000, reward total was -21.000000. running mean: -20.328633\n",
            "resetting env. episode 643.000000, reward total was -21.000000. running mean: -20.335346\n",
            "resetting env. episode 644.000000, reward total was -21.000000. running mean: -20.341993\n",
            "resetting env. episode 645.000000, reward total was -20.000000. running mean: -20.338573\n",
            "resetting env. episode 646.000000, reward total was -21.000000. running mean: -20.345187\n",
            "resetting env. episode 647.000000, reward total was -21.000000. running mean: -20.351735\n",
            "resetting env. episode 648.000000, reward total was -21.000000. running mean: -20.358218\n",
            "resetting env. episode 649.000000, reward total was -19.000000. running mean: -20.344636\n",
            "resetting env. episode 650.000000, reward total was -21.000000. running mean: -20.351189\n",
            "resetting env. episode 651.000000, reward total was -21.000000. running mean: -20.357678\n",
            "resetting env. episode 652.000000, reward total was -21.000000. running mean: -20.364101\n",
            "resetting env. episode 653.000000, reward total was -21.000000. running mean: -20.370460\n",
            "resetting env. episode 654.000000, reward total was -21.000000. running mean: -20.376755\n",
            "resetting env. episode 655.000000, reward total was -20.000000. running mean: -20.372988\n",
            "resetting env. episode 656.000000, reward total was -20.000000. running mean: -20.369258\n",
            "resetting env. episode 657.000000, reward total was -20.000000. running mean: -20.365565\n",
            "resetting env. episode 658.000000, reward total was -21.000000. running mean: -20.371910\n",
            "resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.378190\n",
            "resetting env. episode 660.000000, reward total was -21.000000. running mean: -20.384409\n",
            "resetting env. episode 661.000000, reward total was -21.000000. running mean: -20.390564\n",
            "resetting env. episode 662.000000, reward total was -21.000000. running mean: -20.396659\n",
            "resetting env. episode 663.000000, reward total was -21.000000. running mean: -20.402692\n",
            "resetting env. episode 664.000000, reward total was -20.000000. running mean: -20.398665\n",
            "resetting env. episode 665.000000, reward total was -21.000000. running mean: -20.404679\n",
            "resetting env. episode 666.000000, reward total was -21.000000. running mean: -20.410632\n",
            "resetting env. episode 667.000000, reward total was -21.000000. running mean: -20.416526\n",
            "resetting env. episode 668.000000, reward total was -20.000000. running mean: -20.412360\n",
            "resetting env. episode 669.000000, reward total was -20.000000. running mean: -20.408237\n",
            "resetting env. episode 670.000000, reward total was -20.000000. running mean: -20.404154\n",
            "resetting env. episode 671.000000, reward total was -21.000000. running mean: -20.410113\n",
            "resetting env. episode 672.000000, reward total was -21.000000. running mean: -20.416012\n",
            "resetting env. episode 673.000000, reward total was -20.000000. running mean: -20.411852\n",
            "resetting env. episode 674.000000, reward total was -21.000000. running mean: -20.417733\n",
            "resetting env. episode 675.000000, reward total was -21.000000. running mean: -20.423556\n",
            "resetting env. episode 676.000000, reward total was -21.000000. running mean: -20.429320\n",
            "resetting env. episode 677.000000, reward total was -20.000000. running mean: -20.425027\n",
            "resetting env. episode 678.000000, reward total was -19.000000. running mean: -20.410777\n",
            "resetting env. episode 679.000000, reward total was -19.000000. running mean: -20.396669\n",
            "resetting env. episode 680.000000, reward total was -21.000000. running mean: -20.402702\n",
            "resetting env. episode 681.000000, reward total was -21.000000. running mean: -20.408675\n",
            "resetting env. episode 682.000000, reward total was -21.000000. running mean: -20.414588\n",
            "resetting env. episode 683.000000, reward total was -21.000000. running mean: -20.420443\n",
            "resetting env. episode 684.000000, reward total was -20.000000. running mean: -20.416238\n",
            "resetting env. episode 685.000000, reward total was -21.000000. running mean: -20.422076\n",
            "resetting env. episode 686.000000, reward total was -20.000000. running mean: -20.417855\n",
            "resetting env. episode 687.000000, reward total was -21.000000. running mean: -20.423676\n",
            "resetting env. episode 688.000000, reward total was -20.000000. running mean: -20.419440\n",
            "resetting env. episode 689.000000, reward total was -21.000000. running mean: -20.425245\n",
            "resetting env. episode 690.000000, reward total was -20.000000. running mean: -20.420993\n",
            "resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.426783\n",
            "resetting env. episode 692.000000, reward total was -19.000000. running mean: -20.412515\n",
            "resetting env. episode 693.000000, reward total was -20.000000. running mean: -20.408390\n",
            "resetting env. episode 694.000000, reward total was -21.000000. running mean: -20.414306\n",
            "resetting env. episode 695.000000, reward total was -20.000000. running mean: -20.410163\n",
            "resetting env. episode 696.000000, reward total was -21.000000. running mean: -20.416061\n",
            "resetting env. episode 697.000000, reward total was -21.000000. running mean: -20.421901\n",
            "resetting env. episode 698.000000, reward total was -20.000000. running mean: -20.417682\n",
            "resetting env. episode 699.000000, reward total was -21.000000. running mean: -20.423505\n",
            "resetting env. episode 700.000000, reward total was -20.000000. running mean: -20.419270\n",
            "resetting env. episode 701.000000, reward total was -20.000000. running mean: -20.415077\n",
            "resetting env. episode 702.000000, reward total was -21.000000. running mean: -20.420926\n",
            "resetting env. episode 703.000000, reward total was -21.000000. running mean: -20.426717\n",
            "resetting env. episode 704.000000, reward total was -21.000000. running mean: -20.432450\n",
            "resetting env. episode 705.000000, reward total was -21.000000. running mean: -20.438125\n",
            "resetting env. episode 706.000000, reward total was -21.000000. running mean: -20.443744\n",
            "resetting env. episode 707.000000, reward total was -21.000000. running mean: -20.449307\n",
            "resetting env. episode 708.000000, reward total was -21.000000. running mean: -20.454814\n",
            "resetting env. episode 709.000000, reward total was -21.000000. running mean: -20.460266\n",
            "resetting env. episode 710.000000, reward total was -21.000000. running mean: -20.465663\n",
            "resetting env. episode 711.000000, reward total was -21.000000. running mean: -20.471006\n",
            "resetting env. episode 712.000000, reward total was -21.000000. running mean: -20.476296\n",
            "resetting env. episode 713.000000, reward total was -20.000000. running mean: -20.471533\n",
            "resetting env. episode 714.000000, reward total was -20.000000. running mean: -20.466818\n",
            "resetting env. episode 715.000000, reward total was -21.000000. running mean: -20.472150\n",
            "resetting env. episode 716.000000, reward total was -21.000000. running mean: -20.477428\n",
            "resetting env. episode 717.000000, reward total was -21.000000. running mean: -20.482654\n",
            "resetting env. episode 718.000000, reward total was -19.000000. running mean: -20.467827\n",
            "resetting env. episode 719.000000, reward total was -18.000000. running mean: -20.443149\n",
            "resetting env. episode 720.000000, reward total was -21.000000. running mean: -20.448718\n",
            "resetting env. episode 721.000000, reward total was -21.000000. running mean: -20.454230\n",
            "resetting env. episode 722.000000, reward total was -21.000000. running mean: -20.459688\n",
            "resetting env. episode 723.000000, reward total was -21.000000. running mean: -20.465091\n",
            "resetting env. episode 724.000000, reward total was -21.000000. running mean: -20.470440\n",
            "resetting env. episode 725.000000, reward total was -21.000000. running mean: -20.475736\n",
            "resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.480979\n",
            "resetting env. episode 727.000000, reward total was -21.000000. running mean: -20.486169\n",
            "resetting env. episode 728.000000, reward total was -19.000000. running mean: -20.471307\n",
            "resetting env. episode 729.000000, reward total was -20.000000. running mean: -20.466594\n",
            "resetting env. episode 730.000000, reward total was -21.000000. running mean: -20.471928\n",
            "resetting env. episode 731.000000, reward total was -21.000000. running mean: -20.477209\n",
            "resetting env. episode 732.000000, reward total was -20.000000. running mean: -20.472437\n",
            "resetting env. episode 733.000000, reward total was -20.000000. running mean: -20.467712\n",
            "resetting env. episode 734.000000, reward total was -21.000000. running mean: -20.473035\n",
            "resetting env. episode 735.000000, reward total was -21.000000. running mean: -20.478305\n",
            "resetting env. episode 736.000000, reward total was -21.000000. running mean: -20.483522\n",
            "resetting env. episode 737.000000, reward total was -21.000000. running mean: -20.488687\n",
            "resetting env. episode 738.000000, reward total was -19.000000. running mean: -20.473800\n",
            "resetting env. episode 739.000000, reward total was -21.000000. running mean: -20.479062\n",
            "resetting env. episode 740.000000, reward total was -20.000000. running mean: -20.474271\n",
            "resetting env. episode 741.000000, reward total was -19.000000. running mean: -20.459528\n",
            "resetting env. episode 742.000000, reward total was -20.000000. running mean: -20.454933\n",
            "resetting env. episode 743.000000, reward total was -20.000000. running mean: -20.450384\n",
            "resetting env. episode 744.000000, reward total was -20.000000. running mean: -20.445880\n",
            "resetting env. episode 745.000000, reward total was -21.000000. running mean: -20.451421\n",
            "resetting env. episode 746.000000, reward total was -21.000000. running mean: -20.456907\n",
            "resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.462338\n",
            "resetting env. episode 748.000000, reward total was -21.000000. running mean: -20.467715\n",
            "resetting env. episode 749.000000, reward total was -21.000000. running mean: -20.473037\n",
            "resetting env. episode 750.000000, reward total was -21.000000. running mean: -20.478307\n",
            "resetting env. episode 751.000000, reward total was -21.000000. running mean: -20.483524\n",
            "resetting env. episode 752.000000, reward total was -21.000000. running mean: -20.488689\n",
            "resetting env. episode 753.000000, reward total was -21.000000. running mean: -20.493802\n",
            "resetting env. episode 754.000000, reward total was -18.000000. running mean: -20.468864\n",
            "resetting env. episode 755.000000, reward total was -21.000000. running mean: -20.474175\n",
            "resetting env. episode 756.000000, reward total was -20.000000. running mean: -20.469433\n",
            "resetting env. episode 757.000000, reward total was -21.000000. running mean: -20.474739\n",
            "resetting env. episode 758.000000, reward total was -18.000000. running mean: -20.449992\n",
            "resetting env. episode 759.000000, reward total was -21.000000. running mean: -20.455492\n",
            "resetting env. episode 760.000000, reward total was -19.000000. running mean: -20.440937\n",
            "resetting env. episode 761.000000, reward total was -21.000000. running mean: -20.446527\n",
            "resetting env. episode 762.000000, reward total was -20.000000. running mean: -20.442062\n",
            "resetting env. episode 763.000000, reward total was -21.000000. running mean: -20.447642\n",
            "resetting env. episode 764.000000, reward total was -21.000000. running mean: -20.453165\n",
            "resetting env. episode 765.000000, reward total was -21.000000. running mean: -20.458633\n",
            "resetting env. episode 766.000000, reward total was -20.000000. running mean: -20.454047\n",
            "resetting env. episode 767.000000, reward total was -20.000000. running mean: -20.449507\n",
            "resetting env. episode 768.000000, reward total was -20.000000. running mean: -20.445012\n",
            "resetting env. episode 769.000000, reward total was -20.000000. running mean: -20.440562\n",
            "resetting env. episode 770.000000, reward total was -21.000000. running mean: -20.446156\n",
            "resetting env. episode 771.000000, reward total was -21.000000. running mean: -20.451694\n",
            "resetting env. episode 772.000000, reward total was -20.000000. running mean: -20.447177\n",
            "resetting env. episode 773.000000, reward total was -21.000000. running mean: -20.452706\n",
            "resetting env. episode 774.000000, reward total was -19.000000. running mean: -20.438179\n",
            "resetting env. episode 775.000000, reward total was -19.000000. running mean: -20.423797\n",
            "resetting env. episode 776.000000, reward total was -20.000000. running mean: -20.419559\n",
            "resetting env. episode 777.000000, reward total was -21.000000. running mean: -20.425363\n",
            "resetting env. episode 778.000000, reward total was -21.000000. running mean: -20.431110\n",
            "resetting env. episode 779.000000, reward total was -20.000000. running mean: -20.426798\n",
            "resetting env. episode 780.000000, reward total was -21.000000. running mean: -20.432531\n",
            "resetting env. episode 781.000000, reward total was -20.000000. running mean: -20.428205\n",
            "resetting env. episode 782.000000, reward total was -21.000000. running mean: -20.433923\n",
            "resetting env. episode 783.000000, reward total was -21.000000. running mean: -20.439584\n",
            "resetting env. episode 784.000000, reward total was -21.000000. running mean: -20.445188\n",
            "resetting env. episode 785.000000, reward total was -21.000000. running mean: -20.450736\n",
            "resetting env. episode 786.000000, reward total was -21.000000. running mean: -20.456229\n",
            "resetting env. episode 787.000000, reward total was -20.000000. running mean: -20.451667\n",
            "resetting env. episode 788.000000, reward total was -21.000000. running mean: -20.457150\n",
            "resetting env. episode 789.000000, reward total was -21.000000. running mean: -20.462578\n",
            "resetting env. episode 790.000000, reward total was -20.000000. running mean: -20.457953\n",
            "resetting env. episode 791.000000, reward total was -21.000000. running mean: -20.463373\n",
            "resetting env. episode 792.000000, reward total was -20.000000. running mean: -20.458739\n",
            "resetting env. episode 793.000000, reward total was -20.000000. running mean: -20.454152\n",
            "resetting env. episode 794.000000, reward total was -21.000000. running mean: -20.459610\n",
            "resetting env. episode 795.000000, reward total was -21.000000. running mean: -20.465014\n",
            "resetting env. episode 796.000000, reward total was -20.000000. running mean: -20.460364\n",
            "resetting env. episode 797.000000, reward total was -20.000000. running mean: -20.455761\n",
            "resetting env. episode 798.000000, reward total was -20.000000. running mean: -20.451203\n",
            "resetting env. episode 799.000000, reward total was -19.000000. running mean: -20.436691\n",
            "resetting env. episode 800.000000, reward total was -20.000000. running mean: -20.432324\n",
            "resetting env. episode 801.000000, reward total was -21.000000. running mean: -20.438001\n",
            "resetting env. episode 802.000000, reward total was -21.000000. running mean: -20.443621\n",
            "resetting env. episode 803.000000, reward total was -21.000000. running mean: -20.449185\n",
            "resetting env. episode 804.000000, reward total was -21.000000. running mean: -20.454693\n",
            "resetting env. episode 805.000000, reward total was -20.000000. running mean: -20.450146\n",
            "resetting env. episode 806.000000, reward total was -21.000000. running mean: -20.455644\n",
            "resetting env. episode 807.000000, reward total was -20.000000. running mean: -20.451088\n",
            "resetting env. episode 808.000000, reward total was -20.000000. running mean: -20.446577\n",
            "resetting env. episode 809.000000, reward total was -21.000000. running mean: -20.452111\n",
            "resetting env. episode 810.000000, reward total was -21.000000. running mean: -20.457590\n",
            "resetting env. episode 811.000000, reward total was -20.000000. running mean: -20.453014\n",
            "resetting env. episode 812.000000, reward total was -21.000000. running mean: -20.458484\n",
            "resetting env. episode 813.000000, reward total was -21.000000. running mean: -20.463899\n",
            "resetting env. episode 814.000000, reward total was -21.000000. running mean: -20.469260\n",
            "resetting env. episode 815.000000, reward total was -20.000000. running mean: -20.464568\n",
            "resetting env. episode 816.000000, reward total was -21.000000. running mean: -20.469922\n",
            "resetting env. episode 817.000000, reward total was -21.000000. running mean: -20.475223\n",
            "resetting env. episode 818.000000, reward total was -21.000000. running mean: -20.480471\n",
            "resetting env. episode 819.000000, reward total was -21.000000. running mean: -20.485666\n",
            "resetting env. episode 820.000000, reward total was -21.000000. running mean: -20.490809\n",
            "resetting env. episode 821.000000, reward total was -21.000000. running mean: -20.495901\n",
            "resetting env. episode 822.000000, reward total was -20.000000. running mean: -20.490942\n",
            "resetting env. episode 823.000000, reward total was -21.000000. running mean: -20.496033\n",
            "resetting env. episode 824.000000, reward total was -20.000000. running mean: -20.491072\n",
            "resetting env. episode 825.000000, reward total was -21.000000. running mean: -20.496162\n",
            "resetting env. episode 826.000000, reward total was -20.000000. running mean: -20.491200\n",
            "resetting env. episode 827.000000, reward total was -21.000000. running mean: -20.496288\n",
            "resetting env. episode 828.000000, reward total was -19.000000. running mean: -20.481325\n",
            "resetting env. episode 829.000000, reward total was -21.000000. running mean: -20.486512\n",
            "resetting env. episode 830.000000, reward total was -20.000000. running mean: -20.481647\n",
            "resetting env. episode 831.000000, reward total was -21.000000. running mean: -20.486830\n",
            "resetting env. episode 832.000000, reward total was -21.000000. running mean: -20.491962\n",
            "resetting env. episode 833.000000, reward total was -21.000000. running mean: -20.497042\n",
            "resetting env. episode 834.000000, reward total was -19.000000. running mean: -20.482072\n",
            "resetting env. episode 835.000000, reward total was -20.000000. running mean: -20.477251\n",
            "resetting env. episode 836.000000, reward total was -20.000000. running mean: -20.472479\n",
            "resetting env. episode 837.000000, reward total was -19.000000. running mean: -20.457754\n",
            "resetting env. episode 838.000000, reward total was -19.000000. running mean: -20.443176\n",
            "resetting env. episode 839.000000, reward total was -17.000000. running mean: -20.408745\n",
            "resetting env. episode 840.000000, reward total was -21.000000. running mean: -20.414657\n",
            "resetting env. episode 841.000000, reward total was -21.000000. running mean: -20.420511\n",
            "resetting env. episode 842.000000, reward total was -18.000000. running mean: -20.396305\n",
            "resetting env. episode 843.000000, reward total was -20.000000. running mean: -20.392342\n",
            "resetting env. episode 844.000000, reward total was -21.000000. running mean: -20.398419\n",
            "resetting env. episode 845.000000, reward total was -21.000000. running mean: -20.404435\n",
            "resetting env. episode 846.000000, reward total was -20.000000. running mean: -20.400390\n",
            "resetting env. episode 847.000000, reward total was -21.000000. running mean: -20.406387\n",
            "resetting env. episode 848.000000, reward total was -19.000000. running mean: -20.392323\n",
            "resetting env. episode 849.000000, reward total was -20.000000. running mean: -20.388399\n",
            "resetting env. episode 850.000000, reward total was -21.000000. running mean: -20.394515\n",
            "resetting env. episode 851.000000, reward total was -20.000000. running mean: -20.390570\n",
            "resetting env. episode 852.000000, reward total was -21.000000. running mean: -20.396665\n",
            "resetting env. episode 853.000000, reward total was -21.000000. running mean: -20.402698\n",
            "resetting env. episode 854.000000, reward total was -21.000000. running mean: -20.408671\n",
            "resetting env. episode 855.000000, reward total was -21.000000. running mean: -20.414584\n",
            "resetting env. episode 856.000000, reward total was -21.000000. running mean: -20.420438\n",
            "resetting env. episode 857.000000, reward total was -21.000000. running mean: -20.426234\n",
            "resetting env. episode 858.000000, reward total was -21.000000. running mean: -20.431972\n",
            "resetting env. episode 859.000000, reward total was -21.000000. running mean: -20.437652\n",
            "resetting env. episode 860.000000, reward total was -21.000000. running mean: -20.443275\n",
            "resetting env. episode 861.000000, reward total was -20.000000. running mean: -20.438843\n",
            "resetting env. episode 862.000000, reward total was -21.000000. running mean: -20.444454\n",
            "resetting env. episode 863.000000, reward total was -21.000000. running mean: -20.450010\n",
            "resetting env. episode 864.000000, reward total was -19.000000. running mean: -20.435510\n",
            "resetting env. episode 865.000000, reward total was -21.000000. running mean: -20.441155\n",
            "resetting env. episode 866.000000, reward total was -21.000000. running mean: -20.446743\n",
            "resetting env. episode 867.000000, reward total was -18.000000. running mean: -20.422276\n",
            "resetting env. episode 868.000000, reward total was -20.000000. running mean: -20.418053\n",
            "resetting env. episode 869.000000, reward total was -21.000000. running mean: -20.423872\n",
            "resetting env. episode 870.000000, reward total was -20.000000. running mean: -20.419634\n",
            "resetting env. episode 871.000000, reward total was -21.000000. running mean: -20.425437\n",
            "resetting env. episode 872.000000, reward total was -21.000000. running mean: -20.431183\n",
            "resetting env. episode 873.000000, reward total was -19.000000. running mean: -20.416871\n",
            "resetting env. episode 874.000000, reward total was -20.000000. running mean: -20.412702\n",
            "resetting env. episode 875.000000, reward total was -21.000000. running mean: -20.418575\n",
            "resetting env. episode 876.000000, reward total was -20.000000. running mean: -20.414390\n",
            "resetting env. episode 877.000000, reward total was -21.000000. running mean: -20.420246\n",
            "resetting env. episode 878.000000, reward total was -20.000000. running mean: -20.416043\n",
            "resetting env. episode 879.000000, reward total was -20.000000. running mean: -20.411883\n",
            "resetting env. episode 880.000000, reward total was -19.000000. running mean: -20.397764\n",
            "resetting env. episode 881.000000, reward total was -20.000000. running mean: -20.393786\n",
            "resetting env. episode 882.000000, reward total was -21.000000. running mean: -20.399848\n",
            "resetting env. episode 883.000000, reward total was -21.000000. running mean: -20.405850\n",
            "resetting env. episode 884.000000, reward total was -19.000000. running mean: -20.391791\n",
            "resetting env. episode 885.000000, reward total was -21.000000. running mean: -20.397874\n",
            "resetting env. episode 886.000000, reward total was -20.000000. running mean: -20.393895\n",
            "resetting env. episode 887.000000, reward total was -19.000000. running mean: -20.379956\n",
            "resetting env. episode 888.000000, reward total was -21.000000. running mean: -20.386156\n",
            "resetting env. episode 889.000000, reward total was -21.000000. running mean: -20.392295\n",
            "resetting env. episode 890.000000, reward total was -21.000000. running mean: -20.398372\n",
            "resetting env. episode 891.000000, reward total was -21.000000. running mean: -20.404388\n",
            "resetting env. episode 892.000000, reward total was -21.000000. running mean: -20.410344\n",
            "resetting env. episode 893.000000, reward total was -21.000000. running mean: -20.416241\n",
            "resetting env. episode 894.000000, reward total was -19.000000. running mean: -20.402078\n",
            "resetting env. episode 895.000000, reward total was -21.000000. running mean: -20.408058\n",
            "resetting env. episode 896.000000, reward total was -21.000000. running mean: -20.413977\n",
            "resetting env. episode 897.000000, reward total was -21.000000. running mean: -20.419837\n",
            "resetting env. episode 898.000000, reward total was -21.000000. running mean: -20.425639\n",
            "resetting env. episode 899.000000, reward total was -21.000000. running mean: -20.431382\n",
            "resetting env. episode 900.000000, reward total was -20.000000. running mean: -20.427069\n",
            "resetting env. episode 901.000000, reward total was -19.000000. running mean: -20.412798\n",
            "resetting env. episode 902.000000, reward total was -21.000000. running mean: -20.418670\n",
            "resetting env. episode 903.000000, reward total was -20.000000. running mean: -20.414483\n",
            "resetting env. episode 904.000000, reward total was -21.000000. running mean: -20.420338\n",
            "resetting env. episode 905.000000, reward total was -20.000000. running mean: -20.416135\n",
            "resetting env. episode 906.000000, reward total was -21.000000. running mean: -20.421974\n",
            "resetting env. episode 907.000000, reward total was -21.000000. running mean: -20.427754\n",
            "resetting env. episode 908.000000, reward total was -21.000000. running mean: -20.433476\n",
            "resetting env. episode 909.000000, reward total was -20.000000. running mean: -20.429142\n",
            "resetting env. episode 910.000000, reward total was -21.000000. running mean: -20.434850\n",
            "resetting env. episode 911.000000, reward total was -19.000000. running mean: -20.420502\n",
            "resetting env. episode 912.000000, reward total was -21.000000. running mean: -20.426297\n",
            "resetting env. episode 913.000000, reward total was -21.000000. running mean: -20.432034\n",
            "resetting env. episode 914.000000, reward total was -21.000000. running mean: -20.437713\n",
            "resetting env. episode 915.000000, reward total was -21.000000. running mean: -20.443336\n",
            "resetting env. episode 916.000000, reward total was -21.000000. running mean: -20.448903\n",
            "resetting env. episode 917.000000, reward total was -20.000000. running mean: -20.444414\n",
            "resetting env. episode 918.000000, reward total was -18.000000. running mean: -20.419970\n",
            "resetting env. episode 919.000000, reward total was -21.000000. running mean: -20.425770\n",
            "resetting env. episode 920.000000, reward total was -19.000000. running mean: -20.411512\n",
            "resetting env. episode 921.000000, reward total was -21.000000. running mean: -20.417397\n",
            "resetting env. episode 922.000000, reward total was -21.000000. running mean: -20.423223\n",
            "resetting env. episode 923.000000, reward total was -20.000000. running mean: -20.418991\n",
            "resetting env. episode 924.000000, reward total was -19.000000. running mean: -20.404801\n",
            "resetting env. episode 925.000000, reward total was -20.000000. running mean: -20.400753\n",
            "resetting env. episode 926.000000, reward total was -21.000000. running mean: -20.406746\n",
            "resetting env. episode 927.000000, reward total was -21.000000. running mean: -20.412678\n",
            "resetting env. episode 928.000000, reward total was -18.000000. running mean: -20.388551\n",
            "resetting env. episode 929.000000, reward total was -20.000000. running mean: -20.384666\n",
            "resetting env. episode 930.000000, reward total was -19.000000. running mean: -20.370819\n",
            "resetting env. episode 931.000000, reward total was -21.000000. running mean: -20.377111\n",
            "resetting env. episode 932.000000, reward total was -21.000000. running mean: -20.383340\n",
            "resetting env. episode 933.000000, reward total was -20.000000. running mean: -20.379506\n",
            "resetting env. episode 934.000000, reward total was -21.000000. running mean: -20.385711\n",
            "resetting env. episode 935.000000, reward total was -20.000000. running mean: -20.381854\n",
            "resetting env. episode 936.000000, reward total was -21.000000. running mean: -20.388036\n",
            "resetting env. episode 937.000000, reward total was -21.000000. running mean: -20.394155\n",
            "resetting env. episode 938.000000, reward total was -21.000000. running mean: -20.400214\n",
            "resetting env. episode 939.000000, reward total was -18.000000. running mean: -20.376212\n",
            "resetting env. episode 940.000000, reward total was -21.000000. running mean: -20.382450\n",
            "resetting env. episode 941.000000, reward total was -21.000000. running mean: -20.388625\n",
            "resetting env. episode 942.000000, reward total was -21.000000. running mean: -20.394739\n",
            "resetting env. episode 943.000000, reward total was -21.000000. running mean: -20.400791\n",
            "resetting env. episode 944.000000, reward total was -18.000000. running mean: -20.376784\n",
            "resetting env. episode 945.000000, reward total was -20.000000. running mean: -20.373016\n",
            "resetting env. episode 946.000000, reward total was -21.000000. running mean: -20.379286\n",
            "resetting env. episode 947.000000, reward total was -20.000000. running mean: -20.375493\n",
            "resetting env. episode 948.000000, reward total was -21.000000. running mean: -20.381738\n",
            "resetting env. episode 949.000000, reward total was -21.000000. running mean: -20.387920\n",
            "resetting env. episode 950.000000, reward total was -20.000000. running mean: -20.384041\n",
            "resetting env. episode 951.000000, reward total was -21.000000. running mean: -20.390201\n",
            "resetting env. episode 952.000000, reward total was -20.000000. running mean: -20.386299\n",
            "resetting env. episode 953.000000, reward total was -19.000000. running mean: -20.372436\n",
            "resetting env. episode 954.000000, reward total was -21.000000. running mean: -20.378711\n",
            "resetting env. episode 955.000000, reward total was -20.000000. running mean: -20.374924\n",
            "resetting env. episode 956.000000, reward total was -21.000000. running mean: -20.381175\n",
            "resetting env. episode 957.000000, reward total was -21.000000. running mean: -20.387363\n",
            "resetting env. episode 958.000000, reward total was -21.000000. running mean: -20.393490\n",
            "resetting env. episode 959.000000, reward total was -20.000000. running mean: -20.389555\n",
            "resetting env. episode 960.000000, reward total was -19.000000. running mean: -20.375659\n",
            "resetting env. episode 961.000000, reward total was -18.000000. running mean: -20.351903\n",
            "resetting env. episode 962.000000, reward total was -21.000000. running mean: -20.358384\n",
            "resetting env. episode 963.000000, reward total was -21.000000. running mean: -20.364800\n",
            "resetting env. episode 964.000000, reward total was -21.000000. running mean: -20.371152\n",
            "resetting env. episode 965.000000, reward total was -19.000000. running mean: -20.357440\n",
            "resetting env. episode 966.000000, reward total was -21.000000. running mean: -20.363866\n",
            "resetting env. episode 967.000000, reward total was -21.000000. running mean: -20.370227\n",
            "resetting env. episode 968.000000, reward total was -21.000000. running mean: -20.376525\n",
            "resetting env. episode 969.000000, reward total was -21.000000. running mean: -20.382760\n",
            "resetting env. episode 970.000000, reward total was -20.000000. running mean: -20.378932\n",
            "resetting env. episode 971.000000, reward total was -17.000000. running mean: -20.345143\n",
            "resetting env. episode 972.000000, reward total was -19.000000. running mean: -20.331691\n",
            "resetting env. episode 973.000000, reward total was -20.000000. running mean: -20.328374\n",
            "resetting env. episode 974.000000, reward total was -20.000000. running mean: -20.325091\n",
            "resetting env. episode 975.000000, reward total was -21.000000. running mean: -20.331840\n",
            "resetting env. episode 976.000000, reward total was -21.000000. running mean: -20.338521\n",
            "resetting env. episode 977.000000, reward total was -21.000000. running mean: -20.345136\n",
            "resetting env. episode 978.000000, reward total was -21.000000. running mean: -20.351685\n",
            "resetting env. episode 979.000000, reward total was -21.000000. running mean: -20.358168\n",
            "resetting env. episode 980.000000, reward total was -21.000000. running mean: -20.364586\n",
            "resetting env. episode 981.000000, reward total was -19.000000. running mean: -20.350940\n",
            "resetting env. episode 982.000000, reward total was -20.000000. running mean: -20.347431\n",
            "resetting env. episode 983.000000, reward total was -21.000000. running mean: -20.353957\n",
            "resetting env. episode 984.000000, reward total was -21.000000. running mean: -20.360417\n",
            "resetting env. episode 985.000000, reward total was -21.000000. running mean: -20.366813\n",
            "resetting env. episode 986.000000, reward total was -21.000000. running mean: -20.373145\n",
            "resetting env. episode 987.000000, reward total was -19.000000. running mean: -20.359413\n",
            "resetting env. episode 988.000000, reward total was -21.000000. running mean: -20.365819\n",
            "resetting env. episode 989.000000, reward total was -21.000000. running mean: -20.372161\n",
            "resetting env. episode 990.000000, reward total was -21.000000. running mean: -20.378439\n",
            "resetting env. episode 991.000000, reward total was -19.000000. running mean: -20.364655\n",
            "resetting env. episode 992.000000, reward total was -21.000000. running mean: -20.371008\n",
            "resetting env. episode 993.000000, reward total was -19.000000. running mean: -20.357298\n",
            "resetting env. episode 994.000000, reward total was -18.000000. running mean: -20.333725\n",
            "resetting env. episode 995.000000, reward total was -21.000000. running mean: -20.340388\n",
            "resetting env. episode 996.000000, reward total was -20.000000. running mean: -20.336984\n",
            "resetting env. episode 997.000000, reward total was -20.000000. running mean: -20.333614\n",
            "resetting env. episode 998.000000, reward total was -20.000000. running mean: -20.330278\n",
            "resetting env. episode 999.000000, reward total was -21.000000. running mean: -20.336976\n",
            "resetting env. episode 1000.000000, reward total was -20.000000. running mean: -20.333606\n",
            "resetting env. episode 1001.000000, reward total was -20.000000. running mean: -20.330270\n",
            "resetting env. episode 1002.000000, reward total was -21.000000. running mean: -20.336967\n",
            "resetting env. episode 1003.000000, reward total was -20.000000. running mean: -20.333597\n",
            "resetting env. episode 1004.000000, reward total was -21.000000. running mean: -20.340261\n",
            "resetting env. episode 1005.000000, reward total was -21.000000. running mean: -20.346859\n",
            "resetting env. episode 1006.000000, reward total was -21.000000. running mean: -20.353390\n",
            "resetting env. episode 1007.000000, reward total was -21.000000. running mean: -20.359856\n",
            "resetting env. episode 1008.000000, reward total was -21.000000. running mean: -20.366258\n",
            "resetting env. episode 1009.000000, reward total was -21.000000. running mean: -20.372595\n",
            "resetting env. episode 1010.000000, reward total was -21.000000. running mean: -20.378869\n",
            "resetting env. episode 1011.000000, reward total was -21.000000. running mean: -20.385080\n",
            "resetting env. episode 1012.000000, reward total was -19.000000. running mean: -20.371230\n",
            "resetting env. episode 1013.000000, reward total was -21.000000. running mean: -20.377517\n",
            "resetting env. episode 1014.000000, reward total was -21.000000. running mean: -20.383742\n",
            "resetting env. episode 1015.000000, reward total was -19.000000. running mean: -20.369905\n",
            "resetting env. episode 1016.000000, reward total was -21.000000. running mean: -20.376206\n",
            "resetting env. episode 1017.000000, reward total was -20.000000. running mean: -20.372444\n",
            "resetting env. episode 1018.000000, reward total was -21.000000. running mean: -20.378719\n",
            "resetting env. episode 1019.000000, reward total was -21.000000. running mean: -20.384932\n",
            "resetting env. episode 1020.000000, reward total was -21.000000. running mean: -20.391083\n",
            "resetting env. episode 1021.000000, reward total was -20.000000. running mean: -20.387172\n",
            "resetting env. episode 1022.000000, reward total was -21.000000. running mean: -20.393300\n",
            "resetting env. episode 1023.000000, reward total was -21.000000. running mean: -20.399367\n",
            "resetting env. episode 1024.000000, reward total was -21.000000. running mean: -20.405373\n",
            "resetting env. episode 1025.000000, reward total was -19.000000. running mean: -20.391320\n",
            "resetting env. episode 1026.000000, reward total was -20.000000. running mean: -20.387407\n",
            "resetting env. episode 1027.000000, reward total was -21.000000. running mean: -20.393532\n",
            "resetting env. episode 1028.000000, reward total was -16.000000. running mean: -20.349597\n",
            "resetting env. episode 1029.000000, reward total was -19.000000. running mean: -20.336101\n",
            "resetting env. episode 1030.000000, reward total was -20.000000. running mean: -20.332740\n",
            "resetting env. episode 1031.000000, reward total was -20.000000. running mean: -20.329413\n",
            "resetting env. episode 1032.000000, reward total was -21.000000. running mean: -20.336119\n",
            "resetting env. episode 1033.000000, reward total was -21.000000. running mean: -20.342757\n",
            "resetting env. episode 1034.000000, reward total was -21.000000. running mean: -20.349330\n",
            "resetting env. episode 1035.000000, reward total was -20.000000. running mean: -20.345837\n",
            "resetting env. episode 1036.000000, reward total was -21.000000. running mean: -20.352378\n",
            "resetting env. episode 1037.000000, reward total was -21.000000. running mean: -20.358854\n",
            "resetting env. episode 1038.000000, reward total was -20.000000. running mean: -20.355266\n",
            "resetting env. episode 1039.000000, reward total was -21.000000. running mean: -20.361713\n",
            "resetting env. episode 1040.000000, reward total was -21.000000. running mean: -20.368096\n",
            "resetting env. episode 1041.000000, reward total was -20.000000. running mean: -20.364415\n",
            "resetting env. episode 1042.000000, reward total was -21.000000. running mean: -20.370771\n",
            "resetting env. episode 1043.000000, reward total was -19.000000. running mean: -20.357063\n",
            "resetting env. episode 1044.000000, reward total was -20.000000. running mean: -20.353493\n",
            "resetting env. episode 1045.000000, reward total was -21.000000. running mean: -20.359958\n",
            "resetting env. episode 1046.000000, reward total was -21.000000. running mean: -20.366358\n",
            "resetting env. episode 1047.000000, reward total was -21.000000. running mean: -20.372695\n",
            "resetting env. episode 1048.000000, reward total was -21.000000. running mean: -20.378968\n",
            "resetting env. episode 1049.000000, reward total was -21.000000. running mean: -20.385178\n",
            "resetting env. episode 1050.000000, reward total was -21.000000. running mean: -20.391326\n",
            "resetting env. episode 1051.000000, reward total was -21.000000. running mean: -20.397413\n",
            "resetting env. episode 1052.000000, reward total was -21.000000. running mean: -20.403439\n",
            "resetting env. episode 1053.000000, reward total was -21.000000. running mean: -20.409404\n",
            "resetting env. episode 1054.000000, reward total was -21.000000. running mean: -20.415310\n",
            "resetting env. episode 1055.000000, reward total was -20.000000. running mean: -20.411157\n",
            "resetting env. episode 1056.000000, reward total was -21.000000. running mean: -20.417046\n",
            "resetting env. episode 1057.000000, reward total was -21.000000. running mean: -20.422875\n",
            "resetting env. episode 1058.000000, reward total was -20.000000. running mean: -20.418646\n",
            "resetting env. episode 1059.000000, reward total was -20.000000. running mean: -20.414460\n",
            "resetting env. episode 1060.000000, reward total was -21.000000. running mean: -20.420315\n",
            "resetting env. episode 1061.000000, reward total was -21.000000. running mean: -20.426112\n",
            "resetting env. episode 1062.000000, reward total was -21.000000. running mean: -20.431851\n",
            "resetting env. episode 1063.000000, reward total was -21.000000. running mean: -20.437533\n",
            "resetting env. episode 1064.000000, reward total was -21.000000. running mean: -20.443157\n",
            "resetting env. episode 1065.000000, reward total was -21.000000. running mean: -20.448726\n",
            "resetting env. episode 1066.000000, reward total was -19.000000. running mean: -20.434238\n",
            "resetting env. episode 1067.000000, reward total was -21.000000. running mean: -20.439896\n",
            "resetting env. episode 1068.000000, reward total was -21.000000. running mean: -20.445497\n",
            "resetting env. episode 1069.000000, reward total was -19.000000. running mean: -20.431042\n",
            "resetting env. episode 1070.000000, reward total was -21.000000. running mean: -20.436732\n",
            "resetting env. episode 1071.000000, reward total was -21.000000. running mean: -20.442364\n",
            "resetting env. episode 1072.000000, reward total was -19.000000. running mean: -20.427941\n",
            "resetting env. episode 1073.000000, reward total was -21.000000. running mean: -20.433661\n",
            "resetting env. episode 1074.000000, reward total was -21.000000. running mean: -20.439325\n",
            "resetting env. episode 1075.000000, reward total was -20.000000. running mean: -20.434931\n",
            "resetting env. episode 1076.000000, reward total was -21.000000. running mean: -20.440582\n",
            "resetting env. episode 1077.000000, reward total was -21.000000. running mean: -20.446176\n",
            "resetting env. episode 1078.000000, reward total was -20.000000. running mean: -20.441715\n",
            "resetting env. episode 1079.000000, reward total was -21.000000. running mean: -20.447297\n",
            "resetting env. episode 1080.000000, reward total was -21.000000. running mean: -20.452824\n",
            "resetting env. episode 1081.000000, reward total was -21.000000. running mean: -20.458296\n",
            "resetting env. episode 1082.000000, reward total was -21.000000. running mean: -20.463713\n",
            "resetting env. episode 1083.000000, reward total was -21.000000. running mean: -20.469076\n",
            "resetting env. episode 1084.000000, reward total was -21.000000. running mean: -20.474385\n",
            "resetting env. episode 1085.000000, reward total was -21.000000. running mean: -20.479642\n",
            "resetting env. episode 1086.000000, reward total was -21.000000. running mean: -20.484845\n",
            "resetting env. episode 1087.000000, reward total was -20.000000. running mean: -20.479997\n",
            "resetting env. episode 1088.000000, reward total was -21.000000. running mean: -20.485197\n",
            "resetting env. episode 1089.000000, reward total was -21.000000. running mean: -20.490345\n",
            "resetting env. episode 1090.000000, reward total was -18.000000. running mean: -20.465441\n",
            "resetting env. episode 1091.000000, reward total was -20.000000. running mean: -20.460787\n",
            "resetting env. episode 1092.000000, reward total was -21.000000. running mean: -20.466179\n",
            "resetting env. episode 1093.000000, reward total was -21.000000. running mean: -20.471517\n",
            "resetting env. episode 1094.000000, reward total was -20.000000. running mean: -20.466802\n",
            "resetting env. episode 1095.000000, reward total was -19.000000. running mean: -20.452134\n",
            "resetting env. episode 1096.000000, reward total was -21.000000. running mean: -20.457613\n",
            "resetting env. episode 1097.000000, reward total was -21.000000. running mean: -20.463037\n",
            "resetting env. episode 1098.000000, reward total was -20.000000. running mean: -20.458406\n",
            "resetting env. episode 1099.000000, reward total was -21.000000. running mean: -20.463822\n",
            "resetting env. episode 1100.000000, reward total was -21.000000. running mean: -20.469184\n",
            "resetting env. episode 1101.000000, reward total was -20.000000. running mean: -20.464492\n",
            "resetting env. episode 1102.000000, reward total was -21.000000. running mean: -20.469847\n",
            "resetting env. episode 1103.000000, reward total was -21.000000. running mean: -20.475149\n",
            "resetting env. episode 1104.000000, reward total was -21.000000. running mean: -20.480397\n",
            "resetting env. episode 1105.000000, reward total was -20.000000. running mean: -20.475593\n",
            "resetting env. episode 1106.000000, reward total was -21.000000. running mean: -20.480837\n",
            "resetting env. episode 1107.000000, reward total was -21.000000. running mean: -20.486029\n",
            "resetting env. episode 1108.000000, reward total was -21.000000. running mean: -20.491169\n",
            "resetting env. episode 1109.000000, reward total was -21.000000. running mean: -20.496257\n",
            "resetting env. episode 1110.000000, reward total was -19.000000. running mean: -20.481294\n",
            "resetting env. episode 1111.000000, reward total was -21.000000. running mean: -20.486481\n",
            "resetting env. episode 1112.000000, reward total was -21.000000. running mean: -20.491617\n",
            "resetting env. episode 1113.000000, reward total was -19.000000. running mean: -20.476700\n",
            "resetting env. episode 1114.000000, reward total was -20.000000. running mean: -20.471933\n",
            "resetting env. episode 1115.000000, reward total was -19.000000. running mean: -20.457214\n",
            "resetting env. episode 1116.000000, reward total was -20.000000. running mean: -20.452642\n",
            "resetting env. episode 1117.000000, reward total was -21.000000. running mean: -20.458116\n",
            "resetting env. episode 1118.000000, reward total was -20.000000. running mean: -20.453534\n",
            "resetting env. episode 1119.000000, reward total was -21.000000. running mean: -20.458999\n",
            "resetting env. episode 1120.000000, reward total was -21.000000. running mean: -20.464409\n",
            "resetting env. episode 1121.000000, reward total was -21.000000. running mean: -20.469765\n",
            "resetting env. episode 1122.000000, reward total was -20.000000. running mean: -20.465067\n",
            "resetting env. episode 1123.000000, reward total was -21.000000. running mean: -20.470417\n",
            "resetting env. episode 1124.000000, reward total was -18.000000. running mean: -20.445712\n",
            "resetting env. episode 1125.000000, reward total was -21.000000. running mean: -20.451255\n",
            "resetting env. episode 1126.000000, reward total was -20.000000. running mean: -20.446743\n",
            "resetting env. episode 1127.000000, reward total was -20.000000. running mean: -20.442275\n",
            "resetting env. episode 1128.000000, reward total was -21.000000. running mean: -20.447853\n",
            "resetting env. episode 1129.000000, reward total was -21.000000. running mean: -20.453374\n",
            "resetting env. episode 1130.000000, reward total was -21.000000. running mean: -20.458840\n",
            "resetting env. episode 1131.000000, reward total was -21.000000. running mean: -20.464252\n",
            "resetting env. episode 1132.000000, reward total was -21.000000. running mean: -20.469609\n",
            "resetting env. episode 1133.000000, reward total was -19.000000. running mean: -20.454913\n",
            "resetting env. episode 1134.000000, reward total was -17.000000. running mean: -20.420364\n",
            "resetting env. episode 1135.000000, reward total was -21.000000. running mean: -20.426161\n",
            "resetting env. episode 1136.000000, reward total was -20.000000. running mean: -20.421899\n",
            "resetting env. episode 1137.000000, reward total was -20.000000. running mean: -20.417680\n",
            "resetting env. episode 1138.000000, reward total was -21.000000. running mean: -20.423503\n",
            "resetting env. episode 1139.000000, reward total was -21.000000. running mean: -20.429268\n",
            "resetting env. episode 1140.000000, reward total was -21.000000. running mean: -20.434975\n",
            "resetting env. episode 1141.000000, reward total was -20.000000. running mean: -20.430626\n",
            "resetting env. episode 1142.000000, reward total was -19.000000. running mean: -20.416319\n",
            "resetting env. episode 1143.000000, reward total was -21.000000. running mean: -20.422156\n",
            "resetting env. episode 1144.000000, reward total was -18.000000. running mean: -20.397935\n",
            "resetting env. episode 1145.000000, reward total was -18.000000. running mean: -20.373955\n",
            "resetting env. episode 1146.000000, reward total was -21.000000. running mean: -20.380216\n",
            "resetting env. episode 1147.000000, reward total was -21.000000. running mean: -20.386414\n",
            "resetting env. episode 1148.000000, reward total was -21.000000. running mean: -20.392549\n",
            "resetting env. episode 1149.000000, reward total was -18.000000. running mean: -20.368624\n",
            "resetting env. episode 1150.000000, reward total was -21.000000. running mean: -20.374938\n",
            "resetting env. episode 1151.000000, reward total was -20.000000. running mean: -20.371188\n",
            "resetting env. episode 1152.000000, reward total was -21.000000. running mean: -20.377476\n",
            "resetting env. episode 1153.000000, reward total was -21.000000. running mean: -20.383702\n",
            "resetting env. episode 1154.000000, reward total was -21.000000. running mean: -20.389865\n",
            "resetting env. episode 1155.000000, reward total was -21.000000. running mean: -20.395966\n",
            "resetting env. episode 1156.000000, reward total was -21.000000. running mean: -20.402006\n",
            "resetting env. episode 1157.000000, reward total was -21.000000. running mean: -20.407986\n",
            "resetting env. episode 1158.000000, reward total was -21.000000. running mean: -20.413906\n",
            "resetting env. episode 1159.000000, reward total was -19.000000. running mean: -20.399767\n",
            "resetting env. episode 1160.000000, reward total was -21.000000. running mean: -20.405770\n",
            "resetting env. episode 1161.000000, reward total was -19.000000. running mean: -20.391712\n",
            "resetting env. episode 1162.000000, reward total was -18.000000. running mean: -20.367795\n",
            "resetting env. episode 1163.000000, reward total was -21.000000. running mean: -20.374117\n",
            "resetting env. episode 1164.000000, reward total was -21.000000. running mean: -20.380376\n",
            "resetting env. episode 1165.000000, reward total was -20.000000. running mean: -20.376572\n",
            "resetting env. episode 1166.000000, reward total was -21.000000. running mean: -20.382806\n",
            "resetting env. episode 1167.000000, reward total was -21.000000. running mean: -20.388978\n",
            "resetting env. episode 1168.000000, reward total was -21.000000. running mean: -20.395088\n",
            "resetting env. episode 1169.000000, reward total was -21.000000. running mean: -20.401138\n",
            "resetting env. episode 1170.000000, reward total was -21.000000. running mean: -20.407126\n",
            "resetting env. episode 1171.000000, reward total was -20.000000. running mean: -20.403055\n",
            "resetting env. episode 1172.000000, reward total was -21.000000. running mean: -20.409024\n",
            "resetting env. episode 1173.000000, reward total was -21.000000. running mean: -20.414934\n",
            "resetting env. episode 1174.000000, reward total was -20.000000. running mean: -20.410785\n",
            "resetting env. episode 1175.000000, reward total was -19.000000. running mean: -20.396677\n",
            "resetting env. episode 1176.000000, reward total was -20.000000. running mean: -20.392710\n",
            "resetting env. episode 1177.000000, reward total was -21.000000. running mean: -20.398783\n",
            "resetting env. episode 1178.000000, reward total was -20.000000. running mean: -20.394795\n",
            "resetting env. episode 1179.000000, reward total was -17.000000. running mean: -20.360847\n",
            "resetting env. episode 1180.000000, reward total was -21.000000. running mean: -20.367239\n",
            "resetting env. episode 1181.000000, reward total was -20.000000. running mean: -20.363566\n",
            "resetting env. episode 1182.000000, reward total was -21.000000. running mean: -20.369931\n",
            "resetting env. episode 1183.000000, reward total was -21.000000. running mean: -20.376231\n",
            "resetting env. episode 1184.000000, reward total was -21.000000. running mean: -20.382469\n",
            "resetting env. episode 1185.000000, reward total was -21.000000. running mean: -20.388644\n",
            "resetting env. episode 1186.000000, reward total was -20.000000. running mean: -20.384758\n",
            "resetting env. episode 1187.000000, reward total was -21.000000. running mean: -20.390910\n",
            "resetting env. episode 1188.000000, reward total was -20.000000. running mean: -20.387001\n",
            "resetting env. episode 1189.000000, reward total was -19.000000. running mean: -20.373131\n",
            "resetting env. episode 1190.000000, reward total was -20.000000. running mean: -20.369400\n",
            "resetting env. episode 1191.000000, reward total was -21.000000. running mean: -20.375706\n",
            "resetting env. episode 1192.000000, reward total was -20.000000. running mean: -20.371949\n",
            "resetting env. episode 1193.000000, reward total was -20.000000. running mean: -20.368229\n",
            "resetting env. episode 1194.000000, reward total was -21.000000. running mean: -20.374547\n",
            "resetting env. episode 1195.000000, reward total was -21.000000. running mean: -20.380802\n",
            "resetting env. episode 1196.000000, reward total was -20.000000. running mean: -20.376994\n",
            "resetting env. episode 1197.000000, reward total was -21.000000. running mean: -20.383224\n",
            "resetting env. episode 1198.000000, reward total was -21.000000. running mean: -20.389392\n",
            "resetting env. episode 1199.000000, reward total was -21.000000. running mean: -20.395498\n",
            "resetting env. episode 1200.000000, reward total was -21.000000. running mean: -20.401543\n",
            "resetting env. episode 1201.000000, reward total was -21.000000. running mean: -20.407527\n",
            "resetting env. episode 1202.000000, reward total was -21.000000. running mean: -20.413452\n",
            "resetting env. episode 1203.000000, reward total was -18.000000. running mean: -20.389317\n",
            "resetting env. episode 1204.000000, reward total was -21.000000. running mean: -20.395424\n",
            "resetting env. episode 1205.000000, reward total was -20.000000. running mean: -20.391470\n",
            "resetting env. episode 1206.000000, reward total was -21.000000. running mean: -20.397555\n",
            "resetting env. episode 1207.000000, reward total was -21.000000. running mean: -20.403580\n",
            "resetting env. episode 1208.000000, reward total was -21.000000. running mean: -20.409544\n",
            "resetting env. episode 1209.000000, reward total was -21.000000. running mean: -20.415448\n",
            "resetting env. episode 1210.000000, reward total was -20.000000. running mean: -20.411294\n",
            "resetting env. episode 1211.000000, reward total was -21.000000. running mean: -20.417181\n",
            "resetting env. episode 1212.000000, reward total was -19.000000. running mean: -20.403009\n",
            "resetting env. episode 1213.000000, reward total was -20.000000. running mean: -20.398979\n",
            "resetting env. episode 1214.000000, reward total was -20.000000. running mean: -20.394989\n",
            "resetting env. episode 1215.000000, reward total was -21.000000. running mean: -20.401039\n",
            "resetting env. episode 1216.000000, reward total was -20.000000. running mean: -20.397029\n",
            "resetting env. episode 1217.000000, reward total was -20.000000. running mean: -20.393059\n",
            "resetting env. episode 1218.000000, reward total was -21.000000. running mean: -20.399128\n",
            "resetting env. episode 1219.000000, reward total was -19.000000. running mean: -20.385137\n",
            "resetting env. episode 1220.000000, reward total was -21.000000. running mean: -20.391286\n",
            "resetting env. episode 1221.000000, reward total was -21.000000. running mean: -20.397373\n",
            "resetting env. episode 1222.000000, reward total was -21.000000. running mean: -20.403399\n",
            "resetting env. episode 1223.000000, reward total was -20.000000. running mean: -20.399365\n",
            "resetting env. episode 1224.000000, reward total was -21.000000. running mean: -20.405371\n",
            "resetting env. episode 1225.000000, reward total was -21.000000. running mean: -20.411318\n",
            "resetting env. episode 1226.000000, reward total was -19.000000. running mean: -20.397204\n",
            "resetting env. episode 1227.000000, reward total was -20.000000. running mean: -20.393232\n",
            "resetting env. episode 1228.000000, reward total was -21.000000. running mean: -20.399300\n",
            "resetting env. episode 1229.000000, reward total was -21.000000. running mean: -20.405307\n",
            "resetting env. episode 1230.000000, reward total was -21.000000. running mean: -20.411254\n",
            "resetting env. episode 1231.000000, reward total was -19.000000. running mean: -20.397141\n",
            "resetting env. episode 1232.000000, reward total was -21.000000. running mean: -20.403170\n",
            "resetting env. episode 1233.000000, reward total was -20.000000. running mean: -20.399138\n",
            "resetting env. episode 1234.000000, reward total was -20.000000. running mean: -20.395147\n",
            "resetting env. episode 1235.000000, reward total was -21.000000. running mean: -20.401195\n",
            "resetting env. episode 1236.000000, reward total was -21.000000. running mean: -20.407184\n",
            "resetting env. episode 1237.000000, reward total was -19.000000. running mean: -20.393112\n",
            "resetting env. episode 1238.000000, reward total was -21.000000. running mean: -20.399181\n",
            "resetting env. episode 1239.000000, reward total was -20.000000. running mean: -20.395189\n",
            "resetting env. episode 1240.000000, reward total was -21.000000. running mean: -20.401237\n",
            "resetting env. episode 1241.000000, reward total was -21.000000. running mean: -20.407225\n",
            "resetting env. episode 1242.000000, reward total was -20.000000. running mean: -20.403152\n",
            "resetting env. episode 1243.000000, reward total was -20.000000. running mean: -20.399121\n",
            "resetting env. episode 1244.000000, reward total was -20.000000. running mean: -20.395130\n",
            "resetting env. episode 1245.000000, reward total was -20.000000. running mean: -20.391178\n",
            "resetting env. episode 1246.000000, reward total was -21.000000. running mean: -20.397266\n",
            "resetting env. episode 1247.000000, reward total was -20.000000. running mean: -20.393294\n",
            "resetting env. episode 1248.000000, reward total was -21.000000. running mean: -20.399361\n",
            "resetting env. episode 1249.000000, reward total was -21.000000. running mean: -20.405367\n",
            "resetting env. episode 1250.000000, reward total was -21.000000. running mean: -20.411314\n",
            "resetting env. episode 1251.000000, reward total was -21.000000. running mean: -20.417200\n",
            "resetting env. episode 1252.000000, reward total was -21.000000. running mean: -20.423028\n",
            "resetting env. episode 1253.000000, reward total was -21.000000. running mean: -20.428798\n",
            "resetting env. episode 1254.000000, reward total was -20.000000. running mean: -20.424510\n",
            "resetting env. episode 1255.000000, reward total was -19.000000. running mean: -20.410265\n",
            "resetting env. episode 1256.000000, reward total was -19.000000. running mean: -20.396162\n",
            "resetting env. episode 1257.000000, reward total was -21.000000. running mean: -20.402201\n",
            "resetting env. episode 1258.000000, reward total was -20.000000. running mean: -20.398179\n",
            "resetting env. episode 1259.000000, reward total was -20.000000. running mean: -20.394197\n",
            "resetting env. episode 1260.000000, reward total was -21.000000. running mean: -20.400255\n",
            "resetting env. episode 1261.000000, reward total was -21.000000. running mean: -20.406252\n",
            "resetting env. episode 1262.000000, reward total was -21.000000. running mean: -20.412190\n",
            "resetting env. episode 1263.000000, reward total was -20.000000. running mean: -20.408068\n",
            "resetting env. episode 1264.000000, reward total was -20.000000. running mean: -20.403987\n",
            "resetting env. episode 1265.000000, reward total was -21.000000. running mean: -20.409948\n",
            "resetting env. episode 1266.000000, reward total was -20.000000. running mean: -20.405848\n",
            "resetting env. episode 1267.000000, reward total was -20.000000. running mean: -20.401790\n",
            "resetting env. episode 1268.000000, reward total was -21.000000. running mean: -20.407772\n",
            "resetting env. episode 1269.000000, reward total was -21.000000. running mean: -20.413694\n",
            "resetting env. episode 1270.000000, reward total was -20.000000. running mean: -20.409557\n",
            "resetting env. episode 1271.000000, reward total was -20.000000. running mean: -20.405461\n",
            "resetting env. episode 1272.000000, reward total was -18.000000. running mean: -20.381407\n",
            "resetting env. episode 1273.000000, reward total was -20.000000. running mean: -20.377593\n",
            "resetting env. episode 1274.000000, reward total was -21.000000. running mean: -20.383817\n",
            "resetting env. episode 1275.000000, reward total was -21.000000. running mean: -20.389979\n",
            "resetting env. episode 1276.000000, reward total was -21.000000. running mean: -20.396079\n",
            "resetting env. episode 1277.000000, reward total was -21.000000. running mean: -20.402118\n",
            "resetting env. episode 1278.000000, reward total was -21.000000. running mean: -20.408097\n",
            "resetting env. episode 1279.000000, reward total was -21.000000. running mean: -20.414016\n",
            "resetting env. episode 1280.000000, reward total was -20.000000. running mean: -20.409876\n",
            "resetting env. episode 1281.000000, reward total was -21.000000. running mean: -20.415777\n",
            "resetting env. episode 1282.000000, reward total was -19.000000. running mean: -20.401619\n",
            "resetting env. episode 1283.000000, reward total was -21.000000. running mean: -20.407603\n",
            "resetting env. episode 1284.000000, reward total was -21.000000. running mean: -20.413527\n",
            "resetting env. episode 1285.000000, reward total was -20.000000. running mean: -20.409392\n",
            "resetting env. episode 1286.000000, reward total was -21.000000. running mean: -20.415298\n",
            "resetting env. episode 1287.000000, reward total was -21.000000. running mean: -20.421145\n",
            "resetting env. episode 1288.000000, reward total was -20.000000. running mean: -20.416933\n",
            "resetting env. episode 1289.000000, reward total was -21.000000. running mean: -20.422764\n",
            "resetting env. episode 1290.000000, reward total was -21.000000. running mean: -20.428536\n",
            "resetting env. episode 1291.000000, reward total was -20.000000. running mean: -20.424251\n",
            "resetting env. episode 1292.000000, reward total was -20.000000. running mean: -20.420009\n",
            "resetting env. episode 1293.000000, reward total was -20.000000. running mean: -20.415808\n",
            "resetting env. episode 1294.000000, reward total was -21.000000. running mean: -20.421650\n",
            "resetting env. episode 1295.000000, reward total was -20.000000. running mean: -20.417434\n",
            "resetting env. episode 1296.000000, reward total was -21.000000. running mean: -20.423260\n",
            "resetting env. episode 1297.000000, reward total was -20.000000. running mean: -20.419027\n",
            "resetting env. episode 1298.000000, reward total was -18.000000. running mean: -20.394837\n",
            "resetting env. episode 1299.000000, reward total was -21.000000. running mean: -20.400888\n",
            "resetting env. episode 1300.000000, reward total was -18.000000. running mean: -20.376879\n",
            "resetting env. episode 1301.000000, reward total was -21.000000. running mean: -20.383111\n",
            "resetting env. episode 1302.000000, reward total was -19.000000. running mean: -20.369280\n",
            "resetting env. episode 1303.000000, reward total was -19.000000. running mean: -20.355587\n",
            "resetting env. episode 1304.000000, reward total was -21.000000. running mean: -20.362031\n",
            "resetting env. episode 1305.000000, reward total was -20.000000. running mean: -20.358411\n",
            "resetting env. episode 1306.000000, reward total was -20.000000. running mean: -20.354826\n",
            "resetting env. episode 1307.000000, reward total was -21.000000. running mean: -20.361278\n",
            "resetting env. episode 1308.000000, reward total was -18.000000. running mean: -20.337665\n",
            "resetting env. episode 1309.000000, reward total was -21.000000. running mean: -20.344289\n",
            "resetting env. episode 1310.000000, reward total was -21.000000. running mean: -20.350846\n",
            "resetting env. episode 1311.000000, reward total was -20.000000. running mean: -20.347337\n",
            "resetting env. episode 1312.000000, reward total was -21.000000. running mean: -20.353864\n",
            "resetting env. episode 1313.000000, reward total was -18.000000. running mean: -20.330325\n",
            "resetting env. episode 1314.000000, reward total was -21.000000. running mean: -20.337022\n",
            "resetting env. episode 1315.000000, reward total was -21.000000. running mean: -20.343652\n",
            "resetting env. episode 1316.000000, reward total was -21.000000. running mean: -20.350215\n",
            "resetting env. episode 1317.000000, reward total was -21.000000. running mean: -20.356713\n",
            "resetting env. episode 1318.000000, reward total was -21.000000. running mean: -20.363146\n",
            "resetting env. episode 1319.000000, reward total was -21.000000. running mean: -20.369515\n",
            "resetting env. episode 1320.000000, reward total was -21.000000. running mean: -20.375819\n",
            "resetting env. episode 1321.000000, reward total was -19.000000. running mean: -20.362061\n",
            "resetting env. episode 1322.000000, reward total was -21.000000. running mean: -20.368441\n",
            "resetting env. episode 1323.000000, reward total was -20.000000. running mean: -20.364756\n",
            "resetting env. episode 1324.000000, reward total was -21.000000. running mean: -20.371109\n",
            "resetting env. episode 1325.000000, reward total was -20.000000. running mean: -20.367398\n",
            "resetting env. episode 1326.000000, reward total was -21.000000. running mean: -20.373724\n",
            "resetting env. episode 1327.000000, reward total was -19.000000. running mean: -20.359986\n",
            "resetting env. episode 1328.000000, reward total was -20.000000. running mean: -20.356387\n",
            "resetting env. episode 1329.000000, reward total was -20.000000. running mean: -20.352823\n",
            "resetting env. episode 1330.000000, reward total was -21.000000. running mean: -20.359294\n",
            "resetting env. episode 1331.000000, reward total was -21.000000. running mean: -20.365702\n",
            "resetting env. episode 1332.000000, reward total was -21.000000. running mean: -20.372045\n",
            "resetting env. episode 1333.000000, reward total was -19.000000. running mean: -20.358324\n",
            "resetting env. episode 1334.000000, reward total was -21.000000. running mean: -20.364741\n",
            "resetting env. episode 1335.000000, reward total was -21.000000. running mean: -20.371093\n",
            "resetting env. episode 1336.000000, reward total was -21.000000. running mean: -20.377382\n",
            "resetting env. episode 1337.000000, reward total was -21.000000. running mean: -20.383609\n",
            "resetting env. episode 1338.000000, reward total was -21.000000. running mean: -20.389773\n",
            "resetting env. episode 1339.000000, reward total was -21.000000. running mean: -20.395875\n",
            "resetting env. episode 1340.000000, reward total was -21.000000. running mean: -20.401916\n",
            "resetting env. episode 1341.000000, reward total was -21.000000. running mean: -20.407897\n",
            "resetting env. episode 1342.000000, reward total was -21.000000. running mean: -20.413818\n",
            "resetting env. episode 1343.000000, reward total was -19.000000. running mean: -20.399680\n",
            "resetting env. episode 1344.000000, reward total was -21.000000. running mean: -20.405683\n",
            "resetting env. episode 1345.000000, reward total was -19.000000. running mean: -20.391626\n",
            "resetting env. episode 1346.000000, reward total was -19.000000. running mean: -20.377710\n",
            "resetting env. episode 1347.000000, reward total was -21.000000. running mean: -20.383933\n",
            "resetting env. episode 1348.000000, reward total was -21.000000. running mean: -20.390093\n",
            "resetting env. episode 1349.000000, reward total was -20.000000. running mean: -20.386193\n",
            "resetting env. episode 1350.000000, reward total was -21.000000. running mean: -20.392331\n",
            "resetting env. episode 1351.000000, reward total was -21.000000. running mean: -20.398407\n",
            "resetting env. episode 1352.000000, reward total was -21.000000. running mean: -20.404423\n",
            "resetting env. episode 1353.000000, reward total was -21.000000. running mean: -20.410379\n",
            "resetting env. episode 1354.000000, reward total was -18.000000. running mean: -20.386275\n",
            "resetting env. episode 1355.000000, reward total was -21.000000. running mean: -20.392412\n",
            "resetting env. episode 1356.000000, reward total was -21.000000. running mean: -20.398488\n",
            "resetting env. episode 1357.000000, reward total was -21.000000. running mean: -20.404503\n",
            "resetting env. episode 1358.000000, reward total was -21.000000. running mean: -20.410458\n",
            "resetting env. episode 1359.000000, reward total was -21.000000. running mean: -20.416354\n",
            "resetting env. episode 1360.000000, reward total was -21.000000. running mean: -20.422190\n",
            "resetting env. episode 1361.000000, reward total was -21.000000. running mean: -20.427968\n",
            "resetting env. episode 1362.000000, reward total was -20.000000. running mean: -20.423689\n",
            "resetting env. episode 1363.000000, reward total was -21.000000. running mean: -20.429452\n",
            "resetting env. episode 1364.000000, reward total was -21.000000. running mean: -20.435157\n",
            "resetting env. episode 1365.000000, reward total was -21.000000. running mean: -20.440806\n",
            "resetting env. episode 1366.000000, reward total was -19.000000. running mean: -20.426398\n",
            "resetting env. episode 1367.000000, reward total was -21.000000. running mean: -20.432134\n",
            "resetting env. episode 1368.000000, reward total was -21.000000. running mean: -20.437812\n",
            "resetting env. episode 1369.000000, reward total was -18.000000. running mean: -20.413434\n",
            "resetting env. episode 1370.000000, reward total was -21.000000. running mean: -20.419300\n",
            "resetting env. episode 1371.000000, reward total was -21.000000. running mean: -20.425107\n",
            "resetting env. episode 1372.000000, reward total was -21.000000. running mean: -20.430856\n",
            "resetting env. episode 1373.000000, reward total was -21.000000. running mean: -20.436547\n",
            "resetting env. episode 1374.000000, reward total was -20.000000. running mean: -20.432182\n",
            "resetting env. episode 1375.000000, reward total was -21.000000. running mean: -20.437860\n",
            "resetting env. episode 1376.000000, reward total was -19.000000. running mean: -20.423481\n",
            "resetting env. episode 1377.000000, reward total was -21.000000. running mean: -20.429247\n",
            "resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.434954\n",
            "resetting env. episode 1379.000000, reward total was -19.000000. running mean: -20.420605\n",
            "resetting env. episode 1380.000000, reward total was -21.000000. running mean: -20.426399\n",
            "resetting env. episode 1381.000000, reward total was -21.000000. running mean: -20.432135\n",
            "resetting env. episode 1382.000000, reward total was -21.000000. running mean: -20.437813\n",
            "resetting env. episode 1383.000000, reward total was -21.000000. running mean: -20.443435\n",
            "resetting env. episode 1384.000000, reward total was -21.000000. running mean: -20.449001\n",
            "resetting env. episode 1385.000000, reward total was -20.000000. running mean: -20.444511\n",
            "resetting env. episode 1386.000000, reward total was -20.000000. running mean: -20.440066\n",
            "resetting env. episode 1387.000000, reward total was -21.000000. running mean: -20.445665\n",
            "resetting env. episode 1388.000000, reward total was -21.000000. running mean: -20.451208\n",
            "resetting env. episode 1389.000000, reward total was -21.000000. running mean: -20.456696\n",
            "resetting env. episode 1390.000000, reward total was -21.000000. running mean: -20.462129\n",
            "resetting env. episode 1391.000000, reward total was -21.000000. running mean: -20.467508\n",
            "resetting env. episode 1392.000000, reward total was -20.000000. running mean: -20.462833\n",
            "resetting env. episode 1393.000000, reward total was -21.000000. running mean: -20.468205\n",
            "resetting env. episode 1394.000000, reward total was -20.000000. running mean: -20.463522\n",
            "resetting env. episode 1395.000000, reward total was -21.000000. running mean: -20.468887\n",
            "resetting env. episode 1396.000000, reward total was -21.000000. running mean: -20.474198\n",
            "resetting env. episode 1397.000000, reward total was -21.000000. running mean: -20.479456\n",
            "resetting env. episode 1398.000000, reward total was -21.000000. running mean: -20.484662\n",
            "resetting env. episode 1399.000000, reward total was -21.000000. running mean: -20.489815\n",
            "resetting env. episode 1400.000000, reward total was -21.000000. running mean: -20.494917\n",
            "resetting env. episode 1401.000000, reward total was -20.000000. running mean: -20.489968\n",
            "resetting env. episode 1402.000000, reward total was -21.000000. running mean: -20.495068\n",
            "resetting env. episode 1403.000000, reward total was -21.000000. running mean: -20.500118\n",
            "resetting env. episode 1404.000000, reward total was -21.000000. running mean: -20.505116\n",
            "resetting env. episode 1405.000000, reward total was -19.000000. running mean: -20.490065\n",
            "resetting env. episode 1406.000000, reward total was -19.000000. running mean: -20.475165\n",
            "resetting env. episode 1407.000000, reward total was -21.000000. running mean: -20.480413\n",
            "resetting env. episode 1408.000000, reward total was -21.000000. running mean: -20.485609\n",
            "resetting env. episode 1409.000000, reward total was -19.000000. running mean: -20.470753\n",
            "resetting env. episode 1410.000000, reward total was -21.000000. running mean: -20.476045\n",
            "resetting env. episode 1411.000000, reward total was -20.000000. running mean: -20.471285\n",
            "resetting env. episode 1412.000000, reward total was -21.000000. running mean: -20.476572\n",
            "resetting env. episode 1413.000000, reward total was -19.000000. running mean: -20.461806\n",
            "resetting env. episode 1414.000000, reward total was -21.000000. running mean: -20.467188\n",
            "resetting env. episode 1415.000000, reward total was -20.000000. running mean: -20.462516\n",
            "resetting env. episode 1416.000000, reward total was -21.000000. running mean: -20.467891\n",
            "resetting env. episode 1417.000000, reward total was -21.000000. running mean: -20.473212\n",
            "resetting env. episode 1418.000000, reward total was -20.000000. running mean: -20.468480\n",
            "resetting env. episode 1419.000000, reward total was -20.000000. running mean: -20.463795\n",
            "resetting env. episode 1420.000000, reward total was -21.000000. running mean: -20.469157\n",
            "resetting env. episode 1421.000000, reward total was -17.000000. running mean: -20.434466\n",
            "resetting env. episode 1422.000000, reward total was -21.000000. running mean: -20.440121\n",
            "resetting env. episode 1423.000000, reward total was -21.000000. running mean: -20.445720\n",
            "resetting env. episode 1424.000000, reward total was -21.000000. running mean: -20.451263\n",
            "resetting env. episode 1425.000000, reward total was -17.000000. running mean: -20.416750\n",
            "resetting env. episode 1426.000000, reward total was -19.000000. running mean: -20.402582\n",
            "resetting env. episode 1427.000000, reward total was -20.000000. running mean: -20.398557\n",
            "resetting env. episode 1428.000000, reward total was -21.000000. running mean: -20.404571\n",
            "resetting env. episode 1429.000000, reward total was -21.000000. running mean: -20.410525\n",
            "resetting env. episode 1430.000000, reward total was -20.000000. running mean: -20.406420\n",
            "resetting env. episode 1431.000000, reward total was -20.000000. running mean: -20.402356\n",
            "resetting env. episode 1432.000000, reward total was -20.000000. running mean: -20.398332\n",
            "resetting env. episode 1433.000000, reward total was -17.000000. running mean: -20.364349\n",
            "resetting env. episode 1434.000000, reward total was -21.000000. running mean: -20.370706\n",
            "resetting env. episode 1435.000000, reward total was -20.000000. running mean: -20.366999\n",
            "resetting env. episode 1436.000000, reward total was -20.000000. running mean: -20.363329\n",
            "resetting env. episode 1437.000000, reward total was -21.000000. running mean: -20.369695\n",
            "resetting env. episode 1438.000000, reward total was -21.000000. running mean: -20.375998\n",
            "resetting env. episode 1439.000000, reward total was -19.000000. running mean: -20.362238\n",
            "resetting env. episode 1440.000000, reward total was -21.000000. running mean: -20.368616\n",
            "resetting env. episode 1441.000000, reward total was -20.000000. running mean: -20.364930\n",
            "resetting env. episode 1442.000000, reward total was -21.000000. running mean: -20.371280\n",
            "resetting env. episode 1443.000000, reward total was -21.000000. running mean: -20.377568\n",
            "resetting env. episode 1444.000000, reward total was -20.000000. running mean: -20.373792\n",
            "resetting env. episode 1445.000000, reward total was -21.000000. running mean: -20.380054\n",
            "resetting env. episode 1446.000000, reward total was -21.000000. running mean: -20.386254\n",
            "resetting env. episode 1447.000000, reward total was -20.000000. running mean: -20.382391\n",
            "resetting env. episode 1448.000000, reward total was -20.000000. running mean: -20.378567\n",
            "resetting env. episode 1449.000000, reward total was -21.000000. running mean: -20.384781\n",
            "resetting env. episode 1450.000000, reward total was -21.000000. running mean: -20.390934\n",
            "resetting env. episode 1451.000000, reward total was -21.000000. running mean: -20.397024\n",
            "resetting env. episode 1452.000000, reward total was -20.000000. running mean: -20.393054\n",
            "resetting env. episode 1453.000000, reward total was -21.000000. running mean: -20.399123\n",
            "resetting env. episode 1454.000000, reward total was -21.000000. running mean: -20.405132\n",
            "resetting env. episode 1455.000000, reward total was -21.000000. running mean: -20.411081\n",
            "resetting env. episode 1456.000000, reward total was -21.000000. running mean: -20.416970\n",
            "resetting env. episode 1457.000000, reward total was -21.000000. running mean: -20.422800\n",
            "resetting env. episode 1458.000000, reward total was -20.000000. running mean: -20.418572\n",
            "resetting env. episode 1459.000000, reward total was -19.000000. running mean: -20.404387\n",
            "resetting env. episode 1460.000000, reward total was -19.000000. running mean: -20.390343\n",
            "resetting env. episode 1461.000000, reward total was -21.000000. running mean: -20.396439\n",
            "resetting env. episode 1462.000000, reward total was -19.000000. running mean: -20.382475\n",
            "resetting env. episode 1463.000000, reward total was -21.000000. running mean: -20.388650\n",
            "resetting env. episode 1464.000000, reward total was -18.000000. running mean: -20.364764\n",
            "resetting env. episode 1465.000000, reward total was -20.000000. running mean: -20.361116\n",
            "resetting env. episode 1466.000000, reward total was -21.000000. running mean: -20.367505\n",
            "resetting env. episode 1467.000000, reward total was -21.000000. running mean: -20.373830\n",
            "resetting env. episode 1468.000000, reward total was -19.000000. running mean: -20.360092\n",
            "resetting env. episode 1469.000000, reward total was -21.000000. running mean: -20.366491\n",
            "resetting env. episode 1470.000000, reward total was -21.000000. running mean: -20.372826\n",
            "resetting env. episode 1471.000000, reward total was -20.000000. running mean: -20.369098\n",
            "resetting env. episode 1472.000000, reward total was -21.000000. running mean: -20.375407\n",
            "resetting env. episode 1473.000000, reward total was -21.000000. running mean: -20.381652\n",
            "resetting env. episode 1474.000000, reward total was -21.000000. running mean: -20.387836\n",
            "resetting env. episode 1475.000000, reward total was -21.000000. running mean: -20.393958\n",
            "resetting env. episode 1476.000000, reward total was -21.000000. running mean: -20.400018\n",
            "resetting env. episode 1477.000000, reward total was -20.000000. running mean: -20.396018\n",
            "resetting env. episode 1478.000000, reward total was -21.000000. running mean: -20.402058\n",
            "resetting env. episode 1479.000000, reward total was -20.000000. running mean: -20.398037\n",
            "resetting env. episode 1480.000000, reward total was -21.000000. running mean: -20.404057\n",
            "resetting env. episode 1481.000000, reward total was -19.000000. running mean: -20.390016\n",
            "resetting env. episode 1482.000000, reward total was -20.000000. running mean: -20.386116\n",
            "resetting env. episode 1483.000000, reward total was -21.000000. running mean: -20.392255\n",
            "resetting env. episode 1484.000000, reward total was -21.000000. running mean: -20.398332\n",
            "resetting env. episode 1485.000000, reward total was -18.000000. running mean: -20.374349\n",
            "resetting env. episode 1486.000000, reward total was -21.000000. running mean: -20.380605\n",
            "resetting env. episode 1487.000000, reward total was -20.000000. running mean: -20.376799\n",
            "resetting env. episode 1488.000000, reward total was -21.000000. running mean: -20.383031\n",
            "resetting env. episode 1489.000000, reward total was -21.000000. running mean: -20.389201\n",
            "resetting env. episode 1490.000000, reward total was -21.000000. running mean: -20.395309\n",
            "resetting env. episode 1491.000000, reward total was -21.000000. running mean: -20.401356\n",
            "resetting env. episode 1492.000000, reward total was -20.000000. running mean: -20.397342\n",
            "resetting env. episode 1493.000000, reward total was -20.000000. running mean: -20.393369\n",
            "resetting env. episode 1494.000000, reward total was -21.000000. running mean: -20.399435\n",
            "resetting env. episode 1495.000000, reward total was -21.000000. running mean: -20.405441\n",
            "resetting env. episode 1496.000000, reward total was -21.000000. running mean: -20.411387\n",
            "resetting env. episode 1497.000000, reward total was -21.000000. running mean: -20.417273\n",
            "resetting env. episode 1498.000000, reward total was -21.000000. running mean: -20.423100\n",
            "resetting env. episode 1499.000000, reward total was -21.000000. running mean: -20.428869\n",
            "resetting env. episode 1500.000000, reward total was -21.000000. running mean: -20.434580\n",
            "resetting env. episode 1501.000000, reward total was -21.000000. running mean: -20.440234\n",
            "resetting env. episode 1502.000000, reward total was -20.000000. running mean: -20.435832\n",
            "resetting env. episode 1503.000000, reward total was -21.000000. running mean: -20.441474\n",
            "resetting env. episode 1504.000000, reward total was -21.000000. running mean: -20.447059\n",
            "resetting env. episode 1505.000000, reward total was -19.000000. running mean: -20.432588\n",
            "resetting env. episode 1506.000000, reward total was -21.000000. running mean: -20.438263\n",
            "resetting env. episode 1507.000000, reward total was -21.000000. running mean: -20.443880\n",
            "resetting env. episode 1508.000000, reward total was -20.000000. running mean: -20.439441\n",
            "resetting env. episode 1509.000000, reward total was -20.000000. running mean: -20.435047\n",
            "resetting env. episode 1510.000000, reward total was -21.000000. running mean: -20.440696\n",
            "resetting env. episode 1511.000000, reward total was -20.000000. running mean: -20.436289\n",
            "resetting env. episode 1512.000000, reward total was -20.000000. running mean: -20.431926\n",
            "resetting env. episode 1513.000000, reward total was -21.000000. running mean: -20.437607\n",
            "resetting env. episode 1514.000000, reward total was -20.000000. running mean: -20.433231\n",
            "resetting env. episode 1515.000000, reward total was -21.000000. running mean: -20.438899\n",
            "resetting env. episode 1516.000000, reward total was -21.000000. running mean: -20.444510\n",
            "resetting env. episode 1517.000000, reward total was -19.000000. running mean: -20.430065\n",
            "resetting env. episode 1518.000000, reward total was -21.000000. running mean: -20.435764\n",
            "resetting env. episode 1519.000000, reward total was -20.000000. running mean: -20.431406\n",
            "resetting env. episode 1520.000000, reward total was -19.000000. running mean: -20.417092\n",
            "resetting env. episode 1521.000000, reward total was -19.000000. running mean: -20.402921\n",
            "resetting env. episode 1522.000000, reward total was -21.000000. running mean: -20.408892\n",
            "resetting env. episode 1523.000000, reward total was -21.000000. running mean: -20.414803\n",
            "resetting env. episode 1524.000000, reward total was -21.000000. running mean: -20.420655\n",
            "resetting env. episode 1525.000000, reward total was -20.000000. running mean: -20.416449\n",
            "resetting env. episode 1526.000000, reward total was -18.000000. running mean: -20.392284\n",
            "resetting env. episode 1527.000000, reward total was -20.000000. running mean: -20.388361\n",
            "resetting env. episode 1528.000000, reward total was -19.000000. running mean: -20.374478\n",
            "resetting env. episode 1529.000000, reward total was -21.000000. running mean: -20.380733\n",
            "resetting env. episode 1530.000000, reward total was -20.000000. running mean: -20.376926\n",
            "resetting env. episode 1531.000000, reward total was -19.000000. running mean: -20.363156\n",
            "resetting env. episode 1532.000000, reward total was -21.000000. running mean: -20.369525\n",
            "resetting env. episode 1533.000000, reward total was -21.000000. running mean: -20.375830\n",
            "resetting env. episode 1534.000000, reward total was -20.000000. running mean: -20.372071\n",
            "resetting env. episode 1535.000000, reward total was -21.000000. running mean: -20.378351\n",
            "resetting env. episode 1536.000000, reward total was -20.000000. running mean: -20.374567\n",
            "resetting env. episode 1537.000000, reward total was -21.000000. running mean: -20.380821\n",
            "resetting env. episode 1538.000000, reward total was -21.000000. running mean: -20.387013\n",
            "resetting env. episode 1539.000000, reward total was -19.000000. running mean: -20.373143\n",
            "resetting env. episode 1540.000000, reward total was -18.000000. running mean: -20.349412\n",
            "resetting env. episode 1541.000000, reward total was -21.000000. running mean: -20.355918\n",
            "resetting env. episode 1542.000000, reward total was -21.000000. running mean: -20.362358\n",
            "resetting env. episode 1543.000000, reward total was -21.000000. running mean: -20.368735\n",
            "resetting env. episode 1544.000000, reward total was -20.000000. running mean: -20.365047\n",
            "resetting env. episode 1545.000000, reward total was -21.000000. running mean: -20.371397\n",
            "resetting env. episode 1546.000000, reward total was -19.000000. running mean: -20.357683\n",
            "resetting env. episode 1547.000000, reward total was -21.000000. running mean: -20.364106\n",
            "resetting env. episode 1548.000000, reward total was -21.000000. running mean: -20.370465\n",
            "resetting env. episode 1549.000000, reward total was -20.000000. running mean: -20.366760\n",
            "resetting env. episode 1550.000000, reward total was -21.000000. running mean: -20.373093\n",
            "resetting env. episode 1551.000000, reward total was -20.000000. running mean: -20.369362\n",
            "resetting env. episode 1552.000000, reward total was -19.000000. running mean: -20.355668\n",
            "resetting env. episode 1553.000000, reward total was -21.000000. running mean: -20.362112\n",
            "resetting env. episode 1554.000000, reward total was -21.000000. running mean: -20.368490\n",
            "resetting env. episode 1555.000000, reward total was -21.000000. running mean: -20.374806\n",
            "resetting env. episode 1556.000000, reward total was -21.000000. running mean: -20.381058\n",
            "resetting env. episode 1557.000000, reward total was -20.000000. running mean: -20.377247\n",
            "resetting env. episode 1558.000000, reward total was -21.000000. running mean: -20.383474\n",
            "resetting env. episode 1559.000000, reward total was -21.000000. running mean: -20.389640\n",
            "resetting env. episode 1560.000000, reward total was -21.000000. running mean: -20.395743\n",
            "resetting env. episode 1561.000000, reward total was -20.000000. running mean: -20.391786\n",
            "resetting env. episode 1562.000000, reward total was -21.000000. running mean: -20.397868\n",
            "resetting env. episode 1563.000000, reward total was -21.000000. running mean: -20.403889\n",
            "resetting env. episode 1564.000000, reward total was -21.000000. running mean: -20.409850\n",
            "resetting env. episode 1565.000000, reward total was -19.000000. running mean: -20.395752\n",
            "resetting env. episode 1566.000000, reward total was -21.000000. running mean: -20.401794\n",
            "resetting env. episode 1567.000000, reward total was -20.000000. running mean: -20.397776\n",
            "resetting env. episode 1568.000000, reward total was -21.000000. running mean: -20.403799\n",
            "resetting env. episode 1569.000000, reward total was -21.000000. running mean: -20.409761\n",
            "resetting env. episode 1570.000000, reward total was -20.000000. running mean: -20.405663\n",
            "resetting env. episode 1571.000000, reward total was -20.000000. running mean: -20.401606\n",
            "resetting env. episode 1572.000000, reward total was -21.000000. running mean: -20.407590\n",
            "resetting env. episode 1573.000000, reward total was -20.000000. running mean: -20.403515\n",
            "resetting env. episode 1574.000000, reward total was -21.000000. running mean: -20.409479\n",
            "resetting env. episode 1575.000000, reward total was -21.000000. running mean: -20.415385\n",
            "resetting env. episode 1576.000000, reward total was -21.000000. running mean: -20.421231\n",
            "resetting env. episode 1577.000000, reward total was -21.000000. running mean: -20.427018\n",
            "resetting env. episode 1578.000000, reward total was -21.000000. running mean: -20.432748\n",
            "resetting env. episode 1579.000000, reward total was -21.000000. running mean: -20.438421\n",
            "resetting env. episode 1580.000000, reward total was -20.000000. running mean: -20.434037\n",
            "resetting env. episode 1581.000000, reward total was -21.000000. running mean: -20.439696\n",
            "resetting env. episode 1582.000000, reward total was -19.000000. running mean: -20.425299\n",
            "resetting env. episode 1583.000000, reward total was -19.000000. running mean: -20.411046\n",
            "resetting env. episode 1584.000000, reward total was -20.000000. running mean: -20.406936\n",
            "resetting env. episode 1585.000000, reward total was -21.000000. running mean: -20.412866\n",
            "resetting env. episode 1586.000000, reward total was -21.000000. running mean: -20.418738\n",
            "resetting env. episode 1587.000000, reward total was -21.000000. running mean: -20.424550\n",
            "resetting env. episode 1588.000000, reward total was -21.000000. running mean: -20.430305\n",
            "resetting env. episode 1589.000000, reward total was -21.000000. running mean: -20.436002\n",
            "resetting env. episode 1590.000000, reward total was -21.000000. running mean: -20.441642\n",
            "resetting env. episode 1591.000000, reward total was -20.000000. running mean: -20.437225\n",
            "resetting env. episode 1592.000000, reward total was -21.000000. running mean: -20.442853\n",
            "resetting env. episode 1593.000000, reward total was -21.000000. running mean: -20.448425\n",
            "resetting env. episode 1594.000000, reward total was -21.000000. running mean: -20.453940\n",
            "resetting env. episode 1595.000000, reward total was -20.000000. running mean: -20.449401\n",
            "resetting env. episode 1596.000000, reward total was -21.000000. running mean: -20.454907\n",
            "resetting env. episode 1597.000000, reward total was -20.000000. running mean: -20.450358\n",
            "resetting env. episode 1598.000000, reward total was -21.000000. running mean: -20.455854\n",
            "resetting env. episode 1599.000000, reward total was -19.000000. running mean: -20.441296\n",
            "resetting env. episode 1600.000000, reward total was -21.000000. running mean: -20.446883\n",
            "resetting env. episode 1601.000000, reward total was -21.000000. running mean: -20.452414\n",
            "resetting env. episode 1602.000000, reward total was -20.000000. running mean: -20.447890\n",
            "resetting env. episode 1603.000000, reward total was -21.000000. running mean: -20.453411\n",
            "resetting env. episode 1604.000000, reward total was -21.000000. running mean: -20.458877\n",
            "resetting env. episode 1605.000000, reward total was -18.000000. running mean: -20.434288\n",
            "resetting env. episode 1606.000000, reward total was -21.000000. running mean: -20.439945\n",
            "resetting env. episode 1607.000000, reward total was -18.000000. running mean: -20.415546\n",
            "resetting env. episode 1608.000000, reward total was -20.000000. running mean: -20.411390\n",
            "resetting env. episode 1609.000000, reward total was -21.000000. running mean: -20.417276\n",
            "resetting env. episode 1610.000000, reward total was -21.000000. running mean: -20.423104\n",
            "resetting env. episode 1611.000000, reward total was -21.000000. running mean: -20.428873\n",
            "resetting env. episode 1612.000000, reward total was -20.000000. running mean: -20.424584\n",
            "resetting env. episode 1613.000000, reward total was -21.000000. running mean: -20.430338\n",
            "resetting env. episode 1614.000000, reward total was -21.000000. running mean: -20.436035\n",
            "resetting env. episode 1615.000000, reward total was -19.000000. running mean: -20.421674\n",
            "resetting env. episode 1616.000000, reward total was -20.000000. running mean: -20.417458\n",
            "resetting env. episode 1617.000000, reward total was -21.000000. running mean: -20.423283\n",
            "resetting env. episode 1618.000000, reward total was -20.000000. running mean: -20.419050\n",
            "resetting env. episode 1619.000000, reward total was -21.000000. running mean: -20.424860\n",
            "resetting env. episode 1620.000000, reward total was -19.000000. running mean: -20.410611\n",
            "resetting env. episode 1621.000000, reward total was -18.000000. running mean: -20.386505\n",
            "resetting env. episode 1622.000000, reward total was -21.000000. running mean: -20.392640\n",
            "resetting env. episode 1623.000000, reward total was -20.000000. running mean: -20.388713\n",
            "resetting env. episode 1624.000000, reward total was -21.000000. running mean: -20.394826\n",
            "resetting env. episode 1625.000000, reward total was -20.000000. running mean: -20.390878\n",
            "resetting env. episode 1626.000000, reward total was -21.000000. running mean: -20.396969\n",
            "resetting env. episode 1627.000000, reward total was -19.000000. running mean: -20.383000\n",
            "resetting env. episode 1628.000000, reward total was -21.000000. running mean: -20.389170\n",
            "resetting env. episode 1629.000000, reward total was -20.000000. running mean: -20.385278\n",
            "resetting env. episode 1630.000000, reward total was -16.000000. running mean: -20.341425\n",
            "resetting env. episode 1631.000000, reward total was -18.000000. running mean: -20.318011\n",
            "resetting env. episode 1632.000000, reward total was -20.000000. running mean: -20.314831\n",
            "resetting env. episode 1633.000000, reward total was -21.000000. running mean: -20.321682\n",
            "resetting env. episode 1634.000000, reward total was -21.000000. running mean: -20.328466\n",
            "resetting env. episode 1635.000000, reward total was -21.000000. running mean: -20.335181\n",
            "resetting env. episode 1636.000000, reward total was -19.000000. running mean: -20.321829\n",
            "resetting env. episode 1637.000000, reward total was -19.000000. running mean: -20.308611\n",
            "resetting env. episode 1638.000000, reward total was -21.000000. running mean: -20.315525\n",
            "resetting env. episode 1639.000000, reward total was -20.000000. running mean: -20.312370\n",
            "resetting env. episode 1640.000000, reward total was -21.000000. running mean: -20.319246\n",
            "resetting env. episode 1641.000000, reward total was -21.000000. running mean: -20.326053\n",
            "resetting env. episode 1642.000000, reward total was -20.000000. running mean: -20.322793\n",
            "resetting env. episode 1643.000000, reward total was -20.000000. running mean: -20.319565\n",
            "resetting env. episode 1644.000000, reward total was -18.000000. running mean: -20.296369\n",
            "resetting env. episode 1645.000000, reward total was -21.000000. running mean: -20.303406\n",
            "resetting env. episode 1646.000000, reward total was -21.000000. running mean: -20.310372\n",
            "resetting env. episode 1647.000000, reward total was -21.000000. running mean: -20.317268\n",
            "resetting env. episode 1648.000000, reward total was -21.000000. running mean: -20.324095\n",
            "resetting env. episode 1649.000000, reward total was -20.000000. running mean: -20.320854\n",
            "resetting env. episode 1650.000000, reward total was -21.000000. running mean: -20.327646\n",
            "resetting env. episode 1651.000000, reward total was -21.000000. running mean: -20.334369\n",
            "resetting env. episode 1652.000000, reward total was -20.000000. running mean: -20.331025\n",
            "resetting env. episode 1653.000000, reward total was -19.000000. running mean: -20.317715\n",
            "resetting env. episode 1654.000000, reward total was -21.000000. running mean: -20.324538\n",
            "resetting env. episode 1655.000000, reward total was -21.000000. running mean: -20.331293\n",
            "resetting env. episode 1656.000000, reward total was -21.000000. running mean: -20.337980\n",
            "resetting env. episode 1657.000000, reward total was -21.000000. running mean: -20.344600\n",
            "resetting env. episode 1658.000000, reward total was -21.000000. running mean: -20.351154\n",
            "resetting env. episode 1659.000000, reward total was -21.000000. running mean: -20.357642\n",
            "resetting env. episode 1660.000000, reward total was -21.000000. running mean: -20.364066\n",
            "resetting env. episode 1661.000000, reward total was -21.000000. running mean: -20.370425\n",
            "resetting env. episode 1662.000000, reward total was -20.000000. running mean: -20.366721\n",
            "resetting env. episode 1663.000000, reward total was -21.000000. running mean: -20.373054\n",
            "resetting env. episode 1664.000000, reward total was -17.000000. running mean: -20.339323\n",
            "resetting env. episode 1665.000000, reward total was -20.000000. running mean: -20.335930\n",
            "resetting env. episode 1666.000000, reward total was -21.000000. running mean: -20.342571\n",
            "resetting env. episode 1667.000000, reward total was -21.000000. running mean: -20.349145\n",
            "resetting env. episode 1668.000000, reward total was -19.000000. running mean: -20.335654\n",
            "resetting env. episode 1669.000000, reward total was -21.000000. running mean: -20.342297\n",
            "resetting env. episode 1670.000000, reward total was -21.000000. running mean: -20.348874\n",
            "resetting env. episode 1671.000000, reward total was -21.000000. running mean: -20.355385\n",
            "resetting env. episode 1672.000000, reward total was -21.000000. running mean: -20.361832\n",
            "resetting env. episode 1673.000000, reward total was -20.000000. running mean: -20.358213\n",
            "resetting env. episode 1674.000000, reward total was -20.000000. running mean: -20.354631\n",
            "resetting env. episode 1675.000000, reward total was -18.000000. running mean: -20.331085\n",
            "resetting env. episode 1676.000000, reward total was -21.000000. running mean: -20.337774\n",
            "resetting env. episode 1677.000000, reward total was -21.000000. running mean: -20.344396\n",
            "resetting env. episode 1678.000000, reward total was -21.000000. running mean: -20.350952\n",
            "resetting env. episode 1679.000000, reward total was -20.000000. running mean: -20.347443\n",
            "resetting env. episode 1680.000000, reward total was -19.000000. running mean: -20.333968\n",
            "resetting env. episode 1681.000000, reward total was -21.000000. running mean: -20.340629\n",
            "resetting env. episode 1682.000000, reward total was -20.000000. running mean: -20.337222\n",
            "resetting env. episode 1683.000000, reward total was -21.000000. running mean: -20.343850\n",
            "resetting env. episode 1684.000000, reward total was -21.000000. running mean: -20.350412\n",
            "resetting env. episode 1685.000000, reward total was -20.000000. running mean: -20.346907\n",
            "resetting env. episode 1686.000000, reward total was -20.000000. running mean: -20.343438\n",
            "resetting env. episode 1687.000000, reward total was -21.000000. running mean: -20.350004\n",
            "resetting env. episode 1688.000000, reward total was -20.000000. running mean: -20.346504\n",
            "resetting env. episode 1689.000000, reward total was -21.000000. running mean: -20.353039\n",
            "resetting env. episode 1690.000000, reward total was -21.000000. running mean: -20.359509\n",
            "resetting env. episode 1691.000000, reward total was -20.000000. running mean: -20.355913\n",
            "resetting env. episode 1692.000000, reward total was -19.000000. running mean: -20.342354\n",
            "resetting env. episode 1693.000000, reward total was -20.000000. running mean: -20.338931\n",
            "resetting env. episode 1694.000000, reward total was -21.000000. running mean: -20.345541\n",
            "resetting env. episode 1695.000000, reward total was -21.000000. running mean: -20.352086\n",
            "resetting env. episode 1696.000000, reward total was -21.000000. running mean: -20.358565\n",
            "resetting env. episode 1697.000000, reward total was -21.000000. running mean: -20.364980\n",
            "resetting env. episode 1698.000000, reward total was -21.000000. running mean: -20.371330\n",
            "resetting env. episode 1699.000000, reward total was -21.000000. running mean: -20.377616\n",
            "resetting env. episode 1700.000000, reward total was -20.000000. running mean: -20.373840\n",
            "resetting env. episode 1701.000000, reward total was -20.000000. running mean: -20.370102\n",
            "resetting env. episode 1702.000000, reward total was -21.000000. running mean: -20.376401\n",
            "resetting env. episode 1703.000000, reward total was -21.000000. running mean: -20.382637\n",
            "resetting env. episode 1704.000000, reward total was -21.000000. running mean: -20.388810\n",
            "resetting env. episode 1705.000000, reward total was -20.000000. running mean: -20.384922\n",
            "resetting env. episode 1706.000000, reward total was -20.000000. running mean: -20.381073\n",
            "resetting env. episode 1707.000000, reward total was -21.000000. running mean: -20.387262\n",
            "resetting env. episode 1708.000000, reward total was -21.000000. running mean: -20.393390\n",
            "resetting env. episode 1709.000000, reward total was -21.000000. running mean: -20.399456\n",
            "resetting env. episode 1710.000000, reward total was -20.000000. running mean: -20.395461\n",
            "resetting env. episode 1711.000000, reward total was -16.000000. running mean: -20.351507\n",
            "resetting env. episode 1712.000000, reward total was -20.000000. running mean: -20.347992\n",
            "resetting env. episode 1713.000000, reward total was -20.000000. running mean: -20.344512\n",
            "resetting env. episode 1714.000000, reward total was -21.000000. running mean: -20.351067\n",
            "resetting env. episode 1715.000000, reward total was -19.000000. running mean: -20.337556\n",
            "resetting env. episode 1716.000000, reward total was -21.000000. running mean: -20.344180\n",
            "resetting env. episode 1717.000000, reward total was -21.000000. running mean: -20.350739\n",
            "resetting env. episode 1718.000000, reward total was -20.000000. running mean: -20.347231\n",
            "resetting env. episode 1719.000000, reward total was -19.000000. running mean: -20.333759\n",
            "resetting env. episode 1720.000000, reward total was -19.000000. running mean: -20.320421\n",
            "resetting env. episode 1721.000000, reward total was -21.000000. running mean: -20.327217\n",
            "resetting env. episode 1722.000000, reward total was -21.000000. running mean: -20.333945\n",
            "resetting env. episode 1723.000000, reward total was -21.000000. running mean: -20.340605\n",
            "resetting env. episode 1724.000000, reward total was -21.000000. running mean: -20.347199\n",
            "resetting env. episode 1725.000000, reward total was -21.000000. running mean: -20.353727\n",
            "resetting env. episode 1726.000000, reward total was -21.000000. running mean: -20.360190\n",
            "resetting env. episode 1727.000000, reward total was -21.000000. running mean: -20.366588\n",
            "resetting env. episode 1728.000000, reward total was -21.000000. running mean: -20.372922\n",
            "resetting env. episode 1729.000000, reward total was -21.000000. running mean: -20.379193\n",
            "resetting env. episode 1730.000000, reward total was -20.000000. running mean: -20.375401\n",
            "resetting env. episode 1731.000000, reward total was -20.000000. running mean: -20.371647\n",
            "resetting env. episode 1732.000000, reward total was -21.000000. running mean: -20.377931\n",
            "resetting env. episode 1733.000000, reward total was -21.000000. running mean: -20.384151\n",
            "resetting env. episode 1734.000000, reward total was -21.000000. running mean: -20.390310\n",
            "resetting env. episode 1735.000000, reward total was -21.000000. running mean: -20.396407\n",
            "resetting env. episode 1736.000000, reward total was -21.000000. running mean: -20.402443\n",
            "resetting env. episode 1737.000000, reward total was -20.000000. running mean: -20.398418\n",
            "resetting env. episode 1738.000000, reward total was -21.000000. running mean: -20.404434\n",
            "resetting env. episode 1739.000000, reward total was -20.000000. running mean: -20.400390\n",
            "resetting env. episode 1740.000000, reward total was -19.000000. running mean: -20.386386\n",
            "resetting env. episode 1741.000000, reward total was -21.000000. running mean: -20.392522\n",
            "resetting env. episode 1742.000000, reward total was -19.000000. running mean: -20.378597\n",
            "resetting env. episode 1743.000000, reward total was -19.000000. running mean: -20.364811\n",
            "resetting env. episode 1744.000000, reward total was -20.000000. running mean: -20.361163\n",
            "resetting env. episode 1745.000000, reward total was -20.000000. running mean: -20.357551\n",
            "resetting env. episode 1746.000000, reward total was -20.000000. running mean: -20.353976\n",
            "resetting env. episode 1747.000000, reward total was -21.000000. running mean: -20.360436\n",
            "resetting env. episode 1748.000000, reward total was -21.000000. running mean: -20.366831\n",
            "resetting env. episode 1749.000000, reward total was -21.000000. running mean: -20.373163\n",
            "resetting env. episode 1750.000000, reward total was -19.000000. running mean: -20.359432\n",
            "resetting env. episode 1751.000000, reward total was -21.000000. running mean: -20.365837\n",
            "resetting env. episode 1752.000000, reward total was -21.000000. running mean: -20.372179\n",
            "resetting env. episode 1753.000000, reward total was -21.000000. running mean: -20.378457\n",
            "resetting env. episode 1754.000000, reward total was -19.000000. running mean: -20.364672\n",
            "resetting env. episode 1755.000000, reward total was -20.000000. running mean: -20.361026\n",
            "resetting env. episode 1756.000000, reward total was -20.000000. running mean: -20.357416\n",
            "resetting env. episode 1757.000000, reward total was -21.000000. running mean: -20.363841\n",
            "resetting env. episode 1758.000000, reward total was -21.000000. running mean: -20.370203\n",
            "resetting env. episode 1759.000000, reward total was -19.000000. running mean: -20.356501\n",
            "resetting env. episode 1760.000000, reward total was -19.000000. running mean: -20.342936\n",
            "resetting env. episode 1761.000000, reward total was -21.000000. running mean: -20.349507\n",
            "resetting env. episode 1762.000000, reward total was -20.000000. running mean: -20.346011\n",
            "resetting env. episode 1763.000000, reward total was -21.000000. running mean: -20.352551\n",
            "resetting env. episode 1764.000000, reward total was -21.000000. running mean: -20.359026\n",
            "resetting env. episode 1765.000000, reward total was -19.000000. running mean: -20.345436\n",
            "resetting env. episode 1766.000000, reward total was -20.000000. running mean: -20.341981\n",
            "resetting env. episode 1767.000000, reward total was -21.000000. running mean: -20.348561\n",
            "resetting env. episode 1768.000000, reward total was -21.000000. running mean: -20.355076\n",
            "resetting env. episode 1769.000000, reward total was -21.000000. running mean: -20.361525\n",
            "resetting env. episode 1770.000000, reward total was -21.000000. running mean: -20.367910\n",
            "resetting env. episode 1771.000000, reward total was -20.000000. running mean: -20.364231\n",
            "resetting env. episode 1772.000000, reward total was -21.000000. running mean: -20.370588\n",
            "resetting env. episode 1773.000000, reward total was -21.000000. running mean: -20.376883\n",
            "resetting env. episode 1774.000000, reward total was -19.000000. running mean: -20.363114\n",
            "resetting env. episode 1775.000000, reward total was -21.000000. running mean: -20.369483\n",
            "resetting env. episode 1776.000000, reward total was -21.000000. running mean: -20.375788\n",
            "resetting env. episode 1777.000000, reward total was -21.000000. running mean: -20.382030\n",
            "resetting env. episode 1778.000000, reward total was -21.000000. running mean: -20.388210\n",
            "resetting env. episode 1779.000000, reward total was -21.000000. running mean: -20.394327\n",
            "resetting env. episode 1780.000000, reward total was -21.000000. running mean: -20.400384\n",
            "resetting env. episode 1781.000000, reward total was -21.000000. running mean: -20.406380\n",
            "resetting env. episode 1782.000000, reward total was -19.000000. running mean: -20.392317\n",
            "resetting env. episode 1783.000000, reward total was -21.000000. running mean: -20.398393\n",
            "resetting env. episode 1784.000000, reward total was -21.000000. running mean: -20.404409\n",
            "resetting env. episode 1785.000000, reward total was -21.000000. running mean: -20.410365\n",
            "resetting env. episode 1786.000000, reward total was -21.000000. running mean: -20.416262\n",
            "resetting env. episode 1787.000000, reward total was -21.000000. running mean: -20.422099\n",
            "resetting env. episode 1788.000000, reward total was -18.000000. running mean: -20.397878\n",
            "resetting env. episode 1789.000000, reward total was -21.000000. running mean: -20.403899\n",
            "resetting env. episode 1790.000000, reward total was -19.000000. running mean: -20.389860\n",
            "resetting env. episode 1791.000000, reward total was -21.000000. running mean: -20.395962\n",
            "resetting env. episode 1792.000000, reward total was -18.000000. running mean: -20.372002\n",
            "resetting env. episode 1793.000000, reward total was -21.000000. running mean: -20.378282\n",
            "resetting env. episode 1794.000000, reward total was -19.000000. running mean: -20.364499\n",
            "resetting env. episode 1795.000000, reward total was -21.000000. running mean: -20.370854\n",
            "resetting env. episode 1796.000000, reward total was -20.000000. running mean: -20.367146\n",
            "resetting env. episode 1797.000000, reward total was -20.000000. running mean: -20.363474\n",
            "resetting env. episode 1798.000000, reward total was -21.000000. running mean: -20.369840\n",
            "resetting env. episode 1799.000000, reward total was -21.000000. running mean: -20.376141\n",
            "resetting env. episode 1800.000000, reward total was -21.000000. running mean: -20.382380\n",
            "resetting env. episode 1801.000000, reward total was -20.000000. running mean: -20.378556\n",
            "resetting env. episode 1802.000000, reward total was -21.000000. running mean: -20.384770\n",
            "resetting env. episode 1803.000000, reward total was -21.000000. running mean: -20.390923\n",
            "resetting env. episode 1804.000000, reward total was -21.000000. running mean: -20.397013\n",
            "resetting env. episode 1805.000000, reward total was -20.000000. running mean: -20.393043\n",
            "resetting env. episode 1806.000000, reward total was -21.000000. running mean: -20.399113\n",
            "resetting env. episode 1807.000000, reward total was -20.000000. running mean: -20.395122\n",
            "resetting env. episode 1808.000000, reward total was -20.000000. running mean: -20.391171\n",
            "resetting env. episode 1809.000000, reward total was -20.000000. running mean: -20.387259\n",
            "resetting env. episode 1810.000000, reward total was -21.000000. running mean: -20.393386\n",
            "resetting env. episode 1811.000000, reward total was -21.000000. running mean: -20.399452\n",
            "resetting env. episode 1812.000000, reward total was -21.000000. running mean: -20.405458\n",
            "resetting env. episode 1813.000000, reward total was -21.000000. running mean: -20.411403\n",
            "resetting env. episode 1814.000000, reward total was -21.000000. running mean: -20.417289\n",
            "resetting env. episode 1815.000000, reward total was -21.000000. running mean: -20.423116\n",
            "resetting env. episode 1816.000000, reward total was -21.000000. running mean: -20.428885\n",
            "resetting env. episode 1817.000000, reward total was -20.000000. running mean: -20.424596\n",
            "resetting env. episode 1818.000000, reward total was -21.000000. running mean: -20.430350\n",
            "resetting env. episode 1819.000000, reward total was -21.000000. running mean: -20.436047\n",
            "resetting env. episode 1820.000000, reward total was -21.000000. running mean: -20.441686\n",
            "resetting env. episode 1821.000000, reward total was -20.000000. running mean: -20.437270\n",
            "resetting env. episode 1822.000000, reward total was -19.000000. running mean: -20.422897\n",
            "resetting env. episode 1823.000000, reward total was -20.000000. running mean: -20.418668\n",
            "resetting env. episode 1824.000000, reward total was -21.000000. running mean: -20.424481\n",
            "resetting env. episode 1825.000000, reward total was -21.000000. running mean: -20.430236\n",
            "resetting env. episode 1826.000000, reward total was -20.000000. running mean: -20.425934\n",
            "resetting env. episode 1827.000000, reward total was -21.000000. running mean: -20.431675\n",
            "resetting env. episode 1828.000000, reward total was -21.000000. running mean: -20.437358\n",
            "resetting env. episode 1829.000000, reward total was -21.000000. running mean: -20.442984\n",
            "resetting env. episode 1830.000000, reward total was -20.000000. running mean: -20.438554\n",
            "resetting env. episode 1831.000000, reward total was -21.000000. running mean: -20.444169\n",
            "resetting env. episode 1832.000000, reward total was -20.000000. running mean: -20.439727\n",
            "resetting env. episode 1833.000000, reward total was -19.000000. running mean: -20.425330\n",
            "resetting env. episode 1834.000000, reward total was -18.000000. running mean: -20.401077\n",
            "resetting env. episode 1835.000000, reward total was -21.000000. running mean: -20.407066\n",
            "resetting env. episode 1836.000000, reward total was -21.000000. running mean: -20.412995\n",
            "resetting env. episode 1837.000000, reward total was -20.000000. running mean: -20.408865\n",
            "resetting env. episode 1838.000000, reward total was -20.000000. running mean: -20.404777\n",
            "resetting env. episode 1839.000000, reward total was -21.000000. running mean: -20.410729\n",
            "resetting env. episode 1840.000000, reward total was -20.000000. running mean: -20.406622\n",
            "resetting env. episode 1841.000000, reward total was -21.000000. running mean: -20.412555\n",
            "resetting env. episode 1842.000000, reward total was -21.000000. running mean: -20.418430\n",
            "resetting env. episode 1843.000000, reward total was -20.000000. running mean: -20.414246\n",
            "resetting env. episode 1844.000000, reward total was -19.000000. running mean: -20.400103\n",
            "resetting env. episode 1845.000000, reward total was -20.000000. running mean: -20.396102\n",
            "resetting env. episode 1846.000000, reward total was -21.000000. running mean: -20.402141\n",
            "resetting env. episode 1847.000000, reward total was -21.000000. running mean: -20.408120\n",
            "resetting env. episode 1848.000000, reward total was -21.000000. running mean: -20.414038\n",
            "resetting env. episode 1849.000000, reward total was -20.000000. running mean: -20.409898\n",
            "resetting env. episode 1850.000000, reward total was -21.000000. running mean: -20.415799\n",
            "resetting env. episode 1851.000000, reward total was -20.000000. running mean: -20.411641\n",
            "resetting env. episode 1852.000000, reward total was -21.000000. running mean: -20.417525\n",
            "resetting env. episode 1853.000000, reward total was -20.000000. running mean: -20.413349\n",
            "resetting env. episode 1854.000000, reward total was -21.000000. running mean: -20.419216\n",
            "resetting env. episode 1855.000000, reward total was -21.000000. running mean: -20.425024\n",
            "resetting env. episode 1856.000000, reward total was -20.000000. running mean: -20.420774\n",
            "resetting env. episode 1857.000000, reward total was -21.000000. running mean: -20.426566\n",
            "resetting env. episode 1858.000000, reward total was -21.000000. running mean: -20.432300\n",
            "resetting env. episode 1859.000000, reward total was -20.000000. running mean: -20.427977\n",
            "resetting env. episode 1860.000000, reward total was -19.000000. running mean: -20.413697\n",
            "resetting env. episode 1861.000000, reward total was -21.000000. running mean: -20.419560\n",
            "resetting env. episode 1862.000000, reward total was -21.000000. running mean: -20.425365\n",
            "resetting env. episode 1863.000000, reward total was -21.000000. running mean: -20.431111\n",
            "resetting env. episode 1864.000000, reward total was -21.000000. running mean: -20.436800\n",
            "resetting env. episode 1865.000000, reward total was -20.000000. running mean: -20.432432\n",
            "resetting env. episode 1866.000000, reward total was -21.000000. running mean: -20.438108\n",
            "resetting env. episode 1867.000000, reward total was -20.000000. running mean: -20.433727\n",
            "resetting env. episode 1868.000000, reward total was -21.000000. running mean: -20.439389\n",
            "resetting env. episode 1869.000000, reward total was -21.000000. running mean: -20.444995\n",
            "resetting env. episode 1870.000000, reward total was -18.000000. running mean: -20.420545\n",
            "resetting env. episode 1871.000000, reward total was -21.000000. running mean: -20.426340\n",
            "resetting env. episode 1872.000000, reward total was -20.000000. running mean: -20.422077\n",
            "resetting env. episode 1873.000000, reward total was -21.000000. running mean: -20.427856\n",
            "resetting env. episode 1874.000000, reward total was -21.000000. running mean: -20.433577\n",
            "resetting env. episode 1875.000000, reward total was -21.000000. running mean: -20.439242\n",
            "resetting env. episode 1876.000000, reward total was -21.000000. running mean: -20.444849\n",
            "resetting env. episode 1877.000000, reward total was -20.000000. running mean: -20.440401\n",
            "resetting env. episode 1878.000000, reward total was -21.000000. running mean: -20.445997\n",
            "resetting env. episode 1879.000000, reward total was -21.000000. running mean: -20.451537\n",
            "resetting env. episode 1880.000000, reward total was -21.000000. running mean: -20.457021\n",
            "resetting env. episode 1881.000000, reward total was -21.000000. running mean: -20.462451\n",
            "resetting env. episode 1882.000000, reward total was -21.000000. running mean: -20.467827\n",
            "resetting env. episode 1883.000000, reward total was -21.000000. running mean: -20.473148\n",
            "resetting env. episode 1884.000000, reward total was -21.000000. running mean: -20.478417\n",
            "resetting env. episode 1885.000000, reward total was -21.000000. running mean: -20.483633\n",
            "resetting env. episode 1886.000000, reward total was -21.000000. running mean: -20.488796\n",
            "resetting env. episode 1887.000000, reward total was -21.000000. running mean: -20.493908\n",
            "resetting env. episode 1888.000000, reward total was -21.000000. running mean: -20.498969\n",
            "resetting env. episode 1889.000000, reward total was -20.000000. running mean: -20.493980\n",
            "resetting env. episode 1890.000000, reward total was -21.000000. running mean: -20.499040\n",
            "resetting env. episode 1891.000000, reward total was -20.000000. running mean: -20.494049\n",
            "resetting env. episode 1892.000000, reward total was -21.000000. running mean: -20.499109\n",
            "resetting env. episode 1893.000000, reward total was -20.000000. running mean: -20.494118\n",
            "resetting env. episode 1894.000000, reward total was -21.000000. running mean: -20.499177\n",
            "resetting env. episode 1895.000000, reward total was -20.000000. running mean: -20.494185\n",
            "resetting env. episode 1896.000000, reward total was -20.000000. running mean: -20.489243\n",
            "resetting env. episode 1897.000000, reward total was -21.000000. running mean: -20.494351\n",
            "resetting env. episode 1898.000000, reward total was -20.000000. running mean: -20.489407\n",
            "resetting env. episode 1899.000000, reward total was -21.000000. running mean: -20.494513\n",
            "resetting env. episode 1900.000000, reward total was -21.000000. running mean: -20.499568\n",
            "resetting env. episode 1901.000000, reward total was -19.000000. running mean: -20.484572\n",
            "resetting env. episode 1902.000000, reward total was -20.000000. running mean: -20.479726\n",
            "resetting env. episode 1903.000000, reward total was -20.000000. running mean: -20.474929\n",
            "resetting env. episode 1904.000000, reward total was -21.000000. running mean: -20.480180\n",
            "resetting env. episode 1905.000000, reward total was -20.000000. running mean: -20.475378\n",
            "resetting env. episode 1906.000000, reward total was -21.000000. running mean: -20.480624\n",
            "resetting env. episode 1907.000000, reward total was -21.000000. running mean: -20.485818\n",
            "resetting env. episode 1908.000000, reward total was -21.000000. running mean: -20.490960\n",
            "resetting env. episode 1909.000000, reward total was -21.000000. running mean: -20.496050\n",
            "resetting env. episode 1910.000000, reward total was -21.000000. running mean: -20.501090\n",
            "resetting env. episode 1911.000000, reward total was -20.000000. running mean: -20.496079\n",
            "resetting env. episode 1912.000000, reward total was -19.000000. running mean: -20.481118\n",
            "resetting env. episode 1913.000000, reward total was -19.000000. running mean: -20.466307\n",
            "resetting env. episode 1914.000000, reward total was -20.000000. running mean: -20.461644\n",
            "resetting env. episode 1915.000000, reward total was -21.000000. running mean: -20.467027\n",
            "resetting env. episode 1916.000000, reward total was -21.000000. running mean: -20.472357\n",
            "resetting env. episode 1917.000000, reward total was -20.000000. running mean: -20.467634\n",
            "resetting env. episode 1918.000000, reward total was -21.000000. running mean: -20.472957\n",
            "resetting env. episode 1919.000000, reward total was -21.000000. running mean: -20.478228\n",
            "resetting env. episode 1920.000000, reward total was -20.000000. running mean: -20.473445\n",
            "resetting env. episode 1921.000000, reward total was -21.000000. running mean: -20.478711\n",
            "resetting env. episode 1922.000000, reward total was -21.000000. running mean: -20.483924\n",
            "resetting env. episode 1923.000000, reward total was -21.000000. running mean: -20.489085\n",
            "resetting env. episode 1924.000000, reward total was -21.000000. running mean: -20.494194\n",
            "resetting env. episode 1925.000000, reward total was -21.000000. running mean: -20.499252\n",
            "resetting env. episode 1926.000000, reward total was -20.000000. running mean: -20.494259\n",
            "resetting env. episode 1927.000000, reward total was -20.000000. running mean: -20.489317\n",
            "resetting env. episode 1928.000000, reward total was -21.000000. running mean: -20.494424\n",
            "resetting env. episode 1929.000000, reward total was -21.000000. running mean: -20.499479\n",
            "resetting env. episode 1930.000000, reward total was -21.000000. running mean: -20.504485\n",
            "resetting env. episode 1931.000000, reward total was -21.000000. running mean: -20.509440\n",
            "resetting env. episode 1932.000000, reward total was -21.000000. running mean: -20.514345\n",
            "resetting env. episode 1933.000000, reward total was -20.000000. running mean: -20.509202\n",
            "resetting env. episode 1934.000000, reward total was -21.000000. running mean: -20.514110\n",
            "resetting env. episode 1935.000000, reward total was -19.000000. running mean: -20.498969\n",
            "resetting env. episode 1936.000000, reward total was -21.000000. running mean: -20.503979\n",
            "resetting env. episode 1937.000000, reward total was -21.000000. running mean: -20.508939\n",
            "resetting env. episode 1938.000000, reward total was -21.000000. running mean: -20.513850\n",
            "resetting env. episode 1939.000000, reward total was -21.000000. running mean: -20.518711\n",
            "resetting env. episode 1940.000000, reward total was -21.000000. running mean: -20.523524\n",
            "resetting env. episode 1941.000000, reward total was -21.000000. running mean: -20.528289\n",
            "resetting env. episode 1942.000000, reward total was -21.000000. running mean: -20.533006\n",
            "resetting env. episode 1943.000000, reward total was -21.000000. running mean: -20.537676\n",
            "resetting env. episode 1944.000000, reward total was -21.000000. running mean: -20.542299\n",
            "resetting env. episode 1945.000000, reward total was -21.000000. running mean: -20.546876\n",
            "resetting env. episode 1946.000000, reward total was -21.000000. running mean: -20.551408\n",
            "resetting env. episode 1947.000000, reward total was -21.000000. running mean: -20.555893\n",
            "resetting env. episode 1948.000000, reward total was -21.000000. running mean: -20.560335\n",
            "resetting env. episode 1949.000000, reward total was -19.000000. running mean: -20.544731\n",
            "resetting env. episode 1950.000000, reward total was -21.000000. running mean: -20.549284\n",
            "resetting env. episode 1951.000000, reward total was -21.000000. running mean: -20.553791\n",
            "resetting env. episode 1952.000000, reward total was -20.000000. running mean: -20.548253\n",
            "resetting env. episode 1953.000000, reward total was -21.000000. running mean: -20.552771\n",
            "resetting env. episode 1954.000000, reward total was -19.000000. running mean: -20.537243\n",
            "resetting env. episode 1955.000000, reward total was -21.000000. running mean: -20.541870\n",
            "resetting env. episode 1956.000000, reward total was -19.000000. running mean: -20.526452\n",
            "resetting env. episode 1957.000000, reward total was -21.000000. running mean: -20.531187\n",
            "resetting env. episode 1958.000000, reward total was -21.000000. running mean: -20.535875\n",
            "resetting env. episode 1959.000000, reward total was -19.000000. running mean: -20.520517\n",
            "resetting env. episode 1960.000000, reward total was -20.000000. running mean: -20.515311\n",
            "resetting env. episode 1961.000000, reward total was -21.000000. running mean: -20.520158\n",
            "resetting env. episode 1962.000000, reward total was -21.000000. running mean: -20.524957\n",
            "resetting env. episode 1963.000000, reward total was -20.000000. running mean: -20.519707\n",
            "resetting env. episode 1964.000000, reward total was -21.000000. running mean: -20.524510\n",
            "resetting env. episode 1965.000000, reward total was -20.000000. running mean: -20.519265\n",
            "resetting env. episode 1966.000000, reward total was -20.000000. running mean: -20.514072\n",
            "resetting env. episode 1967.000000, reward total was -20.000000. running mean: -20.508932\n",
            "resetting env. episode 1968.000000, reward total was -20.000000. running mean: -20.503842\n",
            "resetting env. episode 1969.000000, reward total was -20.000000. running mean: -20.498804\n",
            "resetting env. episode 1970.000000, reward total was -21.000000. running mean: -20.503816\n",
            "resetting env. episode 1971.000000, reward total was -21.000000. running mean: -20.508778\n",
            "resetting env. episode 1972.000000, reward total was -20.000000. running mean: -20.503690\n",
            "resetting env. episode 1973.000000, reward total was -21.000000. running mean: -20.508653\n",
            "resetting env. episode 1974.000000, reward total was -20.000000. running mean: -20.503566\n",
            "resetting env. episode 1975.000000, reward total was -21.000000. running mean: -20.508531\n",
            "resetting env. episode 1976.000000, reward total was -21.000000. running mean: -20.513445\n",
            "resetting env. episode 1977.000000, reward total was -21.000000. running mean: -20.518311\n",
            "resetting env. episode 1978.000000, reward total was -21.000000. running mean: -20.523128\n",
            "resetting env. episode 1979.000000, reward total was -21.000000. running mean: -20.527897\n",
            "resetting env. episode 1980.000000, reward total was -21.000000. running mean: -20.532618\n",
            "resetting env. episode 1981.000000, reward total was -21.000000. running mean: -20.537292\n",
            "resetting env. episode 1982.000000, reward total was -20.000000. running mean: -20.531919\n",
            "resetting env. episode 1983.000000, reward total was -20.000000. running mean: -20.526599\n",
            "resetting env. episode 1984.000000, reward total was -20.000000. running mean: -20.521333\n",
            "resetting env. episode 1985.000000, reward total was -21.000000. running mean: -20.526120\n",
            "resetting env. episode 1986.000000, reward total was -20.000000. running mean: -20.520859\n",
            "resetting env. episode 1987.000000, reward total was -21.000000. running mean: -20.525650\n",
            "resetting env. episode 1988.000000, reward total was -20.000000. running mean: -20.520394\n",
            "resetting env. episode 1989.000000, reward total was -18.000000. running mean: -20.495190\n",
            "resetting env. episode 1990.000000, reward total was -21.000000. running mean: -20.500238\n",
            "resetting env. episode 1991.000000, reward total was -21.000000. running mean: -20.505236\n",
            "resetting env. episode 1992.000000, reward total was -21.000000. running mean: -20.510183\n",
            "resetting env. episode 1993.000000, reward total was -21.000000. running mean: -20.515081\n",
            "resetting env. episode 1994.000000, reward total was -21.000000. running mean: -20.519931\n",
            "resetting env. episode 1995.000000, reward total was -19.000000. running mean: -20.504731\n",
            "resetting env. episode 1996.000000, reward total was -21.000000. running mean: -20.509684\n",
            "resetting env. episode 1997.000000, reward total was -21.000000. running mean: -20.514587\n",
            "resetting env. episode 1998.000000, reward total was -21.000000. running mean: -20.519441\n",
            "resetting env. episode 1999.000000, reward total was -20.000000. running mean: -20.514247\n",
            "resetting env. episode 2000.000000, reward total was -20.000000. running mean: -20.509104\n",
            "resetting env. episode 2001.000000, reward total was -20.000000. running mean: -20.504013\n",
            "resetting env. episode 2002.000000, reward total was -21.000000. running mean: -20.508973\n",
            "resetting env. episode 2003.000000, reward total was -21.000000. running mean: -20.513883\n",
            "resetting env. episode 2004.000000, reward total was -20.000000. running mean: -20.508745\n",
            "resetting env. episode 2005.000000, reward total was -21.000000. running mean: -20.513657\n",
            "resetting env. episode 2006.000000, reward total was -21.000000. running mean: -20.518521\n",
            "resetting env. episode 2007.000000, reward total was -21.000000. running mean: -20.523335\n",
            "resetting env. episode 2008.000000, reward total was -20.000000. running mean: -20.518102\n",
            "resetting env. episode 2009.000000, reward total was -21.000000. running mean: -20.522921\n",
            "resetting env. episode 2010.000000, reward total was -21.000000. running mean: -20.527692\n",
            "resetting env. episode 2011.000000, reward total was -21.000000. running mean: -20.532415\n",
            "resetting env. episode 2012.000000, reward total was -21.000000. running mean: -20.537091\n",
            "resetting env. episode 2013.000000, reward total was -21.000000. running mean: -20.541720\n",
            "resetting env. episode 2014.000000, reward total was -20.000000. running mean: -20.536303\n",
            "resetting env. episode 2015.000000, reward total was -21.000000. running mean: -20.540940\n",
            "resetting env. episode 2016.000000, reward total was -20.000000. running mean: -20.535530\n",
            "resetting env. episode 2017.000000, reward total was -21.000000. running mean: -20.540175\n",
            "resetting env. episode 2018.000000, reward total was -20.000000. running mean: -20.534773\n",
            "resetting env. episode 2019.000000, reward total was -20.000000. running mean: -20.529425\n",
            "resetting env. episode 2020.000000, reward total was -21.000000. running mean: -20.534131\n",
            "resetting env. episode 2021.000000, reward total was -20.000000. running mean: -20.528790\n",
            "resetting env. episode 2022.000000, reward total was -17.000000. running mean: -20.493502\n",
            "resetting env. episode 2023.000000, reward total was -21.000000. running mean: -20.498567\n",
            "resetting env. episode 2024.000000, reward total was -21.000000. running mean: -20.503581\n",
            "resetting env. episode 2025.000000, reward total was -21.000000. running mean: -20.508545\n",
            "resetting env. episode 2026.000000, reward total was -21.000000. running mean: -20.513460\n",
            "resetting env. episode 2027.000000, reward total was -21.000000. running mean: -20.518325\n",
            "resetting env. episode 2028.000000, reward total was -20.000000. running mean: -20.513142\n",
            "resetting env. episode 2029.000000, reward total was -21.000000. running mean: -20.518011\n",
            "resetting env. episode 2030.000000, reward total was -21.000000. running mean: -20.522831\n",
            "resetting env. episode 2031.000000, reward total was -21.000000. running mean: -20.527602\n",
            "resetting env. episode 2032.000000, reward total was -20.000000. running mean: -20.522326\n",
            "resetting env. episode 2033.000000, reward total was -19.000000. running mean: -20.507103\n",
            "resetting env. episode 2034.000000, reward total was -21.000000. running mean: -20.512032\n",
            "resetting env. episode 2035.000000, reward total was -20.000000. running mean: -20.506912\n",
            "resetting env. episode 2036.000000, reward total was -21.000000. running mean: -20.511843\n",
            "resetting env. episode 2037.000000, reward total was -19.000000. running mean: -20.496724\n",
            "resetting env. episode 2038.000000, reward total was -20.000000. running mean: -20.491757\n",
            "resetting env. episode 2039.000000, reward total was -19.000000. running mean: -20.476839\n",
            "resetting env. episode 2040.000000, reward total was -21.000000. running mean: -20.482071\n",
            "resetting env. episode 2041.000000, reward total was -19.000000. running mean: -20.467250\n",
            "resetting env. episode 2042.000000, reward total was -20.000000. running mean: -20.462578\n",
            "resetting env. episode 2043.000000, reward total was -21.000000. running mean: -20.467952\n",
            "resetting env. episode 2044.000000, reward total was -20.000000. running mean: -20.463272\n",
            "resetting env. episode 2045.000000, reward total was -20.000000. running mean: -20.458640\n",
            "resetting env. episode 2046.000000, reward total was -20.000000. running mean: -20.454053\n",
            "resetting env. episode 2047.000000, reward total was -21.000000. running mean: -20.459513\n",
            "resetting env. episode 2048.000000, reward total was -21.000000. running mean: -20.464918\n",
            "resetting env. episode 2049.000000, reward total was -21.000000. running mean: -20.470268\n",
            "resetting env. episode 2050.000000, reward total was -20.000000. running mean: -20.465566\n",
            "resetting env. episode 2051.000000, reward total was -21.000000. running mean: -20.470910\n",
            "resetting env. episode 2052.000000, reward total was -19.000000. running mean: -20.456201\n",
            "resetting env. episode 2053.000000, reward total was -21.000000. running mean: -20.461639\n",
            "resetting env. episode 2054.000000, reward total was -20.000000. running mean: -20.457023\n",
            "resetting env. episode 2055.000000, reward total was -20.000000. running mean: -20.452452\n",
            "resetting env. episode 2056.000000, reward total was -21.000000. running mean: -20.457928\n",
            "resetting env. episode 2057.000000, reward total was -20.000000. running mean: -20.453349\n",
            "resetting env. episode 2058.000000, reward total was -19.000000. running mean: -20.438815\n",
            "resetting env. episode 2059.000000, reward total was -21.000000. running mean: -20.444427\n",
            "resetting env. episode 2060.000000, reward total was -19.000000. running mean: -20.429983\n",
            "resetting env. episode 2061.000000, reward total was -21.000000. running mean: -20.435683\n",
            "resetting env. episode 2062.000000, reward total was -20.000000. running mean: -20.431326\n",
            "resetting env. episode 2063.000000, reward total was -21.000000. running mean: -20.437013\n",
            "resetting env. episode 2064.000000, reward total was -20.000000. running mean: -20.432643\n",
            "resetting env. episode 2065.000000, reward total was -20.000000. running mean: -20.428316\n",
            "resetting env. episode 2066.000000, reward total was -20.000000. running mean: -20.424033\n",
            "resetting env. episode 2067.000000, reward total was -21.000000. running mean: -20.429793\n",
            "resetting env. episode 2068.000000, reward total was -21.000000. running mean: -20.435495\n",
            "resetting env. episode 2069.000000, reward total was -21.000000. running mean: -20.441140\n",
            "resetting env. episode 2070.000000, reward total was -20.000000. running mean: -20.436728\n",
            "resetting env. episode 2071.000000, reward total was -20.000000. running mean: -20.432361\n",
            "resetting env. episode 2072.000000, reward total was -21.000000. running mean: -20.438038\n",
            "resetting env. episode 2073.000000, reward total was -19.000000. running mean: -20.423657\n",
            "resetting env. episode 2074.000000, reward total was -21.000000. running mean: -20.429421\n",
            "resetting env. episode 2075.000000, reward total was -21.000000. running mean: -20.435126\n",
            "resetting env. episode 2076.000000, reward total was -21.000000. running mean: -20.440775\n",
            "resetting env. episode 2077.000000, reward total was -21.000000. running mean: -20.446367\n",
            "resetting env. episode 2078.000000, reward total was -20.000000. running mean: -20.441904\n",
            "resetting env. episode 2079.000000, reward total was -21.000000. running mean: -20.447485\n",
            "resetting env. episode 2080.000000, reward total was -21.000000. running mean: -20.453010\n",
            "resetting env. episode 2081.000000, reward total was -20.000000. running mean: -20.448480\n",
            "resetting env. episode 2082.000000, reward total was -21.000000. running mean: -20.453995\n",
            "resetting env. episode 2083.000000, reward total was -20.000000. running mean: -20.449455\n",
            "resetting env. episode 2084.000000, reward total was -20.000000. running mean: -20.444960\n",
            "resetting env. episode 2085.000000, reward total was -21.000000. running mean: -20.450511\n",
            "resetting env. episode 2086.000000, reward total was -21.000000. running mean: -20.456006\n",
            "resetting env. episode 2087.000000, reward total was -21.000000. running mean: -20.461446\n",
            "resetting env. episode 2088.000000, reward total was -19.000000. running mean: -20.446831\n",
            "resetting env. episode 2089.000000, reward total was -21.000000. running mean: -20.452363\n",
            "resetting env. episode 2090.000000, reward total was -20.000000. running mean: -20.447839\n",
            "resetting env. episode 2091.000000, reward total was -20.000000. running mean: -20.443361\n",
            "resetting env. episode 2092.000000, reward total was -21.000000. running mean: -20.448927\n",
            "resetting env. episode 2093.000000, reward total was -19.000000. running mean: -20.434438\n",
            "resetting env. episode 2094.000000, reward total was -21.000000. running mean: -20.440094\n",
            "resetting env. episode 2095.000000, reward total was -19.000000. running mean: -20.425693\n",
            "resetting env. episode 2096.000000, reward total was -21.000000. running mean: -20.431436\n",
            "resetting env. episode 2097.000000, reward total was -21.000000. running mean: -20.437121\n",
            "resetting env. episode 2098.000000, reward total was -21.000000. running mean: -20.442750\n",
            "resetting env. episode 2099.000000, reward total was -21.000000. running mean: -20.448323\n",
            "resetting env. episode 2100.000000, reward total was -20.000000. running mean: -20.443839\n",
            "resetting env. episode 2101.000000, reward total was -21.000000. running mean: -20.449401\n",
            "resetting env. episode 2102.000000, reward total was -21.000000. running mean: -20.454907\n",
            "resetting env. episode 2103.000000, reward total was -19.000000. running mean: -20.440358\n",
            "resetting env. episode 2104.000000, reward total was -20.000000. running mean: -20.435954\n",
            "resetting env. episode 2105.000000, reward total was -18.000000. running mean: -20.411595\n",
            "resetting env. episode 2106.000000, reward total was -21.000000. running mean: -20.417479\n",
            "resetting env. episode 2107.000000, reward total was -21.000000. running mean: -20.423304\n",
            "resetting env. episode 2108.000000, reward total was -20.000000. running mean: -20.419071\n",
            "resetting env. episode 2109.000000, reward total was -21.000000. running mean: -20.424880\n",
            "resetting env. episode 2110.000000, reward total was -21.000000. running mean: -20.430632\n",
            "resetting env. episode 2111.000000, reward total was -21.000000. running mean: -20.436325\n",
            "resetting env. episode 2112.000000, reward total was -21.000000. running mean: -20.441962\n",
            "resetting env. episode 2113.000000, reward total was -21.000000. running mean: -20.447542\n",
            "resetting env. episode 2114.000000, reward total was -21.000000. running mean: -20.453067\n",
            "resetting env. episode 2115.000000, reward total was -19.000000. running mean: -20.438536\n",
            "resetting env. episode 2116.000000, reward total was -18.000000. running mean: -20.414151\n",
            "resetting env. episode 2117.000000, reward total was -20.000000. running mean: -20.410009\n",
            "resetting env. episode 2118.000000, reward total was -21.000000. running mean: -20.415909\n",
            "resetting env. episode 2119.000000, reward total was -21.000000. running mean: -20.421750\n",
            "resetting env. episode 2120.000000, reward total was -20.000000. running mean: -20.417533\n",
            "resetting env. episode 2121.000000, reward total was -21.000000. running mean: -20.423357\n",
            "resetting env. episode 2122.000000, reward total was -21.000000. running mean: -20.429124\n",
            "resetting env. episode 2123.000000, reward total was -21.000000. running mean: -20.434833\n",
            "resetting env. episode 2124.000000, reward total was -20.000000. running mean: -20.430484\n",
            "resetting env. episode 2125.000000, reward total was -21.000000. running mean: -20.436179\n",
            "resetting env. episode 2126.000000, reward total was -21.000000. running mean: -20.441818\n",
            "resetting env. episode 2127.000000, reward total was -20.000000. running mean: -20.437399\n",
            "resetting env. episode 2128.000000, reward total was -21.000000. running mean: -20.443025\n",
            "resetting env. episode 2129.000000, reward total was -17.000000. running mean: -20.408595\n",
            "resetting env. episode 2130.000000, reward total was -20.000000. running mean: -20.404509\n",
            "resetting env. episode 2131.000000, reward total was -21.000000. running mean: -20.410464\n",
            "resetting env. episode 2132.000000, reward total was -18.000000. running mean: -20.386360\n",
            "resetting env. episode 2133.000000, reward total was -21.000000. running mean: -20.392496\n",
            "resetting env. episode 2134.000000, reward total was -21.000000. running mean: -20.398571\n",
            "resetting env. episode 2135.000000, reward total was -21.000000. running mean: -20.404585\n",
            "resetting env. episode 2136.000000, reward total was -18.000000. running mean: -20.380539\n",
            "resetting env. episode 2137.000000, reward total was -21.000000. running mean: -20.386734\n",
            "resetting env. episode 2138.000000, reward total was -20.000000. running mean: -20.382867\n",
            "resetting env. episode 2139.000000, reward total was -19.000000. running mean: -20.369038\n",
            "resetting env. episode 2140.000000, reward total was -21.000000. running mean: -20.375348\n",
            "resetting env. episode 2141.000000, reward total was -20.000000. running mean: -20.371594\n",
            "resetting env. episode 2142.000000, reward total was -19.000000. running mean: -20.357878\n",
            "resetting env. episode 2143.000000, reward total was -21.000000. running mean: -20.364299\n",
            "resetting env. episode 2144.000000, reward total was -21.000000. running mean: -20.370656\n",
            "resetting env. episode 2145.000000, reward total was -21.000000. running mean: -20.376950\n",
            "resetting env. episode 2146.000000, reward total was -21.000000. running mean: -20.383180\n",
            "resetting env. episode 2147.000000, reward total was -20.000000. running mean: -20.379349\n",
            "resetting env. episode 2148.000000, reward total was -21.000000. running mean: -20.385555\n",
            "resetting env. episode 2149.000000, reward total was -20.000000. running mean: -20.381700\n",
            "resetting env. episode 2150.000000, reward total was -20.000000. running mean: -20.377883\n",
            "resetting env. episode 2151.000000, reward total was -21.000000. running mean: -20.384104\n",
            "resetting env. episode 2152.000000, reward total was -20.000000. running mean: -20.380263\n",
            "resetting env. episode 2153.000000, reward total was -20.000000. running mean: -20.376460\n",
            "resetting env. episode 2154.000000, reward total was -20.000000. running mean: -20.372695\n",
            "resetting env. episode 2155.000000, reward total was -18.000000. running mean: -20.348968\n",
            "resetting env. episode 2156.000000, reward total was -21.000000. running mean: -20.355479\n",
            "resetting env. episode 2157.000000, reward total was -20.000000. running mean: -20.351924\n",
            "resetting env. episode 2158.000000, reward total was -21.000000. running mean: -20.358405\n",
            "resetting env. episode 2159.000000, reward total was -21.000000. running mean: -20.364821\n",
            "resetting env. episode 2160.000000, reward total was -20.000000. running mean: -20.361173\n",
            "resetting env. episode 2161.000000, reward total was -21.000000. running mean: -20.367561\n",
            "resetting env. episode 2162.000000, reward total was -21.000000. running mean: -20.373885\n",
            "resetting env. episode 2163.000000, reward total was -21.000000. running mean: -20.380146\n",
            "resetting env. episode 2164.000000, reward total was -21.000000. running mean: -20.386345\n",
            "resetting env. episode 2165.000000, reward total was -20.000000. running mean: -20.382481\n",
            "resetting env. episode 2166.000000, reward total was -18.000000. running mean: -20.358657\n",
            "resetting env. episode 2167.000000, reward total was -20.000000. running mean: -20.355070\n",
            "resetting env. episode 2168.000000, reward total was -21.000000. running mean: -20.361519\n",
            "resetting env. episode 2169.000000, reward total was -21.000000. running mean: -20.367904\n",
            "resetting env. episode 2170.000000, reward total was -21.000000. running mean: -20.374225\n",
            "resetting env. episode 2171.000000, reward total was -21.000000. running mean: -20.380483\n",
            "resetting env. episode 2172.000000, reward total was -21.000000. running mean: -20.386678\n",
            "resetting env. episode 2173.000000, reward total was -21.000000. running mean: -20.392811\n",
            "resetting env. episode 2174.000000, reward total was -21.000000. running mean: -20.398883\n",
            "resetting env. episode 2175.000000, reward total was -21.000000. running mean: -20.404894\n",
            "resetting env. episode 2176.000000, reward total was -20.000000. running mean: -20.400845\n",
            "resetting env. episode 2177.000000, reward total was -19.000000. running mean: -20.386837\n",
            "resetting env. episode 2178.000000, reward total was -21.000000. running mean: -20.392969\n",
            "resetting env. episode 2179.000000, reward total was -21.000000. running mean: -20.399039\n",
            "resetting env. episode 2180.000000, reward total was -20.000000. running mean: -20.395048\n",
            "resetting env. episode 2181.000000, reward total was -21.000000. running mean: -20.401098\n",
            "resetting env. episode 2182.000000, reward total was -20.000000. running mean: -20.397087\n",
            "resetting env. episode 2183.000000, reward total was -21.000000. running mean: -20.403116\n",
            "resetting env. episode 2184.000000, reward total was -21.000000. running mean: -20.409085\n",
            "resetting env. episode 2185.000000, reward total was -20.000000. running mean: -20.404994\n",
            "resetting env. episode 2186.000000, reward total was -21.000000. running mean: -20.410944\n",
            "resetting env. episode 2187.000000, reward total was -19.000000. running mean: -20.396835\n",
            "resetting env. episode 2188.000000, reward total was -18.000000. running mean: -20.372866\n",
            "resetting env. episode 2189.000000, reward total was -21.000000. running mean: -20.379138\n",
            "resetting env. episode 2190.000000, reward total was -19.000000. running mean: -20.365346\n",
            "resetting env. episode 2191.000000, reward total was -21.000000. running mean: -20.371693\n",
            "resetting env. episode 2192.000000, reward total was -21.000000. running mean: -20.377976\n",
            "resetting env. episode 2193.000000, reward total was -19.000000. running mean: -20.364196\n",
            "resetting env. episode 2194.000000, reward total was -20.000000. running mean: -20.360554\n",
            "resetting env. episode 2195.000000, reward total was -21.000000. running mean: -20.366949\n",
            "resetting env. episode 2196.000000, reward total was -19.000000. running mean: -20.353279\n",
            "resetting env. episode 2197.000000, reward total was -21.000000. running mean: -20.359746\n",
            "resetting env. episode 2198.000000, reward total was -19.000000. running mean: -20.346149\n",
            "resetting env. episode 2199.000000, reward total was -20.000000. running mean: -20.342687\n",
            "resetting env. episode 2200.000000, reward total was -21.000000. running mean: -20.349261\n",
            "resetting env. episode 2201.000000, reward total was -19.000000. running mean: -20.335768\n",
            "resetting env. episode 2202.000000, reward total was -21.000000. running mean: -20.342410\n",
            "resetting env. episode 2203.000000, reward total was -19.000000. running mean: -20.328986\n",
            "resetting env. episode 2204.000000, reward total was -20.000000. running mean: -20.325696\n",
            "resetting env. episode 2205.000000, reward total was -20.000000. running mean: -20.322439\n",
            "resetting env. episode 2206.000000, reward total was -21.000000. running mean: -20.329215\n",
            "resetting env. episode 2207.000000, reward total was -21.000000. running mean: -20.335923\n",
            "resetting env. episode 2208.000000, reward total was -20.000000. running mean: -20.332564\n",
            "resetting env. episode 2209.000000, reward total was -21.000000. running mean: -20.339238\n",
            "resetting env. episode 2210.000000, reward total was -20.000000. running mean: -20.335846\n",
            "resetting env. episode 2211.000000, reward total was -21.000000. running mean: -20.342487\n",
            "resetting env. episode 2212.000000, reward total was -21.000000. running mean: -20.349062\n",
            "resetting env. episode 2213.000000, reward total was -20.000000. running mean: -20.345572\n",
            "resetting env. episode 2214.000000, reward total was -21.000000. running mean: -20.352116\n",
            "resetting env. episode 2215.000000, reward total was -21.000000. running mean: -20.358595\n",
            "resetting env. episode 2216.000000, reward total was -21.000000. running mean: -20.365009\n",
            "resetting env. episode 2217.000000, reward total was -21.000000. running mean: -20.371359\n",
            "resetting env. episode 2218.000000, reward total was -20.000000. running mean: -20.367645\n",
            "resetting env. episode 2219.000000, reward total was -21.000000. running mean: -20.373969\n",
            "resetting env. episode 2220.000000, reward total was -20.000000. running mean: -20.370229\n",
            "resetting env. episode 2221.000000, reward total was -18.000000. running mean: -20.346527\n",
            "resetting env. episode 2222.000000, reward total was -21.000000. running mean: -20.353061\n",
            "resetting env. episode 2223.000000, reward total was -20.000000. running mean: -20.349531\n",
            "resetting env. episode 2224.000000, reward total was -21.000000. running mean: -20.356036\n",
            "resetting env. episode 2225.000000, reward total was -20.000000. running mean: -20.352475\n",
            "resetting env. episode 2226.000000, reward total was -20.000000. running mean: -20.348950\n",
            "resetting env. episode 2227.000000, reward total was -21.000000. running mean: -20.355461\n",
            "resetting env. episode 2228.000000, reward total was -20.000000. running mean: -20.351906\n",
            "resetting env. episode 2229.000000, reward total was -21.000000. running mean: -20.358387\n",
            "resetting env. episode 2230.000000, reward total was -21.000000. running mean: -20.364803\n",
            "resetting env. episode 2231.000000, reward total was -20.000000. running mean: -20.361155\n",
            "resetting env. episode 2232.000000, reward total was -20.000000. running mean: -20.357544\n",
            "resetting env. episode 2233.000000, reward total was -21.000000. running mean: -20.363968\n",
            "resetting env. episode 2234.000000, reward total was -21.000000. running mean: -20.370329\n",
            "resetting env. episode 2235.000000, reward total was -21.000000. running mean: -20.376625\n",
            "resetting env. episode 2236.000000, reward total was -19.000000. running mean: -20.362859\n",
            "resetting env. episode 2237.000000, reward total was -21.000000. running mean: -20.369231\n",
            "resetting env. episode 2238.000000, reward total was -21.000000. running mean: -20.375538\n",
            "resetting env. episode 2239.000000, reward total was -18.000000. running mean: -20.351783\n",
            "resetting env. episode 2240.000000, reward total was -21.000000. running mean: -20.358265\n",
            "resetting env. episode 2241.000000, reward total was -18.000000. running mean: -20.334682\n",
            "resetting env. episode 2242.000000, reward total was -20.000000. running mean: -20.331336\n",
            "resetting env. episode 2243.000000, reward total was -21.000000. running mean: -20.338022\n",
            "resetting env. episode 2244.000000, reward total was -21.000000. running mean: -20.344642\n",
            "resetting env. episode 2245.000000, reward total was -21.000000. running mean: -20.351196\n",
            "resetting env. episode 2246.000000, reward total was -21.000000. running mean: -20.357684\n",
            "resetting env. episode 2247.000000, reward total was -21.000000. running mean: -20.364107\n",
            "resetting env. episode 2248.000000, reward total was -21.000000. running mean: -20.370466\n",
            "resetting env. episode 2249.000000, reward total was -21.000000. running mean: -20.376761\n",
            "resetting env. episode 2250.000000, reward total was -21.000000. running mean: -20.382993\n",
            "resetting env. episode 2251.000000, reward total was -21.000000. running mean: -20.389163\n",
            "resetting env. episode 2252.000000, reward total was -20.000000. running mean: -20.385272\n",
            "resetting env. episode 2253.000000, reward total was -20.000000. running mean: -20.381419\n",
            "resetting env. episode 2254.000000, reward total was -19.000000. running mean: -20.367605\n",
            "resetting env. episode 2255.000000, reward total was -21.000000. running mean: -20.373929\n",
            "resetting env. episode 2256.000000, reward total was -20.000000. running mean: -20.370190\n",
            "resetting env. episode 2257.000000, reward total was -20.000000. running mean: -20.366488\n",
            "resetting env. episode 2258.000000, reward total was -21.000000. running mean: -20.372823\n",
            "resetting env. episode 2259.000000, reward total was -21.000000. running mean: -20.379095\n",
            "resetting env. episode 2260.000000, reward total was -18.000000. running mean: -20.355304\n",
            "resetting env. episode 2261.000000, reward total was -21.000000. running mean: -20.361751\n",
            "resetting env. episode 2262.000000, reward total was -19.000000. running mean: -20.348133\n",
            "resetting env. episode 2263.000000, reward total was -19.000000. running mean: -20.334652\n",
            "resetting env. episode 2264.000000, reward total was -19.000000. running mean: -20.321305\n",
            "resetting env. episode 2265.000000, reward total was -20.000000. running mean: -20.318092\n",
            "resetting env. episode 2266.000000, reward total was -21.000000. running mean: -20.324911\n",
            "resetting env. episode 2267.000000, reward total was -19.000000. running mean: -20.311662\n",
            "resetting env. episode 2268.000000, reward total was -21.000000. running mean: -20.318546\n",
            "resetting env. episode 2269.000000, reward total was -21.000000. running mean: -20.325360\n",
            "resetting env. episode 2270.000000, reward total was -21.000000. running mean: -20.332106\n",
            "resetting env. episode 2271.000000, reward total was -21.000000. running mean: -20.338785\n",
            "resetting env. episode 2272.000000, reward total was -21.000000. running mean: -20.345398\n",
            "resetting env. episode 2273.000000, reward total was -20.000000. running mean: -20.341944\n",
            "resetting env. episode 2274.000000, reward total was -21.000000. running mean: -20.348524\n",
            "resetting env. episode 2275.000000, reward total was -20.000000. running mean: -20.345039\n",
            "resetting env. episode 2276.000000, reward total was -21.000000. running mean: -20.351589\n",
            "resetting env. episode 2277.000000, reward total was -20.000000. running mean: -20.348073\n",
            "resetting env. episode 2278.000000, reward total was -21.000000. running mean: -20.354592\n",
            "resetting env. episode 2279.000000, reward total was -21.000000. running mean: -20.361046\n",
            "resetting env. episode 2280.000000, reward total was -20.000000. running mean: -20.357436\n",
            "resetting env. episode 2281.000000, reward total was -21.000000. running mean: -20.363861\n",
            "resetting env. episode 2282.000000, reward total was -20.000000. running mean: -20.360223\n",
            "resetting env. episode 2283.000000, reward total was -18.000000. running mean: -20.336620\n",
            "resetting env. episode 2284.000000, reward total was -20.000000. running mean: -20.333254\n",
            "resetting env. episode 2285.000000, reward total was -19.000000. running mean: -20.319922\n",
            "resetting env. episode 2286.000000, reward total was -20.000000. running mean: -20.316722\n",
            "resetting env. episode 2287.000000, reward total was -21.000000. running mean: -20.323555\n",
            "resetting env. episode 2288.000000, reward total was -20.000000. running mean: -20.320320\n",
            "resetting env. episode 2289.000000, reward total was -19.000000. running mean: -20.307116\n",
            "resetting env. episode 2290.000000, reward total was -19.000000. running mean: -20.294045\n",
            "resetting env. episode 2291.000000, reward total was -21.000000. running mean: -20.301105\n",
            "resetting env. episode 2292.000000, reward total was -21.000000. running mean: -20.308094\n",
            "resetting env. episode 2293.000000, reward total was -21.000000. running mean: -20.315013\n",
            "resetting env. episode 2294.000000, reward total was -21.000000. running mean: -20.321863\n",
            "resetting env. episode 2295.000000, reward total was -21.000000. running mean: -20.328644\n",
            "resetting env. episode 2296.000000, reward total was -21.000000. running mean: -20.335358\n",
            "resetting env. episode 2297.000000, reward total was -20.000000. running mean: -20.332004\n",
            "resetting env. episode 2298.000000, reward total was -21.000000. running mean: -20.338684\n",
            "resetting env. episode 2299.000000, reward total was -21.000000. running mean: -20.345297\n",
            "resetting env. episode 2300.000000, reward total was -21.000000. running mean: -20.351844\n",
            "resetting env. episode 2301.000000, reward total was -21.000000. running mean: -20.358326\n",
            "resetting env. episode 2302.000000, reward total was -20.000000. running mean: -20.354742\n",
            "resetting env. episode 2303.000000, reward total was -21.000000. running mean: -20.361195\n",
            "resetting env. episode 2304.000000, reward total was -21.000000. running mean: -20.367583\n",
            "resetting env. episode 2305.000000, reward total was -21.000000. running mean: -20.373907\n",
            "resetting env. episode 2306.000000, reward total was -20.000000. running mean: -20.370168\n",
            "resetting env. episode 2307.000000, reward total was -18.000000. running mean: -20.346467\n",
            "resetting env. episode 2308.000000, reward total was -18.000000. running mean: -20.323002\n",
            "resetting env. episode 2309.000000, reward total was -21.000000. running mean: -20.329772\n",
            "resetting env. episode 2310.000000, reward total was -21.000000. running mean: -20.336474\n",
            "resetting env. episode 2311.000000, reward total was -21.000000. running mean: -20.343109\n",
            "resetting env. episode 2312.000000, reward total was -21.000000. running mean: -20.349678\n",
            "resetting env. episode 2313.000000, reward total was -20.000000. running mean: -20.346182\n",
            "resetting env. episode 2314.000000, reward total was -21.000000. running mean: -20.352720\n",
            "resetting env. episode 2315.000000, reward total was -20.000000. running mean: -20.349192\n",
            "resetting env. episode 2316.000000, reward total was -21.000000. running mean: -20.355701\n",
            "resetting env. episode 2317.000000, reward total was -21.000000. running mean: -20.362144\n",
            "resetting env. episode 2318.000000, reward total was -21.000000. running mean: -20.368522\n",
            "resetting env. episode 2319.000000, reward total was -21.000000. running mean: -20.374837\n",
            "resetting env. episode 2320.000000, reward total was -21.000000. running mean: -20.381089\n",
            "resetting env. episode 2321.000000, reward total was -20.000000. running mean: -20.377278\n",
            "resetting env. episode 2322.000000, reward total was -21.000000. running mean: -20.383505\n",
            "resetting env. episode 2323.000000, reward total was -20.000000. running mean: -20.379670\n",
            "resetting env. episode 2324.000000, reward total was -21.000000. running mean: -20.385873\n",
            "resetting env. episode 2325.000000, reward total was -19.000000. running mean: -20.372014\n",
            "resetting env. episode 2326.000000, reward total was -21.000000. running mean: -20.378294\n",
            "resetting env. episode 2327.000000, reward total was -21.000000. running mean: -20.384511\n",
            "resetting env. episode 2328.000000, reward total was -21.000000. running mean: -20.390666\n",
            "resetting env. episode 2329.000000, reward total was -21.000000. running mean: -20.396760\n",
            "resetting env. episode 2330.000000, reward total was -18.000000. running mean: -20.372792\n",
            "resetting env. episode 2331.000000, reward total was -21.000000. running mean: -20.379064\n",
            "resetting env. episode 2332.000000, reward total was -21.000000. running mean: -20.385273\n",
            "resetting env. episode 2333.000000, reward total was -21.000000. running mean: -20.391421\n",
            "resetting env. episode 2334.000000, reward total was -20.000000. running mean: -20.387506\n",
            "resetting env. episode 2335.000000, reward total was -21.000000. running mean: -20.393631\n",
            "resetting env. episode 2336.000000, reward total was -21.000000. running mean: -20.399695\n",
            "resetting env. episode 2337.000000, reward total was -21.000000. running mean: -20.405698\n",
            "resetting env. episode 2338.000000, reward total was -21.000000. running mean: -20.411641\n",
            "resetting env. episode 2339.000000, reward total was -20.000000. running mean: -20.407525\n",
            "resetting env. episode 2340.000000, reward total was -21.000000. running mean: -20.413449\n",
            "resetting env. episode 2341.000000, reward total was -21.000000. running mean: -20.419315\n",
            "resetting env. episode 2342.000000, reward total was -21.000000. running mean: -20.425122\n",
            "resetting env. episode 2343.000000, reward total was -20.000000. running mean: -20.420871\n",
            "resetting env. episode 2344.000000, reward total was -20.000000. running mean: -20.416662\n",
            "resetting env. episode 2345.000000, reward total was -21.000000. running mean: -20.422495\n",
            "resetting env. episode 2346.000000, reward total was -21.000000. running mean: -20.428270\n",
            "resetting env. episode 2347.000000, reward total was -21.000000. running mean: -20.433988\n",
            "resetting env. episode 2348.000000, reward total was -19.000000. running mean: -20.419648\n",
            "resetting env. episode 2349.000000, reward total was -21.000000. running mean: -20.425451\n",
            "resetting env. episode 2350.000000, reward total was -21.000000. running mean: -20.431197\n",
            "resetting env. episode 2351.000000, reward total was -21.000000. running mean: -20.436885\n",
            "resetting env. episode 2352.000000, reward total was -21.000000. running mean: -20.442516\n",
            "resetting env. episode 2353.000000, reward total was -21.000000. running mean: -20.448091\n",
            "resetting env. episode 2354.000000, reward total was -20.000000. running mean: -20.443610\n",
            "resetting env. episode 2355.000000, reward total was -21.000000. running mean: -20.449174\n",
            "resetting env. episode 2356.000000, reward total was -21.000000. running mean: -20.454682\n",
            "resetting env. episode 2357.000000, reward total was -21.000000. running mean: -20.460135\n",
            "resetting env. episode 2358.000000, reward total was -21.000000. running mean: -20.465534\n",
            "resetting env. episode 2359.000000, reward total was -21.000000. running mean: -20.470879\n",
            "resetting env. episode 2360.000000, reward total was -21.000000. running mean: -20.476170\n",
            "resetting env. episode 2361.000000, reward total was -20.000000. running mean: -20.471408\n",
            "resetting env. episode 2362.000000, reward total was -21.000000. running mean: -20.476694\n",
            "resetting env. episode 2363.000000, reward total was -21.000000. running mean: -20.481927\n",
            "resetting env. episode 2364.000000, reward total was -21.000000. running mean: -20.487108\n",
            "resetting env. episode 2365.000000, reward total was -20.000000. running mean: -20.482237\n",
            "resetting env. episode 2366.000000, reward total was -21.000000. running mean: -20.487414\n",
            "resetting env. episode 2367.000000, reward total was -21.000000. running mean: -20.492540\n",
            "resetting env. episode 2368.000000, reward total was -21.000000. running mean: -20.497615\n",
            "resetting env. episode 2369.000000, reward total was -21.000000. running mean: -20.502639\n",
            "resetting env. episode 2370.000000, reward total was -21.000000. running mean: -20.507612\n",
            "resetting env. episode 2371.000000, reward total was -21.000000. running mean: -20.512536\n",
            "resetting env. episode 2372.000000, reward total was -20.000000. running mean: -20.507411\n",
            "resetting env. episode 2373.000000, reward total was -21.000000. running mean: -20.512337\n",
            "resetting env. episode 2374.000000, reward total was -20.000000. running mean: -20.507213\n",
            "resetting env. episode 2375.000000, reward total was -21.000000. running mean: -20.512141\n",
            "resetting env. episode 2376.000000, reward total was -20.000000. running mean: -20.507020\n",
            "resetting env. episode 2377.000000, reward total was -20.000000. running mean: -20.501950\n",
            "resetting env. episode 2378.000000, reward total was -21.000000. running mean: -20.506930\n",
            "resetting env. episode 2379.000000, reward total was -21.000000. running mean: -20.511861\n",
            "resetting env. episode 2380.000000, reward total was -19.000000. running mean: -20.496742\n",
            "resetting env. episode 2381.000000, reward total was -21.000000. running mean: -20.501775\n",
            "resetting env. episode 2382.000000, reward total was -21.000000. running mean: -20.506757\n",
            "resetting env. episode 2383.000000, reward total was -21.000000. running mean: -20.511689\n",
            "resetting env. episode 2384.000000, reward total was -21.000000. running mean: -20.516572\n",
            "resetting env. episode 2385.000000, reward total was -21.000000. running mean: -20.521407\n",
            "resetting env. episode 2386.000000, reward total was -20.000000. running mean: -20.516193\n",
            "resetting env. episode 2387.000000, reward total was -21.000000. running mean: -20.521031\n",
            "resetting env. episode 2388.000000, reward total was -21.000000. running mean: -20.525820\n",
            "resetting env. episode 2389.000000, reward total was -20.000000. running mean: -20.520562\n",
            "resetting env. episode 2390.000000, reward total was -17.000000. running mean: -20.485357\n",
            "resetting env. episode 2391.000000, reward total was -21.000000. running mean: -20.490503\n",
            "resetting env. episode 2392.000000, reward total was -21.000000. running mean: -20.495598\n",
            "resetting env. episode 2393.000000, reward total was -21.000000. running mean: -20.500642\n",
            "resetting env. episode 2394.000000, reward total was -21.000000. running mean: -20.505636\n",
            "resetting env. episode 2395.000000, reward total was -21.000000. running mean: -20.510579\n",
            "resetting env. episode 2396.000000, reward total was -21.000000. running mean: -20.515473\n",
            "resetting env. episode 2397.000000, reward total was -20.000000. running mean: -20.510319\n",
            "resetting env. episode 2398.000000, reward total was -21.000000. running mean: -20.515216\n",
            "resetting env. episode 2399.000000, reward total was -21.000000. running mean: -20.520063\n",
            "resetting env. episode 2400.000000, reward total was -21.000000. running mean: -20.524863\n",
            "resetting env. episode 2401.000000, reward total was -19.000000. running mean: -20.509614\n",
            "resetting env. episode 2402.000000, reward total was -18.000000. running mean: -20.484518\n",
            "resetting env. episode 2403.000000, reward total was -21.000000. running mean: -20.489673\n",
            "resetting env. episode 2404.000000, reward total was -18.000000. running mean: -20.464776\n",
            "resetting env. episode 2405.000000, reward total was -20.000000. running mean: -20.460128\n",
            "resetting env. episode 2406.000000, reward total was -21.000000. running mean: -20.465527\n",
            "resetting env. episode 2407.000000, reward total was -20.000000. running mean: -20.460872\n",
            "resetting env. episode 2408.000000, reward total was -21.000000. running mean: -20.466263\n",
            "resetting env. episode 2409.000000, reward total was -20.000000. running mean: -20.461600\n",
            "resetting env. episode 2410.000000, reward total was -21.000000. running mean: -20.466984\n",
            "resetting env. episode 2411.000000, reward total was -21.000000. running mean: -20.472315\n",
            "resetting env. episode 2412.000000, reward total was -21.000000. running mean: -20.477591\n",
            "resetting env. episode 2413.000000, reward total was -20.000000. running mean: -20.472816\n",
            "resetting env. episode 2414.000000, reward total was -21.000000. running mean: -20.478087\n",
            "resetting env. episode 2415.000000, reward total was -21.000000. running mean: -20.483307\n",
            "resetting env. episode 2416.000000, reward total was -21.000000. running mean: -20.488473\n",
            "resetting env. episode 2417.000000, reward total was -21.000000. running mean: -20.493589\n",
            "resetting env. episode 2418.000000, reward total was -20.000000. running mean: -20.488653\n",
            "resetting env. episode 2419.000000, reward total was -20.000000. running mean: -20.483766\n",
            "resetting env. episode 2420.000000, reward total was -21.000000. running mean: -20.488929\n",
            "resetting env. episode 2421.000000, reward total was -20.000000. running mean: -20.484039\n",
            "resetting env. episode 2422.000000, reward total was -20.000000. running mean: -20.479199\n",
            "resetting env. episode 2423.000000, reward total was -21.000000. running mean: -20.484407\n",
            "resetting env. episode 2424.000000, reward total was -21.000000. running mean: -20.489563\n",
            "resetting env. episode 2425.000000, reward total was -21.000000. running mean: -20.494667\n",
            "resetting env. episode 2426.000000, reward total was -21.000000. running mean: -20.499721\n",
            "resetting env. episode 2427.000000, reward total was -18.000000. running mean: -20.474723\n",
            "resetting env. episode 2428.000000, reward total was -21.000000. running mean: -20.479976\n",
            "resetting env. episode 2429.000000, reward total was -20.000000. running mean: -20.475176\n",
            "resetting env. episode 2430.000000, reward total was -21.000000. running mean: -20.480425\n",
            "resetting env. episode 2431.000000, reward total was -21.000000. running mean: -20.485620\n",
            "resetting env. episode 2432.000000, reward total was -21.000000. running mean: -20.490764\n",
            "resetting env. episode 2433.000000, reward total was -20.000000. running mean: -20.485857\n",
            "resetting env. episode 2434.000000, reward total was -21.000000. running mean: -20.490998\n",
            "resetting env. episode 2435.000000, reward total was -21.000000. running mean: -20.496088\n",
            "resetting env. episode 2436.000000, reward total was -19.000000. running mean: -20.481127\n",
            "resetting env. episode 2437.000000, reward total was -20.000000. running mean: -20.476316\n",
            "resetting env. episode 2438.000000, reward total was -21.000000. running mean: -20.481553\n",
            "resetting env. episode 2439.000000, reward total was -18.000000. running mean: -20.456737\n",
            "resetting env. episode 2440.000000, reward total was -21.000000. running mean: -20.462170\n",
            "resetting env. episode 2441.000000, reward total was -20.000000. running mean: -20.457548\n",
            "resetting env. episode 2442.000000, reward total was -21.000000. running mean: -20.462973\n",
            "resetting env. episode 2443.000000, reward total was -20.000000. running mean: -20.458343\n",
            "resetting env. episode 2444.000000, reward total was -21.000000. running mean: -20.463759\n",
            "resetting env. episode 2445.000000, reward total was -21.000000. running mean: -20.469122\n",
            "resetting env. episode 2446.000000, reward total was -19.000000. running mean: -20.454431\n",
            "resetting env. episode 2447.000000, reward total was -21.000000. running mean: -20.459886\n",
            "resetting env. episode 2448.000000, reward total was -21.000000. running mean: -20.465287\n",
            "resetting env. episode 2449.000000, reward total was -21.000000. running mean: -20.470635\n",
            "resetting env. episode 2450.000000, reward total was -21.000000. running mean: -20.475928\n",
            "resetting env. episode 2451.000000, reward total was -21.000000. running mean: -20.481169\n",
            "resetting env. episode 2452.000000, reward total was -21.000000. running mean: -20.486357\n",
            "resetting env. episode 2453.000000, reward total was -21.000000. running mean: -20.491494\n",
            "resetting env. episode 2454.000000, reward total was -21.000000. running mean: -20.496579\n",
            "resetting env. episode 2455.000000, reward total was -21.000000. running mean: -20.501613\n",
            "resetting env. episode 2456.000000, reward total was -18.000000. running mean: -20.476597\n",
            "resetting env. episode 2457.000000, reward total was -21.000000. running mean: -20.481831\n",
            "resetting env. episode 2458.000000, reward total was -20.000000. running mean: -20.477013\n",
            "resetting env. episode 2459.000000, reward total was -21.000000. running mean: -20.482242\n",
            "resetting env. episode 2460.000000, reward total was -21.000000. running mean: -20.487420\n",
            "resetting env. episode 2461.000000, reward total was -21.000000. running mean: -20.492546\n",
            "resetting env. episode 2462.000000, reward total was -19.000000. running mean: -20.477620\n",
            "resetting env. episode 2463.000000, reward total was -19.000000. running mean: -20.462844\n",
            "resetting env. episode 2464.000000, reward total was -21.000000. running mean: -20.468216\n",
            "resetting env. episode 2465.000000, reward total was -21.000000. running mean: -20.473534\n",
            "resetting env. episode 2466.000000, reward total was -21.000000. running mean: -20.478798\n",
            "resetting env. episode 2467.000000, reward total was -21.000000. running mean: -20.484010\n",
            "resetting env. episode 2468.000000, reward total was -21.000000. running mean: -20.489170\n",
            "resetting env. episode 2469.000000, reward total was -21.000000. running mean: -20.494278\n",
            "resetting env. episode 2470.000000, reward total was -20.000000. running mean: -20.489336\n",
            "resetting env. episode 2471.000000, reward total was -21.000000. running mean: -20.494442\n",
            "resetting env. episode 2472.000000, reward total was -21.000000. running mean: -20.499498\n",
            "resetting env. episode 2473.000000, reward total was -19.000000. running mean: -20.484503\n",
            "resetting env. episode 2474.000000, reward total was -21.000000. running mean: -20.489658\n",
            "resetting env. episode 2475.000000, reward total was -21.000000. running mean: -20.494761\n",
            "resetting env. episode 2476.000000, reward total was -21.000000. running mean: -20.499814\n",
            "resetting env. episode 2477.000000, reward total was -21.000000. running mean: -20.504816\n",
            "resetting env. episode 2478.000000, reward total was -20.000000. running mean: -20.499767\n",
            "resetting env. episode 2479.000000, reward total was -20.000000. running mean: -20.494770\n",
            "resetting env. episode 2480.000000, reward total was -20.000000. running mean: -20.489822\n",
            "resetting env. episode 2481.000000, reward total was -21.000000. running mean: -20.494924\n",
            "resetting env. episode 2482.000000, reward total was -21.000000. running mean: -20.499975\n",
            "resetting env. episode 2483.000000, reward total was -21.000000. running mean: -20.504975\n",
            "resetting env. episode 2484.000000, reward total was -19.000000. running mean: -20.489925\n",
            "resetting env. episode 2485.000000, reward total was -21.000000. running mean: -20.495026\n",
            "resetting env. episode 2486.000000, reward total was -21.000000. running mean: -20.500076\n",
            "resetting env. episode 2487.000000, reward total was -21.000000. running mean: -20.505075\n",
            "resetting env. episode 2488.000000, reward total was -20.000000. running mean: -20.500024\n",
            "resetting env. episode 2489.000000, reward total was -20.000000. running mean: -20.495024\n",
            "resetting env. episode 2490.000000, reward total was -21.000000. running mean: -20.500074\n",
            "resetting env. episode 2491.000000, reward total was -20.000000. running mean: -20.495073\n",
            "resetting env. episode 2492.000000, reward total was -21.000000. running mean: -20.500122\n",
            "resetting env. episode 2493.000000, reward total was -21.000000. running mean: -20.505121\n",
            "resetting env. episode 2494.000000, reward total was -20.000000. running mean: -20.500070\n",
            "resetting env. episode 2495.000000, reward total was -20.000000. running mean: -20.495069\n",
            "resetting env. episode 2496.000000, reward total was -21.000000. running mean: -20.500118\n",
            "resetting env. episode 2497.000000, reward total was -19.000000. running mean: -20.485117\n",
            "resetting env. episode 2498.000000, reward total was -20.000000. running mean: -20.480266\n",
            "resetting env. episode 2499.000000, reward total was -21.000000. running mean: -20.485463\n",
            "resetting env. episode 2500.000000, reward total was -20.000000. running mean: -20.480609\n",
            "resetting env. episode 2501.000000, reward total was -21.000000. running mean: -20.485803\n",
            "resetting env. episode 2502.000000, reward total was -20.000000. running mean: -20.480945\n",
            "resetting env. episode 2503.000000, reward total was -21.000000. running mean: -20.486135\n",
            "resetting env. episode 2504.000000, reward total was -20.000000. running mean: -20.481274\n",
            "resetting env. episode 2505.000000, reward total was -20.000000. running mean: -20.476461\n",
            "resetting env. episode 2506.000000, reward total was -20.000000. running mean: -20.471696\n",
            "resetting env. episode 2507.000000, reward total was -20.000000. running mean: -20.466979\n",
            "resetting env. episode 2508.000000, reward total was -20.000000. running mean: -20.462310\n",
            "resetting env. episode 2509.000000, reward total was -21.000000. running mean: -20.467687\n",
            "resetting env. episode 2510.000000, reward total was -18.000000. running mean: -20.443010\n",
            "resetting env. episode 2511.000000, reward total was -20.000000. running mean: -20.438580\n",
            "resetting env. episode 2512.000000, reward total was -21.000000. running mean: -20.444194\n",
            "resetting env. episode 2513.000000, reward total was -20.000000. running mean: -20.439752\n",
            "resetting env. episode 2514.000000, reward total was -20.000000. running mean: -20.435354\n",
            "resetting env. episode 2515.000000, reward total was -20.000000. running mean: -20.431001\n",
            "resetting env. episode 2516.000000, reward total was -20.000000. running mean: -20.426691\n",
            "resetting env. episode 2517.000000, reward total was -19.000000. running mean: -20.412424\n",
            "resetting env. episode 2518.000000, reward total was -21.000000. running mean: -20.418300\n",
            "resetting env. episode 2519.000000, reward total was -21.000000. running mean: -20.424117\n",
            "resetting env. episode 2520.000000, reward total was -20.000000. running mean: -20.419875\n",
            "resetting env. episode 2521.000000, reward total was -21.000000. running mean: -20.425677\n",
            "resetting env. episode 2522.000000, reward total was -19.000000. running mean: -20.411420\n",
            "resetting env. episode 2523.000000, reward total was -21.000000. running mean: -20.417306\n",
            "resetting env. episode 2524.000000, reward total was -21.000000. running mean: -20.423133\n",
            "resetting env. episode 2525.000000, reward total was -20.000000. running mean: -20.418901\n",
            "resetting env. episode 2526.000000, reward total was -20.000000. running mean: -20.414712\n",
            "resetting env. episode 2527.000000, reward total was -19.000000. running mean: -20.400565\n",
            "resetting env. episode 2528.000000, reward total was -20.000000. running mean: -20.396560\n",
            "resetting env. episode 2529.000000, reward total was -20.000000. running mean: -20.392594\n",
            "resetting env. episode 2530.000000, reward total was -21.000000. running mean: -20.398668\n",
            "resetting env. episode 2531.000000, reward total was -21.000000. running mean: -20.404681\n",
            "resetting env. episode 2532.000000, reward total was -21.000000. running mean: -20.410635\n",
            "resetting env. episode 2533.000000, reward total was -21.000000. running mean: -20.416528\n",
            "resetting env. episode 2534.000000, reward total was -21.000000. running mean: -20.422363\n",
            "resetting env. episode 2535.000000, reward total was -21.000000. running mean: -20.428139\n",
            "resetting env. episode 2536.000000, reward total was -20.000000. running mean: -20.423858\n",
            "resetting env. episode 2537.000000, reward total was -19.000000. running mean: -20.409619\n",
            "resetting env. episode 2538.000000, reward total was -20.000000. running mean: -20.405523\n",
            "resetting env. episode 2539.000000, reward total was -20.000000. running mean: -20.401468\n",
            "resetting env. episode 2540.000000, reward total was -20.000000. running mean: -20.397453\n",
            "resetting env. episode 2541.000000, reward total was -20.000000. running mean: -20.393479\n",
            "resetting env. episode 2542.000000, reward total was -20.000000. running mean: -20.389544\n",
            "resetting env. episode 2543.000000, reward total was -21.000000. running mean: -20.395648\n",
            "resetting env. episode 2544.000000, reward total was -19.000000. running mean: -20.381692\n",
            "resetting env. episode 2545.000000, reward total was -19.000000. running mean: -20.367875\n",
            "resetting env. episode 2546.000000, reward total was -21.000000. running mean: -20.374196\n",
            "resetting env. episode 2547.000000, reward total was -21.000000. running mean: -20.380454\n",
            "resetting env. episode 2548.000000, reward total was -20.000000. running mean: -20.376650\n",
            "resetting env. episode 2549.000000, reward total was -20.000000. running mean: -20.372883\n",
            "resetting env. episode 2550.000000, reward total was -21.000000. running mean: -20.379154\n",
            "resetting env. episode 2551.000000, reward total was -21.000000. running mean: -20.385363\n",
            "resetting env. episode 2552.000000, reward total was -20.000000. running mean: -20.381509\n",
            "resetting env. episode 2553.000000, reward total was -20.000000. running mean: -20.377694\n",
            "resetting env. episode 2554.000000, reward total was -20.000000. running mean: -20.373917\n",
            "resetting env. episode 2555.000000, reward total was -19.000000. running mean: -20.360178\n",
            "resetting env. episode 2556.000000, reward total was -21.000000. running mean: -20.366576\n",
            "resetting env. episode 2557.000000, reward total was -21.000000. running mean: -20.372911\n",
            "resetting env. episode 2558.000000, reward total was -21.000000. running mean: -20.379181\n",
            "resetting env. episode 2559.000000, reward total was -20.000000. running mean: -20.375390\n",
            "resetting env. episode 2560.000000, reward total was -21.000000. running mean: -20.381636\n",
            "resetting env. episode 2561.000000, reward total was -21.000000. running mean: -20.387819\n",
            "resetting env. episode 2562.000000, reward total was -21.000000. running mean: -20.393941\n",
            "resetting env. episode 2563.000000, reward total was -21.000000. running mean: -20.400002\n",
            "resetting env. episode 2564.000000, reward total was -20.000000. running mean: -20.396002\n",
            "resetting env. episode 2565.000000, reward total was -21.000000. running mean: -20.402042\n",
            "resetting env. episode 2566.000000, reward total was -21.000000. running mean: -20.408021\n",
            "resetting env. episode 2567.000000, reward total was -21.000000. running mean: -20.413941\n",
            "resetting env. episode 2568.000000, reward total was -21.000000. running mean: -20.419802\n",
            "resetting env. episode 2569.000000, reward total was -21.000000. running mean: -20.425604\n",
            "resetting env. episode 2570.000000, reward total was -21.000000. running mean: -20.431348\n",
            "resetting env. episode 2571.000000, reward total was -21.000000. running mean: -20.437034\n",
            "resetting env. episode 2572.000000, reward total was -20.000000. running mean: -20.432664\n",
            "resetting env. episode 2573.000000, reward total was -18.000000. running mean: -20.408337\n",
            "resetting env. episode 2574.000000, reward total was -21.000000. running mean: -20.414254\n",
            "resetting env. episode 2575.000000, reward total was -20.000000. running mean: -20.410111\n",
            "resetting env. episode 2576.000000, reward total was -20.000000. running mean: -20.406010\n",
            "resetting env. episode 2577.000000, reward total was -19.000000. running mean: -20.391950\n",
            "resetting env. episode 2578.000000, reward total was -21.000000. running mean: -20.398031\n",
            "resetting env. episode 2579.000000, reward total was -21.000000. running mean: -20.404050\n",
            "resetting env. episode 2580.000000, reward total was -19.000000. running mean: -20.390010\n",
            "resetting env. episode 2581.000000, reward total was -21.000000. running mean: -20.396110\n",
            "resetting env. episode 2582.000000, reward total was -21.000000. running mean: -20.402149\n",
            "resetting env. episode 2583.000000, reward total was -18.000000. running mean: -20.378127\n",
            "resetting env. episode 2584.000000, reward total was -20.000000. running mean: -20.374346\n",
            "resetting env. episode 2585.000000, reward total was -18.000000. running mean: -20.350602\n",
            "resetting env. episode 2586.000000, reward total was -21.000000. running mean: -20.357096\n",
            "resetting env. episode 2587.000000, reward total was -19.000000. running mean: -20.343525\n",
            "resetting env. episode 2588.000000, reward total was -21.000000. running mean: -20.350090\n",
            "resetting env. episode 2589.000000, reward total was -21.000000. running mean: -20.356589\n",
            "resetting env. episode 2590.000000, reward total was -21.000000. running mean: -20.363023\n",
            "resetting env. episode 2591.000000, reward total was -21.000000. running mean: -20.369393\n",
            "resetting env. episode 2592.000000, reward total was -21.000000. running mean: -20.375699\n",
            "resetting env. episode 2593.000000, reward total was -21.000000. running mean: -20.381942\n",
            "resetting env. episode 2594.000000, reward total was -20.000000. running mean: -20.378123\n",
            "resetting env. episode 2595.000000, reward total was -21.000000. running mean: -20.384341\n",
            "resetting env. episode 2596.000000, reward total was -21.000000. running mean: -20.390498\n",
            "resetting env. episode 2597.000000, reward total was -21.000000. running mean: -20.396593\n",
            "resetting env. episode 2598.000000, reward total was -21.000000. running mean: -20.402627\n",
            "resetting env. episode 2599.000000, reward total was -21.000000. running mean: -20.408601\n",
            "resetting env. episode 2600.000000, reward total was -21.000000. running mean: -20.414515\n",
            "resetting env. episode 2601.000000, reward total was -21.000000. running mean: -20.420370\n",
            "resetting env. episode 2602.000000, reward total was -19.000000. running mean: -20.406166\n",
            "resetting env. episode 2603.000000, reward total was -21.000000. running mean: -20.412104\n",
            "resetting env. episode 2604.000000, reward total was -20.000000. running mean: -20.407983\n",
            "resetting env. episode 2605.000000, reward total was -21.000000. running mean: -20.413904\n",
            "resetting env. episode 2606.000000, reward total was -19.000000. running mean: -20.399764\n",
            "resetting env. episode 2607.000000, reward total was -18.000000. running mean: -20.375767\n",
            "resetting env. episode 2608.000000, reward total was -20.000000. running mean: -20.372009\n",
            "resetting env. episode 2609.000000, reward total was -18.000000. running mean: -20.348289\n",
            "resetting env. episode 2610.000000, reward total was -20.000000. running mean: -20.344806\n",
            "resetting env. episode 2611.000000, reward total was -20.000000. running mean: -20.341358\n",
            "resetting env. episode 2612.000000, reward total was -21.000000. running mean: -20.347945\n",
            "resetting env. episode 2613.000000, reward total was -21.000000. running mean: -20.354465\n",
            "resetting env. episode 2614.000000, reward total was -19.000000. running mean: -20.340920\n",
            "resetting env. episode 2615.000000, reward total was -20.000000. running mean: -20.337511\n",
            "resetting env. episode 2616.000000, reward total was -21.000000. running mean: -20.344136\n",
            "resetting env. episode 2617.000000, reward total was -19.000000. running mean: -20.330695\n",
            "resetting env. episode 2618.000000, reward total was -21.000000. running mean: -20.337388\n",
            "resetting env. episode 2619.000000, reward total was -20.000000. running mean: -20.334014\n",
            "resetting env. episode 2620.000000, reward total was -21.000000. running mean: -20.340674\n",
            "resetting env. episode 2621.000000, reward total was -21.000000. running mean: -20.347267\n",
            "resetting env. episode 2622.000000, reward total was -19.000000. running mean: -20.333794\n",
            "resetting env. episode 2623.000000, reward total was -19.000000. running mean: -20.320456\n",
            "resetting env. episode 2624.000000, reward total was -20.000000. running mean: -20.317252\n",
            "resetting env. episode 2625.000000, reward total was -20.000000. running mean: -20.314079\n",
            "resetting env. episode 2626.000000, reward total was -20.000000. running mean: -20.310939\n",
            "resetting env. episode 2627.000000, reward total was -21.000000. running mean: -20.317829\n",
            "resetting env. episode 2628.000000, reward total was -16.000000. running mean: -20.274651\n",
            "resetting env. episode 2629.000000, reward total was -20.000000. running mean: -20.271904\n",
            "resetting env. episode 2630.000000, reward total was -21.000000. running mean: -20.279185\n",
            "resetting env. episode 2631.000000, reward total was -17.000000. running mean: -20.246393\n",
            "resetting env. episode 2632.000000, reward total was -21.000000. running mean: -20.253930\n",
            "resetting env. episode 2633.000000, reward total was -21.000000. running mean: -20.261390\n",
            "resetting env. episode 2634.000000, reward total was -20.000000. running mean: -20.258776\n",
            "resetting env. episode 2635.000000, reward total was -21.000000. running mean: -20.266189\n",
            "resetting env. episode 2636.000000, reward total was -21.000000. running mean: -20.273527\n",
            "resetting env. episode 2637.000000, reward total was -19.000000. running mean: -20.260791\n",
            "resetting env. episode 2638.000000, reward total was -21.000000. running mean: -20.268184\n",
            "resetting env. episode 2639.000000, reward total was -17.000000. running mean: -20.235502\n",
            "resetting env. episode 2640.000000, reward total was -21.000000. running mean: -20.243147\n",
            "resetting env. episode 2641.000000, reward total was -21.000000. running mean: -20.250715\n",
            "resetting env. episode 2642.000000, reward total was -21.000000. running mean: -20.258208\n",
            "resetting env. episode 2643.000000, reward total was -21.000000. running mean: -20.265626\n",
            "resetting env. episode 2644.000000, reward total was -19.000000. running mean: -20.252970\n",
            "resetting env. episode 2645.000000, reward total was -20.000000. running mean: -20.250440\n",
            "resetting env. episode 2646.000000, reward total was -21.000000. running mean: -20.257936\n",
            "resetting env. episode 2647.000000, reward total was -17.000000. running mean: -20.225356\n",
            "resetting env. episode 2648.000000, reward total was -21.000000. running mean: -20.233103\n",
            "resetting env. episode 2649.000000, reward total was -21.000000. running mean: -20.240772\n",
            "resetting env. episode 2650.000000, reward total was -21.000000. running mean: -20.248364\n",
            "resetting env. episode 2651.000000, reward total was -19.000000. running mean: -20.235880\n",
            "resetting env. episode 2652.000000, reward total was -21.000000. running mean: -20.243522\n",
            "resetting env. episode 2653.000000, reward total was -20.000000. running mean: -20.241086\n",
            "resetting env. episode 2654.000000, reward total was -20.000000. running mean: -20.238675\n",
            "resetting env. episode 2655.000000, reward total was -21.000000. running mean: -20.246289\n",
            "resetting env. episode 2656.000000, reward total was -20.000000. running mean: -20.243826\n",
            "resetting env. episode 2657.000000, reward total was -20.000000. running mean: -20.241388\n",
            "resetting env. episode 2658.000000, reward total was -21.000000. running mean: -20.248974\n",
            "resetting env. episode 2659.000000, reward total was -20.000000. running mean: -20.246484\n",
            "resetting env. episode 2660.000000, reward total was -19.000000. running mean: -20.234019\n",
            "resetting env. episode 2661.000000, reward total was -20.000000. running mean: -20.231679\n",
            "resetting env. episode 2662.000000, reward total was -19.000000. running mean: -20.219362\n",
            "resetting env. episode 2663.000000, reward total was -21.000000. running mean: -20.227168\n",
            "resetting env. episode 2664.000000, reward total was -21.000000. running mean: -20.234897\n",
            "resetting env. episode 2665.000000, reward total was -21.000000. running mean: -20.242548\n",
            "resetting env. episode 2666.000000, reward total was -21.000000. running mean: -20.250122\n",
            "resetting env. episode 2667.000000, reward total was -20.000000. running mean: -20.247621\n",
            "resetting env. episode 2668.000000, reward total was -21.000000. running mean: -20.255145\n",
            "resetting env. episode 2669.000000, reward total was -21.000000. running mean: -20.262593\n",
            "resetting env. episode 2670.000000, reward total was -20.000000. running mean: -20.259968\n",
            "resetting env. episode 2671.000000, reward total was -20.000000. running mean: -20.257368\n",
            "resetting env. episode 2672.000000, reward total was -21.000000. running mean: -20.264794\n",
            "resetting env. episode 2673.000000, reward total was -19.000000. running mean: -20.252146\n",
            "resetting env. episode 2674.000000, reward total was -21.000000. running mean: -20.259625\n",
            "resetting env. episode 2675.000000, reward total was -21.000000. running mean: -20.267029\n",
            "resetting env. episode 2676.000000, reward total was -21.000000. running mean: -20.274358\n",
            "resetting env. episode 2677.000000, reward total was -20.000000. running mean: -20.271615\n",
            "resetting env. episode 2678.000000, reward total was -21.000000. running mean: -20.278899\n",
            "resetting env. episode 2679.000000, reward total was -21.000000. running mean: -20.286110\n",
            "resetting env. episode 2680.000000, reward total was -19.000000. running mean: -20.273248\n",
            "resetting env. episode 2681.000000, reward total was -21.000000. running mean: -20.280516\n",
            "resetting env. episode 2682.000000, reward total was -19.000000. running mean: -20.267711\n",
            "resetting env. episode 2683.000000, reward total was -21.000000. running mean: -20.275034\n",
            "resetting env. episode 2684.000000, reward total was -21.000000. running mean: -20.282283\n",
            "resetting env. episode 2685.000000, reward total was -21.000000. running mean: -20.289461\n",
            "resetting env. episode 2686.000000, reward total was -19.000000. running mean: -20.276566\n",
            "resetting env. episode 2687.000000, reward total was -19.000000. running mean: -20.263800\n",
            "resetting env. episode 2688.000000, reward total was -21.000000. running mean: -20.271162\n",
            "resetting env. episode 2689.000000, reward total was -21.000000. running mean: -20.278451\n",
            "resetting env. episode 2690.000000, reward total was -21.000000. running mean: -20.285666\n",
            "resetting env. episode 2691.000000, reward total was -19.000000. running mean: -20.272809\n",
            "resetting env. episode 2692.000000, reward total was -20.000000. running mean: -20.270081\n",
            "resetting env. episode 2693.000000, reward total was -20.000000. running mean: -20.267381\n",
            "resetting env. episode 2694.000000, reward total was -21.000000. running mean: -20.274707\n",
            "resetting env. episode 2695.000000, reward total was -21.000000. running mean: -20.281960\n",
            "resetting env. episode 2696.000000, reward total was -21.000000. running mean: -20.289140\n",
            "resetting env. episode 2697.000000, reward total was -21.000000. running mean: -20.296249\n",
            "resetting env. episode 2698.000000, reward total was -18.000000. running mean: -20.273286\n",
            "resetting env. episode 2699.000000, reward total was -20.000000. running mean: -20.270553\n",
            "resetting env. episode 2700.000000, reward total was -21.000000. running mean: -20.277848\n",
            "resetting env. episode 2701.000000, reward total was -19.000000. running mean: -20.265069\n",
            "resetting env. episode 2702.000000, reward total was -20.000000. running mean: -20.262419\n",
            "resetting env. episode 2703.000000, reward total was -21.000000. running mean: -20.269794\n",
            "resetting env. episode 2704.000000, reward total was -21.000000. running mean: -20.277096\n",
            "resetting env. episode 2705.000000, reward total was -20.000000. running mean: -20.274326\n",
            "resetting env. episode 2706.000000, reward total was -21.000000. running mean: -20.281582\n",
            "resetting env. episode 2707.000000, reward total was -21.000000. running mean: -20.288766\n",
            "resetting env. episode 2708.000000, reward total was -21.000000. running mean: -20.295879\n",
            "resetting env. episode 2709.000000, reward total was -20.000000. running mean: -20.292920\n",
            "resetting env. episode 2710.000000, reward total was -21.000000. running mean: -20.299991\n",
            "resetting env. episode 2711.000000, reward total was -19.000000. running mean: -20.286991\n",
            "resetting env. episode 2712.000000, reward total was -21.000000. running mean: -20.294121\n",
            "resetting env. episode 2713.000000, reward total was -21.000000. running mean: -20.301180\n",
            "resetting env. episode 2714.000000, reward total was -21.000000. running mean: -20.308168\n",
            "resetting env. episode 2715.000000, reward total was -21.000000. running mean: -20.315086\n",
            "resetting env. episode 2716.000000, reward total was -21.000000. running mean: -20.321935\n",
            "resetting env. episode 2717.000000, reward total was -21.000000. running mean: -20.328716\n",
            "resetting env. episode 2718.000000, reward total was -21.000000. running mean: -20.335429\n",
            "resetting env. episode 2719.000000, reward total was -20.000000. running mean: -20.332075\n",
            "resetting env. episode 2720.000000, reward total was -20.000000. running mean: -20.328754\n",
            "resetting env. episode 2721.000000, reward total was -21.000000. running mean: -20.335466\n",
            "resetting env. episode 2722.000000, reward total was -20.000000. running mean: -20.332112\n",
            "resetting env. episode 2723.000000, reward total was -21.000000. running mean: -20.338791\n",
            "resetting env. episode 2724.000000, reward total was -20.000000. running mean: -20.335403\n",
            "resetting env. episode 2725.000000, reward total was -21.000000. running mean: -20.342049\n",
            "resetting env. episode 2726.000000, reward total was -21.000000. running mean: -20.348628\n",
            "resetting env. episode 2727.000000, reward total was -21.000000. running mean: -20.355142\n",
            "resetting env. episode 2728.000000, reward total was -20.000000. running mean: -20.351590\n",
            "resetting env. episode 2729.000000, reward total was -21.000000. running mean: -20.358075\n",
            "resetting env. episode 2730.000000, reward total was -21.000000. running mean: -20.364494\n",
            "resetting env. episode 2731.000000, reward total was -21.000000. running mean: -20.370849\n",
            "resetting env. episode 2732.000000, reward total was -21.000000. running mean: -20.377140\n",
            "resetting env. episode 2733.000000, reward total was -21.000000. running mean: -20.383369\n",
            "resetting env. episode 2734.000000, reward total was -20.000000. running mean: -20.379535\n",
            "resetting env. episode 2735.000000, reward total was -21.000000. running mean: -20.385740\n",
            "resetting env. episode 2736.000000, reward total was -21.000000. running mean: -20.391883\n",
            "resetting env. episode 2737.000000, reward total was -21.000000. running mean: -20.397964\n",
            "resetting env. episode 2738.000000, reward total was -19.000000. running mean: -20.383984\n",
            "resetting env. episode 2739.000000, reward total was -20.000000. running mean: -20.380144\n",
            "resetting env. episode 2740.000000, reward total was -21.000000. running mean: -20.386343\n",
            "resetting env. episode 2741.000000, reward total was -21.000000. running mean: -20.392479\n",
            "resetting env. episode 2742.000000, reward total was -21.000000. running mean: -20.398555\n",
            "resetting env. episode 2743.000000, reward total was -21.000000. running mean: -20.404569\n",
            "resetting env. episode 2744.000000, reward total was -21.000000. running mean: -20.410523\n",
            "resetting env. episode 2745.000000, reward total was -21.000000. running mean: -20.416418\n",
            "resetting env. episode 2746.000000, reward total was -21.000000. running mean: -20.422254\n",
            "resetting env. episode 2747.000000, reward total was -21.000000. running mean: -20.428031\n",
            "resetting env. episode 2748.000000, reward total was -20.000000. running mean: -20.423751\n",
            "resetting env. episode 2749.000000, reward total was -17.000000. running mean: -20.389514\n",
            "resetting env. episode 2750.000000, reward total was -21.000000. running mean: -20.395618\n",
            "resetting env. episode 2751.000000, reward total was -21.000000. running mean: -20.401662\n",
            "resetting env. episode 2752.000000, reward total was -21.000000. running mean: -20.407646\n",
            "resetting env. episode 2753.000000, reward total was -19.000000. running mean: -20.393569\n",
            "resetting env. episode 2754.000000, reward total was -21.000000. running mean: -20.399633\n",
            "resetting env. episode 2755.000000, reward total was -21.000000. running mean: -20.405637\n",
            "resetting env. episode 2756.000000, reward total was -20.000000. running mean: -20.401581\n",
            "resetting env. episode 2757.000000, reward total was -20.000000. running mean: -20.397565\n",
            "resetting env. episode 2758.000000, reward total was -21.000000. running mean: -20.403589\n",
            "resetting env. episode 2759.000000, reward total was -21.000000. running mean: -20.409553\n",
            "resetting env. episode 2760.000000, reward total was -21.000000. running mean: -20.415458\n",
            "resetting env. episode 2761.000000, reward total was -20.000000. running mean: -20.411303\n",
            "resetting env. episode 2762.000000, reward total was -19.000000. running mean: -20.397190\n",
            "resetting env. episode 2763.000000, reward total was -21.000000. running mean: -20.403218\n",
            "resetting env. episode 2764.000000, reward total was -21.000000. running mean: -20.409186\n",
            "resetting env. episode 2765.000000, reward total was -21.000000. running mean: -20.415094\n",
            "resetting env. episode 2766.000000, reward total was -20.000000. running mean: -20.410943\n",
            "resetting env. episode 2767.000000, reward total was -20.000000. running mean: -20.406834\n",
            "resetting env. episode 2768.000000, reward total was -21.000000. running mean: -20.412766\n",
            "resetting env. episode 2769.000000, reward total was -21.000000. running mean: -20.418638\n",
            "resetting env. episode 2770.000000, reward total was -21.000000. running mean: -20.424452\n",
            "resetting env. episode 2771.000000, reward total was -21.000000. running mean: -20.430207\n",
            "resetting env. episode 2772.000000, reward total was -21.000000. running mean: -20.435905\n",
            "resetting env. episode 2773.000000, reward total was -21.000000. running mean: -20.441546\n",
            "resetting env. episode 2774.000000, reward total was -21.000000. running mean: -20.447130\n",
            "resetting env. episode 2775.000000, reward total was -19.000000. running mean: -20.432659\n",
            "resetting env. episode 2776.000000, reward total was -20.000000. running mean: -20.428333\n",
            "resetting env. episode 2777.000000, reward total was -21.000000. running mean: -20.434049\n",
            "resetting env. episode 2778.000000, reward total was -20.000000. running mean: -20.429709\n",
            "resetting env. episode 2779.000000, reward total was -19.000000. running mean: -20.415412\n",
            "resetting env. episode 2780.000000, reward total was -20.000000. running mean: -20.411258\n",
            "resetting env. episode 2781.000000, reward total was -21.000000. running mean: -20.417145\n",
            "resetting env. episode 2782.000000, reward total was -21.000000. running mean: -20.422974\n",
            "resetting env. episode 2783.000000, reward total was -19.000000. running mean: -20.408744\n",
            "resetting env. episode 2784.000000, reward total was -21.000000. running mean: -20.414656\n",
            "resetting env. episode 2785.000000, reward total was -21.000000. running mean: -20.420510\n",
            "resetting env. episode 2786.000000, reward total was -20.000000. running mean: -20.416305\n",
            "resetting env. episode 2787.000000, reward total was -20.000000. running mean: -20.412142\n",
            "resetting env. episode 2788.000000, reward total was -21.000000. running mean: -20.418020\n",
            "resetting env. episode 2789.000000, reward total was -20.000000. running mean: -20.413840\n",
            "resetting env. episode 2790.000000, reward total was -19.000000. running mean: -20.399702\n",
            "resetting env. episode 2791.000000, reward total was -21.000000. running mean: -20.405705\n",
            "resetting env. episode 2792.000000, reward total was -20.000000. running mean: -20.401648\n",
            "resetting env. episode 2793.000000, reward total was -21.000000. running mean: -20.407631\n",
            "resetting env. episode 2794.000000, reward total was -20.000000. running mean: -20.403555\n",
            "resetting env. episode 2795.000000, reward total was -21.000000. running mean: -20.409519\n",
            "resetting env. episode 2796.000000, reward total was -20.000000. running mean: -20.405424\n",
            "resetting env. episode 2797.000000, reward total was -20.000000. running mean: -20.401370\n",
            "resetting env. episode 2798.000000, reward total was -21.000000. running mean: -20.407356\n",
            "resetting env. episode 2799.000000, reward total was -20.000000. running mean: -20.403283\n",
            "resetting env. episode 2800.000000, reward total was -20.000000. running mean: -20.399250\n",
            "resetting env. episode 2801.000000, reward total was -20.000000. running mean: -20.395257\n",
            "resetting env. episode 2802.000000, reward total was -21.000000. running mean: -20.401305\n",
            "resetting env. episode 2803.000000, reward total was -20.000000. running mean: -20.397292\n",
            "resetting env. episode 2804.000000, reward total was -21.000000. running mean: -20.403319\n",
            "resetting env. episode 2805.000000, reward total was -21.000000. running mean: -20.409285\n",
            "resetting env. episode 2806.000000, reward total was -20.000000. running mean: -20.405193\n",
            "resetting env. episode 2807.000000, reward total was -21.000000. running mean: -20.411141\n",
            "resetting env. episode 2808.000000, reward total was -19.000000. running mean: -20.397029\n",
            "resetting env. episode 2809.000000, reward total was -19.000000. running mean: -20.383059\n",
            "resetting env. episode 2810.000000, reward total was -21.000000. running mean: -20.389228\n",
            "resetting env. episode 2811.000000, reward total was -21.000000. running mean: -20.395336\n",
            "resetting env. episode 2812.000000, reward total was -20.000000. running mean: -20.391383\n",
            "resetting env. episode 2813.000000, reward total was -20.000000. running mean: -20.387469\n",
            "resetting env. episode 2814.000000, reward total was -21.000000. running mean: -20.393594\n",
            "resetting env. episode 2815.000000, reward total was -21.000000. running mean: -20.399658\n",
            "resetting env. episode 2816.000000, reward total was -21.000000. running mean: -20.405662\n",
            "resetting env. episode 2817.000000, reward total was -20.000000. running mean: -20.401605\n",
            "resetting env. episode 2818.000000, reward total was -21.000000. running mean: -20.407589\n",
            "resetting env. episode 2819.000000, reward total was -21.000000. running mean: -20.413513\n",
            "resetting env. episode 2820.000000, reward total was -20.000000. running mean: -20.409378\n",
            "resetting env. episode 2821.000000, reward total was -21.000000. running mean: -20.415284\n",
            "resetting env. episode 2822.000000, reward total was -21.000000. running mean: -20.421131\n",
            "resetting env. episode 2823.000000, reward total was -20.000000. running mean: -20.416920\n",
            "resetting env. episode 2824.000000, reward total was -20.000000. running mean: -20.412751\n",
            "resetting env. episode 2825.000000, reward total was -21.000000. running mean: -20.418623\n",
            "resetting env. episode 2826.000000, reward total was -19.000000. running mean: -20.404437\n",
            "resetting env. episode 2827.000000, reward total was -21.000000. running mean: -20.410393\n",
            "resetting env. episode 2828.000000, reward total was -21.000000. running mean: -20.416289\n",
            "resetting env. episode 2829.000000, reward total was -18.000000. running mean: -20.392126\n",
            "resetting env. episode 2830.000000, reward total was -21.000000. running mean: -20.398205\n",
            "resetting env. episode 2831.000000, reward total was -21.000000. running mean: -20.404223\n",
            "resetting env. episode 2832.000000, reward total was -20.000000. running mean: -20.400180\n",
            "resetting env. episode 2833.000000, reward total was -20.000000. running mean: -20.396179\n",
            "resetting env. episode 2834.000000, reward total was -19.000000. running mean: -20.382217\n",
            "resetting env. episode 2835.000000, reward total was -21.000000. running mean: -20.388395\n",
            "resetting env. episode 2836.000000, reward total was -21.000000. running mean: -20.394511\n",
            "resetting env. episode 2837.000000, reward total was -20.000000. running mean: -20.390566\n",
            "resetting env. episode 2838.000000, reward total was -21.000000. running mean: -20.396660\n",
            "resetting env. episode 2839.000000, reward total was -21.000000. running mean: -20.402693\n",
            "resetting env. episode 2840.000000, reward total was -21.000000. running mean: -20.408666\n",
            "resetting env. episode 2841.000000, reward total was -21.000000. running mean: -20.414580\n",
            "resetting env. episode 2842.000000, reward total was -21.000000. running mean: -20.420434\n",
            "resetting env. episode 2843.000000, reward total was -20.000000. running mean: -20.416230\n",
            "resetting env. episode 2844.000000, reward total was -21.000000. running mean: -20.422067\n",
            "resetting env. episode 2845.000000, reward total was -20.000000. running mean: -20.417847\n",
            "resetting env. episode 2846.000000, reward total was -21.000000. running mean: -20.423668\n",
            "resetting env. episode 2847.000000, reward total was -21.000000. running mean: -20.429432\n",
            "resetting env. episode 2848.000000, reward total was -21.000000. running mean: -20.435137\n",
            "resetting env. episode 2849.000000, reward total was -21.000000. running mean: -20.440786\n",
            "resetting env. episode 2850.000000, reward total was -21.000000. running mean: -20.446378\n",
            "resetting env. episode 2851.000000, reward total was -21.000000. running mean: -20.451914\n",
            "resetting env. episode 2852.000000, reward total was -21.000000. running mean: -20.457395\n",
            "resetting env. episode 2853.000000, reward total was -21.000000. running mean: -20.462821\n",
            "resetting env. episode 2854.000000, reward total was -21.000000. running mean: -20.468193\n",
            "resetting env. episode 2855.000000, reward total was -21.000000. running mean: -20.473511\n",
            "resetting env. episode 2856.000000, reward total was -21.000000. running mean: -20.478776\n",
            "resetting env. episode 2857.000000, reward total was -20.000000. running mean: -20.473988\n",
            "resetting env. episode 2858.000000, reward total was -21.000000. running mean: -20.479248\n",
            "resetting env. episode 2859.000000, reward total was -20.000000. running mean: -20.474456\n",
            "resetting env. episode 2860.000000, reward total was -20.000000. running mean: -20.469711\n",
            "resetting env. episode 2861.000000, reward total was -21.000000. running mean: -20.475014\n",
            "resetting env. episode 2862.000000, reward total was -18.000000. running mean: -20.450264\n",
            "resetting env. episode 2863.000000, reward total was -21.000000. running mean: -20.455761\n",
            "resetting env. episode 2864.000000, reward total was -20.000000. running mean: -20.451204\n",
            "resetting env. episode 2865.000000, reward total was -20.000000. running mean: -20.446692\n",
            "resetting env. episode 2866.000000, reward total was -20.000000. running mean: -20.442225\n",
            "resetting env. episode 2867.000000, reward total was -21.000000. running mean: -20.447802\n",
            "resetting env. episode 2868.000000, reward total was -21.000000. running mean: -20.453324\n",
            "resetting env. episode 2869.000000, reward total was -21.000000. running mean: -20.458791\n",
            "resetting env. episode 2870.000000, reward total was -21.000000. running mean: -20.464203\n",
            "resetting env. episode 2871.000000, reward total was -20.000000. running mean: -20.459561\n",
            "resetting env. episode 2872.000000, reward total was -21.000000. running mean: -20.464966\n",
            "resetting env. episode 2873.000000, reward total was -19.000000. running mean: -20.450316\n",
            "resetting env. episode 2874.000000, reward total was -21.000000. running mean: -20.455813\n",
            "resetting env. episode 2875.000000, reward total was -21.000000. running mean: -20.461255\n",
            "resetting env. episode 2876.000000, reward total was -21.000000. running mean: -20.466642\n",
            "resetting env. episode 2877.000000, reward total was -20.000000. running mean: -20.461976\n",
            "resetting env. episode 2878.000000, reward total was -20.000000. running mean: -20.457356\n",
            "resetting env. episode 2879.000000, reward total was -20.000000. running mean: -20.452782\n",
            "resetting env. episode 2880.000000, reward total was -20.000000. running mean: -20.448255\n",
            "resetting env. episode 2881.000000, reward total was -21.000000. running mean: -20.453772\n",
            "resetting env. episode 2882.000000, reward total was -19.000000. running mean: -20.439234\n",
            "resetting env. episode 2883.000000, reward total was -21.000000. running mean: -20.444842\n",
            "resetting env. episode 2884.000000, reward total was -20.000000. running mean: -20.440394\n",
            "resetting env. episode 2885.000000, reward total was -21.000000. running mean: -20.445990\n",
            "resetting env. episode 2886.000000, reward total was -20.000000. running mean: -20.441530\n",
            "resetting env. episode 2887.000000, reward total was -21.000000. running mean: -20.447114\n",
            "resetting env. episode 2888.000000, reward total was -21.000000. running mean: -20.452643\n",
            "resetting env. episode 2889.000000, reward total was -21.000000. running mean: -20.458117\n",
            "resetting env. episode 2890.000000, reward total was -21.000000. running mean: -20.463536\n",
            "resetting env. episode 2891.000000, reward total was -21.000000. running mean: -20.468900\n",
            "resetting env. episode 2892.000000, reward total was -19.000000. running mean: -20.454211\n",
            "resetting env. episode 2893.000000, reward total was -20.000000. running mean: -20.449669\n",
            "resetting env. episode 2894.000000, reward total was -20.000000. running mean: -20.445173\n",
            "resetting env. episode 2895.000000, reward total was -20.000000. running mean: -20.440721\n",
            "resetting env. episode 2896.000000, reward total was -20.000000. running mean: -20.436314\n",
            "resetting env. episode 2897.000000, reward total was -20.000000. running mean: -20.431950\n",
            "resetting env. episode 2898.000000, reward total was -20.000000. running mean: -20.427631\n",
            "resetting env. episode 2899.000000, reward total was -21.000000. running mean: -20.433355\n",
            "resetting env. episode 2900.000000, reward total was -21.000000. running mean: -20.439021\n",
            "resetting env. episode 2901.000000, reward total was -21.000000. running mean: -20.444631\n",
            "resetting env. episode 2902.000000, reward total was -20.000000. running mean: -20.440185\n",
            "resetting env. episode 2903.000000, reward total was -18.000000. running mean: -20.415783\n",
            "resetting env. episode 2904.000000, reward total was -21.000000. running mean: -20.421625\n",
            "resetting env. episode 2905.000000, reward total was -20.000000. running mean: -20.417409\n",
            "resetting env. episode 2906.000000, reward total was -21.000000. running mean: -20.423235\n",
            "resetting env. episode 2907.000000, reward total was -20.000000. running mean: -20.419002\n",
            "resetting env. episode 2908.000000, reward total was -21.000000. running mean: -20.424812\n",
            "resetting env. episode 2909.000000, reward total was -21.000000. running mean: -20.430564\n",
            "resetting env. episode 2910.000000, reward total was -21.000000. running mean: -20.436258\n",
            "resetting env. episode 2911.000000, reward total was -19.000000. running mean: -20.421896\n",
            "resetting env. episode 2912.000000, reward total was -21.000000. running mean: -20.427677\n",
            "resetting env. episode 2913.000000, reward total was -17.000000. running mean: -20.393400\n",
            "resetting env. episode 2914.000000, reward total was -21.000000. running mean: -20.399466\n",
            "resetting env. episode 2915.000000, reward total was -21.000000. running mean: -20.405471\n",
            "resetting env. episode 2916.000000, reward total was -20.000000. running mean: -20.401417\n",
            "resetting env. episode 2917.000000, reward total was -20.000000. running mean: -20.397403\n",
            "resetting env. episode 2918.000000, reward total was -21.000000. running mean: -20.403429\n",
            "resetting env. episode 2919.000000, reward total was -21.000000. running mean: -20.409394\n",
            "resetting env. episode 2920.000000, reward total was -21.000000. running mean: -20.415300\n",
            "resetting env. episode 2921.000000, reward total was -21.000000. running mean: -20.421147\n",
            "resetting env. episode 2922.000000, reward total was -21.000000. running mean: -20.426936\n",
            "resetting env. episode 2923.000000, reward total was -21.000000. running mean: -20.432666\n",
            "resetting env. episode 2924.000000, reward total was -19.000000. running mean: -20.418340\n",
            "resetting env. episode 2925.000000, reward total was -20.000000. running mean: -20.414156\n",
            "resetting env. episode 2926.000000, reward total was -20.000000. running mean: -20.410015\n",
            "resetting env. episode 2927.000000, reward total was -21.000000. running mean: -20.415915\n",
            "resetting env. episode 2928.000000, reward total was -21.000000. running mean: -20.421756\n",
            "resetting env. episode 2929.000000, reward total was -21.000000. running mean: -20.427538\n",
            "resetting env. episode 2930.000000, reward total was -21.000000. running mean: -20.433263\n",
            "resetting env. episode 2931.000000, reward total was -21.000000. running mean: -20.438930\n",
            "resetting env. episode 2932.000000, reward total was -21.000000. running mean: -20.444541\n",
            "resetting env. episode 2933.000000, reward total was -20.000000. running mean: -20.440095\n",
            "resetting env. episode 2934.000000, reward total was -21.000000. running mean: -20.445694\n",
            "resetting env. episode 2935.000000, reward total was -21.000000. running mean: -20.451237\n",
            "resetting env. episode 2936.000000, reward total was -21.000000. running mean: -20.456725\n",
            "resetting env. episode 2937.000000, reward total was -21.000000. running mean: -20.462158\n",
            "resetting env. episode 2938.000000, reward total was -20.000000. running mean: -20.457536\n",
            "resetting env. episode 2939.000000, reward total was -20.000000. running mean: -20.452961\n",
            "resetting env. episode 2940.000000, reward total was -21.000000. running mean: -20.458431\n",
            "resetting env. episode 2941.000000, reward total was -20.000000. running mean: -20.453847\n",
            "resetting env. episode 2942.000000, reward total was -21.000000. running mean: -20.459308\n",
            "resetting env. episode 2943.000000, reward total was -20.000000. running mean: -20.454715\n",
            "resetting env. episode 2944.000000, reward total was -21.000000. running mean: -20.460168\n",
            "resetting env. episode 2945.000000, reward total was -20.000000. running mean: -20.455567\n",
            "resetting env. episode 2946.000000, reward total was -21.000000. running mean: -20.461011\n",
            "resetting env. episode 2947.000000, reward total was -20.000000. running mean: -20.456401\n",
            "resetting env. episode 2948.000000, reward total was -20.000000. running mean: -20.451837\n",
            "resetting env. episode 2949.000000, reward total was -21.000000. running mean: -20.457318\n",
            "resetting env. episode 2950.000000, reward total was -21.000000. running mean: -20.462745\n",
            "resetting env. episode 2951.000000, reward total was -21.000000. running mean: -20.468118\n",
            "resetting env. episode 2952.000000, reward total was -21.000000. running mean: -20.473437\n",
            "resetting env. episode 2953.000000, reward total was -21.000000. running mean: -20.478702\n",
            "resetting env. episode 2954.000000, reward total was -20.000000. running mean: -20.473915\n",
            "resetting env. episode 2955.000000, reward total was -20.000000. running mean: -20.469176\n",
            "resetting env. episode 2956.000000, reward total was -21.000000. running mean: -20.474484\n",
            "resetting env. episode 2957.000000, reward total was -21.000000. running mean: -20.479739\n",
            "resetting env. episode 2958.000000, reward total was -21.000000. running mean: -20.484942\n",
            "resetting env. episode 2959.000000, reward total was -21.000000. running mean: -20.490093\n",
            "resetting env. episode 2960.000000, reward total was -21.000000. running mean: -20.495192\n",
            "resetting env. episode 2961.000000, reward total was -21.000000. running mean: -20.500240\n",
            "resetting env. episode 2962.000000, reward total was -21.000000. running mean: -20.505237\n",
            "resetting env. episode 2963.000000, reward total was -21.000000. running mean: -20.510185\n",
            "resetting env. episode 2964.000000, reward total was -20.000000. running mean: -20.505083\n",
            "resetting env. episode 2965.000000, reward total was -21.000000. running mean: -20.510032\n",
            "resetting env. episode 2966.000000, reward total was -21.000000. running mean: -20.514932\n",
            "resetting env. episode 2967.000000, reward total was -21.000000. running mean: -20.519783\n",
            "resetting env. episode 2968.000000, reward total was -20.000000. running mean: -20.514585\n",
            "resetting env. episode 2969.000000, reward total was -20.000000. running mean: -20.509439\n",
            "resetting env. episode 2970.000000, reward total was -21.000000. running mean: -20.514345\n",
            "resetting env. episode 2971.000000, reward total was -21.000000. running mean: -20.519201\n",
            "resetting env. episode 2972.000000, reward total was -21.000000. running mean: -20.524009\n",
            "resetting env. episode 2973.000000, reward total was -21.000000. running mean: -20.528769\n",
            "resetting env. episode 2974.000000, reward total was -21.000000. running mean: -20.533481\n",
            "resetting env. episode 2975.000000, reward total was -21.000000. running mean: -20.538147\n",
            "resetting env. episode 2976.000000, reward total was -20.000000. running mean: -20.532765\n",
            "resetting env. episode 2977.000000, reward total was -21.000000. running mean: -20.537437\n",
            "resetting env. episode 2978.000000, reward total was -20.000000. running mean: -20.532063\n",
            "resetting env. episode 2979.000000, reward total was -21.000000. running mean: -20.536742\n",
            "resetting env. episode 2980.000000, reward total was -20.000000. running mean: -20.531375\n",
            "resetting env. episode 2981.000000, reward total was -21.000000. running mean: -20.536061\n",
            "resetting env. episode 2982.000000, reward total was -19.000000. running mean: -20.520701\n",
            "resetting env. episode 2983.000000, reward total was -21.000000. running mean: -20.525494\n",
            "resetting env. episode 2984.000000, reward total was -21.000000. running mean: -20.530239\n",
            "resetting env. episode 2985.000000, reward total was -18.000000. running mean: -20.504936\n",
            "resetting env. episode 2986.000000, reward total was -21.000000. running mean: -20.509887\n",
            "resetting env. episode 2987.000000, reward total was -21.000000. running mean: -20.514788\n",
            "resetting env. episode 2988.000000, reward total was -21.000000. running mean: -20.519640\n",
            "resetting env. episode 2989.000000, reward total was -21.000000. running mean: -20.524444\n",
            "resetting env. episode 2990.000000, reward total was -20.000000. running mean: -20.519199\n",
            "resetting env. episode 2991.000000, reward total was -21.000000. running mean: -20.524007\n",
            "resetting env. episode 2992.000000, reward total was -20.000000. running mean: -20.518767\n",
            "resetting env. episode 2993.000000, reward total was -21.000000. running mean: -20.523580\n",
            "resetting env. episode 2994.000000, reward total was -21.000000. running mean: -20.528344\n",
            "resetting env. episode 2995.000000, reward total was -20.000000. running mean: -20.523060\n",
            "resetting env. episode 2996.000000, reward total was -21.000000. running mean: -20.527830\n",
            "resetting env. episode 2997.000000, reward total was -21.000000. running mean: -20.532551\n",
            "resetting env. episode 2998.000000, reward total was -21.000000. running mean: -20.537226\n",
            "resetting env. episode 2999.000000, reward total was -21.000000. running mean: -20.541854\n",
            "resetting env. episode 3000.000000, reward total was -20.000000. running mean: -20.536435\n",
            "CPU times: user 2h 13min 12s, sys: 59min 49s, total: 3h 13min 2s\n",
            "Wall time: 1h 40min 55s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "cHYCDYwhlVLV"
      },
      "cell_type": "code",
      "source": [
        "#%time hist2 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8fheN9DRlWXQ",
        "outputId": "f139d86a-21b6-4003-ca83-f85c22b59431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9AxOcQhIsKow"
      },
      "cell_type": "code",
      "source": [
        "#%time hist3 = train_model(env, model, total_episodes=1500)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w2NblmwDsL3y"
      },
      "cell_type": "code",
      "source": [
        "#play_game(env, model)"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}